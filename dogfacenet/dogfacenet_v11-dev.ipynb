{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DogFaceNet version 11: Dev version number 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import tensorflow.keras.backend as K\n",
    "from triplets_processing import *\n",
    "import shutil\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/dogfacenet/aligned/after_4/'\n",
    "PATH_SAVE = '../output/history/'\n",
    "PATH_MODEL = '../output/model/'\n",
    "SIZE = (224,224,3)\n",
    "VALID_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "- Load image and labels\n",
    "- Training set, validation set (close-set) and testing (open-set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = np.empty(0)\n",
    "labels = np.empty(0)\n",
    "idx = 0\n",
    "for root,dirs,files in os.walk(PATH):\n",
    "    if len(files)>1:\n",
    "        for i in range(len(files)):\n",
    "            files[i] = root + '/' + files[i]\n",
    "        filenames = np.append(filenames,files)\n",
    "        labels = np.append(labels,np.ones(len(files))*idx)\n",
    "        idx += 1\n",
    "print(len(labels))\n",
    "h,w,c = SIZE\n",
    "images = np.empty((len(filenames),h,w,c))\n",
    "for i,f in enumerate(filenames):\n",
    "    images[i] = sk.io.imread(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "images /= 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['../data/dogfacenet/aligned/after_4/1182/1182.0.jpg',\n",
       "       '../data/dogfacenet/aligned/after_4/1182/1182.3.jpg',\n",
       "       '../data/dogfacenet/aligned/after_4/1182/1182.1.jpg', ...,\n",
       "       '../data/dogfacenet/aligned/after_4/1109/1109.4.jpg',\n",
       "       '../data/dogfacenet/aligned/after_4/1109/1109.3.jpg',\n",
       "       '../data/dogfacenet/aligned/after_4/1109/1109.1.jpg'], dtype='<U50')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without imread\n",
    "\n",
    "filenames = np.empty(0)\n",
    "labels = np.empty(0)\n",
    "idx = 0\n",
    "for root,dirs,files in os.walk(PATH):\n",
    "    if len(files)>1:\n",
    "        for i in range(len(files)):\n",
    "            files[i] = root + '/' + files[i]\n",
    "        filenames = np.append(filenames,files)\n",
    "        labels = np.append(labels,np.ones(len(files))*idx)\n",
    "        idx += 1\n",
    "print(len(labels))\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1424\n"
     ]
    }
   ],
   "source": [
    "nbof_classes = len(np.unique(labels))\n",
    "print(nbof_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "    channel_shift_range = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_transform(images, datagen):\n",
    "    \"\"\"\n",
    "    Apply a data preprocessing transformation to n images\n",
    "    Args:\n",
    "        -images\n",
    "        -ImageDataGenerator\n",
    "    Return:\n",
    "        -images of the same shape of the inputs but transformed\n",
    "    \"\"\"\n",
    "    for x in datagen.flow(images, batch_size=len(images), shuffle=False):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open-set: test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbof_test = int(TEST_SPLIT*nbof_classes)\n",
    "\n",
    "keep_test = np.less(labels,nbof_test)\n",
    "keep_train = np.logical_not(keep_test)\n",
    "\n",
    "filenames_test = filenames[keep_test]\n",
    "labels_test = labels[keep_test]\n",
    "\n",
    "filenames_train = filenames[keep_train]\n",
    "labels_train = labels[keep_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbof_test = int(TEST_SPLIT*nbof_classes)\n",
    "\n",
    "keep_test = np.less(labels,nbof_test)\n",
    "keep_train = np.logical_not(keep_test)\n",
    "\n",
    "images_test = images[keep_test]\n",
    "labels_test = labels[keep_test]\n",
    "\n",
    "images_train = images[keep_train]\n",
    "labels_train = labels[keep_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del images\n",
    "del labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_triplets_batch(filenames,labels,nbof_triplet = 21 * 3):\n",
    "    \n",
    "    triplet_train = []\n",
    "    y_triplet = np.empty(nbof_triplet)\n",
    "    classes = np.unique(labels)\n",
    "    for i in range(0,nbof_triplet,3):\n",
    "        # Pick a class and chose two pictures from this class\n",
    "        classAP = classes[np.random.randint(len(classes))]\n",
    "        keep = np.equal(labels,classAP)\n",
    "        keep_classAP = filenames[keep]\n",
    "        keep_classAP_idx = labels[keep]\n",
    "        idx_image1 = np.random.randint(len(keep_classAP))\n",
    "        idx_image2 = np.random.randint(len(keep_classAP))\n",
    "        while idx_image1 == idx_image2:\n",
    "            idx_image2 = np.random.randint(len(keep_classAP))\n",
    "\n",
    "        triplet_train += [keep_classAP[idx_image1]]\n",
    "        triplet_train += [keep_classAP[idx_image2]]\n",
    "        y_triplet[i] = keep_classAP_idx[idx_image1]\n",
    "        y_triplet[i+1] = keep_classAP_idx[idx_image2]\n",
    "        # Pick a class for the negative picture\n",
    "        classN = classes[np.random.randint(len(classes))]\n",
    "        while classN==classAP:\n",
    "            classN = classes[np.random.randint(len(classes))]\n",
    "        keep = np.equal(labels,classN)\n",
    "        keep_classN = filenames[keep]\n",
    "        keep_classN_idx = labels[keep]\n",
    "        idx_image3 = np.random.randint(len(keep_classN))\n",
    "        triplet_train += [keep_classN[idx_image3]]\n",
    "        y_triplet[i+2] = keep_classN_idx[idx_image3]\n",
    "        \n",
    "    return triplet_train, y_triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filenames):\n",
    "    h,w,c = SIZE\n",
    "    #print(filenames)\n",
    "    images = np.empty((len(filenames),h,w,c))\n",
    "    for i,f in enumerate(filenames):\n",
    "        #print(f)\n",
    "        images[i] = sk.io.imread(f)/255.0\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(filenames, labels, batch_size=63, use_aug=True, datagen=datagen):\n",
    "    while True:\n",
    "        f_triplet, y_triplet = define_triplets_batch(filenames, labels, batch_size)\n",
    "        i_triplet = load_images(f_triplet)\n",
    "        if use_aug:\n",
    "            i_triplet = apply_transform(i_triplet, datagen)\n",
    "        yield (i_triplet, y_triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,y in image_generator(filenames_train,labels_train,9):\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            plt.subplot(3,3,3*i+j+1)\n",
    "            plt.imshow(a[i*3+j])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet test definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c = SIZE\n",
    "images_test = np.empty((len(filenames_test),h,w,c))\n",
    "for i,f in enumerate(filenames_test):\n",
    "    images_test[i] = sk.io.imread(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#triplet_train, y_triplet_train = define_triplets(images_train,labels_train)\n",
    "triplet_test, y_triplet_test = define_triplets(images_test,labels_test,1000*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3\n",
    "def triplet(y_true,y_pred):\n",
    "    \n",
    "    a = y_pred[0::3]\n",
    "    p = y_pred[1::3]\n",
    "    n = y_pred[2::3]\n",
    "    \n",
    "    ap = K.sum(K.square(a-p),-1)\n",
    "    an = K.sum(K.square(a-n),-1)\n",
    "\n",
    "    return K.sum(tf.nn.relu(ap - an + alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_acc(y_true,y_pred):\n",
    "    a = y_pred[0::3]\n",
    "    p = y_pred[1::3]\n",
    "    n = y_pred[2::3]\n",
    "    \n",
    "    ap = K.sum(K.square(a-p),-1)\n",
    "    an = K.sum(K.square(a-n),-1)\n",
    "    \n",
    "    return K.less(ap+alpha,an)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dogfacenet_v11: VGG like\n",
    "emb_size = 16\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(104, 104, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(1024, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(emb_size))\n",
    "model.add(Lambda(lambda x: tf.nn.l2_normalize(x,axis=-1)))\n",
    "\n",
    "model.compile(loss=triplet,\n",
    "              optimizer='adam',\n",
    "              metrics=[triplet_acc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 224, 224, 16) 2352        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 112, 112, 16) 2304        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 112, 112, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 112, 112, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 112, 112, 16) 2304        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 112, 112, 16) 0           dropout[0][0]                    \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 112, 112, 16) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 16) 2304        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 112, 112, 16) 0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 112, 112, 16) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 32)   4608        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 56, 56, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 32)   9216        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 32)   0           dropout_3[0][0]                  \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 56, 56, 32)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 32)   9216        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 32)   0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 56, 56, 32)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 64)   18432       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 28, 28, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 64)   36864       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 28, 28, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_6[0][0]                  \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28, 28, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 64)   36864       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28, 28, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 64)   0           dropout_7[0][0]                  \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 28, 28, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 128)  73728       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 14, 14, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 14, 14, 128)  147456      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 14, 14, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 128)  0           dropout_9[0][0]                  \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 14, 14, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 14, 14, 128)  147456      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 14, 14, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 128)  0           dropout_10[0][0]                 \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 14, 14, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 512)    589824      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 7, 512)    2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 7, 7, 512)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 512)    2359296     dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 7, 7, 512)    2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 7, 7, 512)    0           dropout_12[0][0]                 \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 7, 7, 512)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 7, 7, 512)    2359296     dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 7, 7, 512)    2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 7, 7, 512)    0           dropout_13[0][0]                 \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 7, 7, 512)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 512)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          65536       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128)          0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 5,876,144\n",
      "Trainable params: 5,871,600\n",
      "Non-trainable params: 4,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# dogfacenet_v12: Resnet like\n",
    "emb_size = 128\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Add, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
    "\n",
    "inputs = Input(shape=SIZE)\n",
    "\n",
    "x = Conv2D(16, (7, 7), use_bias=False, activation='relu', padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "for layer in [16,32,64,128,512]:\n",
    "\n",
    "    x = Conv2D(layer, (3, 3), strides=(2,2), use_bias=False, activation='relu', padding='same')(x)\n",
    "    r = BatchNormalization()(x)\n",
    "    r = Dropout(0.25)(r)\n",
    "    \n",
    "    x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
    "    x = BatchNormalization()(x)\n",
    "    r = Add()([r,x])\n",
    "    r = Dropout(0.25)(r)\n",
    "    \n",
    "    x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([r,x])\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(emb_size, use_bias=False)(x)\n",
    "outputs = Lambda(lambda x: tf.nn.l2_normalize(x,axis=-1))(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,outputs)\n",
    "\n",
    "model.compile(loss=triplet,\n",
    "              optimizer='adam',\n",
    "              metrics=[triplet_acc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 883s 2s/step - loss: 7.8938 - triplet_acc: 0.6021 - val_loss: 8.2109 - val_triplet_acc: 0.2188\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 876s 2s/step - loss: 6.6920 - triplet_acc: 0.6511 - val_loss: 7.6159 - val_triplet_acc: 0.4975\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 888s 2s/step - loss: 6.0420 - triplet_acc: 0.6675 - val_loss: 7.4567 - val_triplet_acc: 0.6262\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 878s 2s/step - loss: 5.1157 - triplet_acc: 0.6937 - val_loss: 5.9328 - val_triplet_acc: 0.6987\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 870s 2s/step - loss: 4.2930 - triplet_acc: 0.7044 - val_loss: 5.0008 - val_triplet_acc: 0.6850\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 871s 2s/step - loss: 3.8582 - triplet_acc: 0.7100 - val_loss: 4.3856 - val_triplet_acc: 0.7225\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 871s 2s/step - loss: 3.5194 - triplet_acc: 0.7272 - val_loss: 4.9373 - val_triplet_acc: 0.6600\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 886s 2s/step - loss: 3.3125 - triplet_acc: 0.7377 - val_loss: 5.2704 - val_triplet_acc: 0.6912\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 886s 2s/step - loss: 3.3010 - triplet_acc: 0.7403 - val_loss: 3.3565 - val_triplet_acc: 0.7188\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 870s 2s/step - loss: 2.9510 - triplet_acc: 0.7597 - val_loss: 5.4183 - val_triplet_acc: 0.5613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb32fee3dd8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    image_generator(filenames_train,labels_train,3*40),\n",
    "    steps_per_epoch=500,\n",
    "    epochs=10,\n",
    "    validation_data=image_generator(filenames_test,labels_test,3*40,False),\n",
    "    validation_steps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PATH_MODEL + '2019.04.10.dogfacenet_v12.'+str(0)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dogfacenet_v24\n",
    "emb_size = 32\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Add, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
    "\n",
    "inputs = Input(shape=(104, 104, 3))\n",
    "\n",
    "x = Conv2D(64, (7, 7), use_bias=False, activation='relu', padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "for layer in [64,64,128,256,512]:\n",
    "    # Batch normalization layer\n",
    "    x = Conv2D(layer, (3, 3), strides=(2,2), use_bias=False, activation='relu', padding='same')(x)\n",
    "    r = BatchNormalization()(x)\n",
    "    r = Dropout(0.25)(r)\n",
    "    \n",
    "    x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
    "    x = BatchNormalization()(x)\n",
    "    r = Add()([r,x])\n",
    "    r = Dropout(0.25)(r)\n",
    "    \n",
    "    x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([r,x])\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(emb_size, use_bias=False)(x)\n",
    "outputs = Lambda(lambda x: tf.nn.l2_normalize(x,axis=-1))(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,outputs)\n",
    "\n",
    "model.compile(loss=triplet,\n",
    "              optimizer='adam',\n",
    "              metrics=[triplet_acc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dogfacenet_v23\n",
    "emb_size = 32\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Add, Concatenate, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
    "\n",
    "inputs = Input(shape=(104, 104, 3))\n",
    "\n",
    "x = Conv2D(64, (7, 7), use_bias=False, activation='relu', padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "for layer in [64,128,512,1024]:\n",
    "    # Batch normalization layer\n",
    "    x = Conv2D(layer, (3, 3), strides=(2,2), use_bias=False, activation='relu', padding='same')(x)\n",
    "    r = BatchNormalization()(x)\n",
    "    r = Dropout(0.25)(r)\n",
    "    \n",
    "    for i in range(2):\n",
    "        gsize = layer//32\n",
    "        branch = []\n",
    "        for group in range(32):\n",
    "            x = Conv2D(gsize, (1, 1), use_bias=False, padding='same')(r)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Conv2D(gsize, (3, 3), use_bias=False, activation='relu', padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "            \n",
    "            branch += [x]\n",
    "        \n",
    "        x = Concatenate()(branch)\n",
    "        x = Conv2D(layer, (1, 1), use_bias=False, activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Add()([r,x])\n",
    "        r = Dropout(0.25)(x)\n",
    "    \n",
    "\n",
    "x = GlobalAveragePooling2D()(r)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(emb_size, use_bias=False)(x)\n",
    "outputs = Lambda(lambda x: tf.nn.l2_normalize(x,axis=-1))(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,outputs)\n",
    "\n",
    "model.compile(loss=triplet,\n",
    "              optimizer='adam',\n",
    "              metrics=[triplet_acc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dogfacenet_v18\n",
    "emb_size = 32\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Add, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
    "\n",
    "inputs = Input(shape=(104, 104, 3))\n",
    "\n",
    "x = Conv2D(32, (7, 7), use_bias=False, activation='relu', padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "for layer in [32,32,64,128,512]:\n",
    "    \n",
    "    for channel in range(4):\n",
    "    x = Conv2D(layer, (3, 3), strides=(2,2), use_bias=False, activation='relu', padding='same')(x)\n",
    "    r = BatchNormalization()(x)\n",
    "    r = Dropout(0.25)(r)\n",
    "    \n",
    "    x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
    "    x = BatchNormalization()(x)\n",
    "    r = Add()([r,x])\n",
    "    r = Dropout(0.25)(r)\n",
    "    \n",
    "    x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([r,x])\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(emb_size, use_bias=False)(x)\n",
    "outputs = Lambda(lambda x: tf.nn.l2_normalize(x,axis=-1))(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,outputs)\n",
    "\n",
    "model.compile(loss=triplet,\n",
    "              optimizer='adam',\n",
    "              metrics=[triplet_acc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dogfacenet_v20\n",
    "# close to official resnet with identity blocks\n",
    "emb_size = 32\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Add, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
    "\n",
    "inputs = Input(shape=(104, 104, 3))\n",
    "\n",
    "x = Conv2D(16, (7, 7), use_bias=False, activation='relu', padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "layers = [16,32,64,128,512,1024]\n",
    "\n",
    "for i in range(len(layers)-1):\n",
    "    layer = layers[i]\n",
    "    layer2 = layers[i+1]\n",
    "    \n",
    "    x = Conv2D(layer2, (3, 3), strides=(2,2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    r = Activation('relu')(x)\n",
    "    \n",
    "    # Resnet blocks\n",
    "    for j in range(2):\n",
    "        x = Conv2D(layer, (1, 1), padding='same')(r)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(layer, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(layer2, (1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Add()([r,x])\n",
    "        x = Activation('relu')(x)\n",
    "        r = Dropout(0.25)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(r)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(emb_size, use_bias=False)(x)\n",
    "outputs = Lambda(lambda x: tf.nn.l2_normalize(x,axis=-1))(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,outputs)\n",
    "\n",
    "model.compile(loss=triplet,\n",
    "              optimizer='adam',\n",
    "              metrics=[triplet_acc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dogfacenet_v21\n",
    "# close to official resneXt with identity blocks\n",
    "emb_size = 32\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Add, Concatenate, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
    "\n",
    "inputs = Input(shape=(104, 104, 3))\n",
    "\n",
    "x = Conv2D(32, (7, 7), use_bias=False, activation='relu', padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "layers = [32,64,128,512,1024,2048]\n",
    "\n",
    "for i in range(len(layers)-1):\n",
    "    layer = layers[i]\n",
    "    layer2 = layers[i+1]\n",
    "    \n",
    "    x = Conv2D(layer2, (3, 3), strides=(2,2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    r = Activation('relu')(x)\n",
    "    \n",
    "    # ResneXt blocks, group 16\n",
    "    for j in range(2):\n",
    "        ksize = layer//16\n",
    "        branch_res = []\n",
    "        \n",
    "        for k in range(16):\n",
    "            x = Conv2D(ksize, (1, 1), padding='same')(r)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            x = Conv2D(ksize, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "            \n",
    "            branch_res += [x]\n",
    "        \n",
    "        x = Concatenate()(branch_res)\n",
    "        x = Conv2D(layer2, (1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Add()([r,x])\n",
    "        x = Activation('relu')(x)\n",
    "        r = Dropout(0.25)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(r)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(emb_size, use_bias=False)(x)\n",
    "outputs = Lambda(lambda x: tf.nn.l2_normalize(x,axis=-1))(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,outputs)\n",
    "\n",
    "model.compile(loss=triplet,\n",
    "              optimizer='adam',\n",
    "              metrics=[triplet_acc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(PATH_MODEL + '2019.02.28.dogfacenet_v12.hard_triplet.alpha.0.3.2.h5', custom_objects={'triplet':triplet,'triplet_acc':triplet_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(PATH_MODEL + '2019.02.14.dogfacenet_v11.hard_triplet_trained.data_aug.20.h5', custom_objects={'triplet':triplet,'triplet_acc':triplet_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(PATH_MODEL + '2019.02.27.dogfacenet_v11.hard_triplet_trained.data_aug_2.16.h5', custom_objects={'triplet':triplet,'triplet_acc':triplet_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(triplet_test,y_triplet_test, batch_size=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FileLink(PATH_MODEL + '2019.02.28.dogfacenet_v12.hard_triplet.alpha.0.3.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink(PATH_MODEL + '2019.02.28.dogfacenet_v12.hard_triplet.alpha.0.50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink(PATH_SAVE + '2018.02.27.dogfacenet_v11.hard_triplet.data_aug.10.a_0.3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PATH_MODEL + '2019.02.12.hard_triplet_trained.data_aug.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "triplet_train, y_triplet_train = define_triplets(images_train,labels_train)\n",
    "triplet_test, y_triplet_test = define_triplets(images_test,labels_test,1000*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str((3*len(predict_train)+3*(nbof_classes//10 + 1),h,w,c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_images_train\n",
    "del new_labels_train\n",
    "del predict_train\n",
    "del triplet_train, y_triplet_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_images_train, new_labels_train = shuffle_classes(images_train,labels_train)\n",
    "predict_train=model.predict(new_images_train)\n",
    "triplet_train, y_triplet_train = define_hard_triplets(new_images_train,new_labels_train,predict_train,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    history = model.fit(\n",
    "        triplet_train,\n",
    "        y_triplet_train,\n",
    "        batch_size = 21*3,\n",
    "        epochs = 1,\n",
    "        validation_data=(triplet_test,y_triplet_test),\n",
    "        shuffle=False\n",
    "    )\n",
    "    histories += [history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PATH_MODEL + '2019.04.08.dogfacenet_v12.'+str(1)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories2 = [histories[i] for i in range(29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(PATH_MODEL + '2019.02.27.dogfacenet_v11.hard_triplet_trained.data_aug.6.h5', custom_objects={'triplet':triplet,'triplet_acc':triplet_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    history = model.fit(\n",
    "        triplet_train,\n",
    "        y_triplet_train,\n",
    "        batch_size = 21*3,\n",
    "        epochs = 1,\n",
    "        validation_data=(triplet_test,y_triplet_test),\n",
    "        shuffle=False\n",
    "    )\n",
    "    histories2 += [history]\n",
    "model.save(PATH_MODEL + '2019.02.27.dogfacenet_v11.hard_triplet_trained.data_aug.'+str(16)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = histories[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=triplet,\n",
    "              optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "              metrics=[triplet_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 14*3 epochs with lr=0.001\n",
    "- 4*3 epochs with lr=0.0005\n",
    "- 4*3 epochs with lr=0.0003\n",
    "- 4*1 epochs with lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.save(PATH_MODEL + '2019.02.28.dogfacenet_v22.hard_triplet.alpha.0.3.'+str(l)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = [14,4,4,4]\n",
    "lr = [0.001,0.0005,0.0003,0.0001]\n",
    "for l in range(1,len(lr)):\n",
    "    model.compile(loss=triplet,\n",
    "              optimizer=tf.keras.optimizers.Adam(lr[l]),\n",
    "              metrics=[triplet_acc])\n",
    "    for k in range(epochs[l]):\n",
    "        epoch_nb = k+sum(epochs[:l])\n",
    "        print(\"Beginning epoch number: \"+str(epoch_nb)+\", over \"+str(sum(epochs))+\" epochs. \\n\")\n",
    "\n",
    "        \n",
    "        new_images_train, new_labels_train = shuffle_classes(images_train,labels_train)\n",
    "        predict_train=model.predict(new_images_train)\n",
    "        triplet_train, y_triplet_train = define_hard_triplets(new_images_train,new_labels_train,predict_train,10,3)\n",
    "\n",
    "        for i in range(6):\n",
    "            history = model.fit(\n",
    "                triplet_train,\n",
    "                y_triplet_train,\n",
    "                batch_size = 21*3,\n",
    "                epochs = 1,\n",
    "                validation_data=(triplet_test,y_triplet_test),\n",
    "                shuffle=False\n",
    "            )\n",
    "            histories += [history]\n",
    "        \n",
    "        del new_images_train, new_labels_train, predict_train, triplet_train, y_triplet_train\n",
    "        gc.collect()\n",
    "        model.save(PATH_MODEL + '2019.04.08.dogfacenet_v12.'+str(k)+'.h5')\n",
    "\n",
    "        loss = np.empty(0)\n",
    "        val_loss = np.empty(0)\n",
    "        acc = np.empty(0)\n",
    "        val_acc = np.empty(0)\n",
    "\n",
    "        for history in histories:\n",
    "            loss = np.append(loss,history.history['loss'])\n",
    "            val_loss = np.append(val_loss,history.history['val_loss'])\n",
    "            acc = np.append(acc,history.history['triplet_acc'])\n",
    "            val_acc = np.append(val_acc,history.history['val_triplet_acc'])\n",
    "\n",
    "\n",
    "        history_ = np.array([loss,val_loss,acc,val_acc])\n",
    "        np.save(PATH_SAVE+'2019.04.08.dogfacenet_v12.npy',history_)\n",
    "        np.savetxt(PATH_SAVE+'2019.04.08.dogfacenet_v12.txt',history_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PATH_MODEL + '2019.02.28.dogfacenet_v24.hard_triplet.alpha.0.3.'+str(0)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ = np.load(PATH_SAVE+'2018.02.28.dogfacenet_v12.hard_triplet.data_aug.5.a_0.3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,val_loss,acc,val_acc = history_\n",
    "\n",
    "epochs = np.arange(len(loss))\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs,loss, '-o', label=\"loss\")\n",
    "plt.plot(epochs,val_loss, '-o', label=\"val loss\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.yticks(np.arange(0,8,1))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs,acc, '-o', label=\"acc\")\n",
    "plt.plot(epochs,val_acc, '-o', label=\"val acc\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = np.empty(0)\n",
    "val_loss = np.empty(0)\n",
    "acc = np.empty(0)\n",
    "val_acc = np.empty(0)\n",
    "\n",
    "for history in histories:\n",
    "    loss = np.append(loss,history.history['loss'])\n",
    "    val_loss = np.append(val_loss,history.history['val_loss'])\n",
    "    acc = np.append(acc,history.history['triplet_acc'])\n",
    "    val_acc = np.append(val_acc,history.history['val_triplet_acc'])\n",
    "\n",
    "    \n",
    "history_ = np.array([loss,val_loss,acc,val_acc])\n",
    "np.save(PATH_SAVE+'2018.02.28.dogfacenet_v24.hard_triplet.data_aug.0.a_0.3.npy',history_)\n",
    "np.savetxt(PATH_SAVE+'2018.02.28.dogfacenet_v24.hard_triplet.data_aug.0.a_0.3.txt',history_)\n",
    "\n",
    "epochs = np.arange(len(loss))\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs,loss, '-o', label=\"loss\")\n",
    "plt.plot(epochs,val_loss, '-o', label=\"val_loss\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.yticks(np.arange(0,8,1))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs,acc, '-o', label=\"acc\")\n",
    "plt.plot(epochs,val_acc, '-o', label=\"val_acc\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    new_images_train, new_labels_train = shuffle_classes(images_train,labels_train)\n",
    "    predict_train=model.predict(new_images_train)\n",
    "    triplet_train, y_triplet_train = define_hard_triplets(new_images_train,new_labels_train,predict_train)\n",
    "\n",
    "    model.fit(\n",
    "        triplet_train,\n",
    "        y_triplet_train,\n",
    "        batch_size = 21*3,\n",
    "        epochs = 1,\n",
    "        validation_data=(triplet_test,y_triplet_test),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    model.save(PATH_MODEL + '2019.02.14.dogfacenet_v11.hard_triplet_trained.data_aug.'+str(i+16)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_images_train, new_labels_train = shuffle_classes(images_train,labels_train)\n",
    "predict_train=model.predict(new_images_train)\n",
    "triplet_train, y_triplet_train = define_hard_triplets(new_images_train,new_labels_train,predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=model.fit(\n",
    "    triplet_train,\n",
    "    y_triplet_train,\n",
    "    batch_size = 21*3,\n",
    "    epochs = 1,\n",
    "    validation_data=(triplet_test,y_triplet_test),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PATH_MODEL + '2019.02.14.dogfacenet_v11.hard_triplet_trained.data_aug.6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.empty(0)\n",
    "val_loss = np.empty(0)\n",
    "acc = np.empty(0)\n",
    "val_acc = np.empty(0)\n",
    "\n",
    "loss = np.append(loss,history.history['loss'])\n",
    "val_loss = np.append(val_loss,history.history['val_loss'])\n",
    "acc = np.append(acc,history.history['triplet_acc'])\n",
    "val_acc = np.append(val_acc,history.history['val_triplet_acc'])\n",
    "    \n",
    "    \n",
    "history_ = np.array([loss,val_loss,acc,val_acc])\n",
    "np.save(PATH_SAVE+'2018.02.12.dogfacenet_v6.hard_triplet.data_aug.0.a_0.3.npy',history_)\n",
    "np.savetxt(PATH_SAVE+'2018.02.12.dogfacenet_v6.hard_triplet.data_aug.0.a_0.3.txt',history_)\n",
    "\n",
    "epochs = np.arange(len(loss))\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs,loss, '-o', label=\"loss\")\n",
    "plt.plot(epochs,val_loss, '-o', label=\"val_loss\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs,acc, '-o', label=\"acc\")\n",
    "plt.plot(epochs,val_acc, '-o', label=\"val_acc\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histories = []\n",
    "nbof_cycles = 9\n",
    "for i in range(0,nbof_cycles,1):\n",
    "\n",
    "    history=model.fit(\n",
    "        triplet_train,\n",
    "        y_triplet_train,\n",
    "        batch_size = 21*3,\n",
    "        epochs = nbof_cycles-i,\n",
    "        validation_data=(triplet_test,y_triplet_test),\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    histories += [history]\n",
    "    model.save(PATH_MODEL + '2019.02.14.dogfacenet_v10.hard_triplet_trained.data_aug.' + str(i+1) + '.h5')\n",
    "    \n",
    "    new_images_train, new_labels_train = shuffle_classes(images_train,labels_train)\n",
    "    predict_train=model.predict(new_images_train)\n",
    "    triplet_train, y_triplet_train = define_hard_triplets(new_images_train,new_labels_train,predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.empty(0)\n",
    "val_loss = np.empty(0)\n",
    "acc = np.empty(0)\n",
    "val_acc = np.empty(0)\n",
    "\n",
    "for i in range(len(histories)):\n",
    "    history = histories[i]\n",
    "    \n",
    "    loss = np.append(loss,history.history['loss'])\n",
    "    val_loss = np.append(val_loss,history.history['val_loss'])\n",
    "    acc = np.append(acc,history.history['triplet_acc'])\n",
    "    val_acc = np.append(val_acc,history.history['val_triplet_acc'])\n",
    "    \n",
    "    \n",
    "history_ = np.array([loss,val_loss,acc,val_acc])\n",
    "np.save(PATH_SAVE+'2018.02.13.dogfacenet_v9.hard_triplet.2.a_0.3.npy',history_)\n",
    "np.savetxt(PATH_SAVE+'2018.02.13.dogfacenet_v9.hard_triplet.2.a_0.3.txt',history_)\n",
    "\n",
    "epochs = np.arange(len(loss))\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs,loss, '-o', label=\"loss\")\n",
    "plt.plot(epochs,val_loss, '-o', label=\"val_loss\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs,acc, '-o', label=\"acc\")\n",
    "plt.plot(epochs,val_acc, '-o', label=\"val_acc\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on new triplet integrity\n",
    "print(new_y_triplet_train[-30:])\n",
    "t = np.equal(new_y_triplet_train[0::3],new_y_triplet_train[1::3])\n",
    "print(t)\n",
    "np.sum(t.astype(np.float32))/len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on verification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBOF_PAIRS = 5000\n",
    "#NBOF_PAIRS = len(images_test)\n",
    "\n",
    "# Create pairs\n",
    "h,w,c = SIZE\n",
    "pairs = np.empty((NBOF_PAIRS*2,h,w,c))\n",
    "issame = np.empty(NBOF_PAIRS)\n",
    "class_test = np.unique(labels_test)\n",
    "for i in range(NBOF_PAIRS):\n",
    "    alea = np.random.rand()\n",
    "    # Pair of different dogs\n",
    "    if alea < 0.5:\n",
    "        # Chose the classes:\n",
    "        class1 = np.random.randint(len(class_test))\n",
    "        class2 = np.random.randint(len(class_test))\n",
    "        while class1==class2:\n",
    "            class2 = np.random.randint(len(class_test))\n",
    "            \n",
    "        # Extract images of this class:\n",
    "        images_class1 = images_test[np.equal(labels_test,class1)]\n",
    "        images_class2 = images_test[np.equal(labels_test,class2)]\n",
    "        \n",
    "        # Chose an image amoung these selected images\n",
    "        pairs[i*2] = images_class1[np.random.randint(len(images_class1))]\n",
    "        pairs[i*2+1] = images_class2[np.random.randint(len(images_class2))]\n",
    "        issame[i] = 0\n",
    "    # Pair of same dogs\n",
    "    else:\n",
    "        # Chose a class\n",
    "        clas = np.random.randint(len(class_test))\n",
    "        images_class = images_test[np.equal(labels_test,clas)]\n",
    "        \n",
    "        # Select two images from this class\n",
    "        idx_image1 = np.random.randint(len(images_class))\n",
    "        idx_image2 = np.random.randint(len(images_class))\n",
    "        while idx_image1 == idx_image2:\n",
    "            idx_image2 = np.random.randint(len(images_class))\n",
    "        \n",
    "        pairs[i*2] = images_class[idx_image1]\n",
    "        pairs[i*2+1] = images_class[idx_image2]\n",
    "        issame[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test: Check the pairs\n",
    "s = 10\n",
    "n = 5\n",
    "print(issame[s:(n+s)])\n",
    "fig = plt.figure(figsize=(5,3*n))\n",
    "for i in range(s,s+n):\n",
    "    plt.subplot(n,2,2*(i-s)+1)\n",
    "    plt.imshow(pairs[2*i]*0.5+0.5)\n",
    "    plt.subplot(n,2,2*(i-s)+2)\n",
    "    plt.imshow(pairs[2*i+1]*0.5+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model.predict(pairs)\n",
    "# Separates the pairs\n",
    "emb1 = predict[0::2]\n",
    "emb2 = predict[1::2]\n",
    "\n",
    "# Computes distance between pairs\n",
    "diff = np.square(emb1-emb2)\n",
    "dist = np.sum(diff,1)\n",
    "\n",
    "\n",
    "best = 0\n",
    "best_t = 0\n",
    "thresholds = np.arange(0.001,4,0.001)\n",
    "for i in tqdm_notebook(range(len(thresholds))):\n",
    "    less = np.less(dist, thresholds[i])\n",
    "    acc = np.logical_not(np.logical_xor(less, issame))\n",
    "    acc = acc.astype(float)\n",
    "    out = np.sum(acc)\n",
    "    out = out/len(acc)\n",
    "    if out > best:\n",
    "        best_t = thresholds[i]\n",
    "        best = out\n",
    "\n",
    "print(\"Best threshold: \" + str(best_t))\n",
    "print(\"Best accuracy: \" + str(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False accepted examples and False rejected examples\n",
    "t = 0.68\n",
    "fa = []\n",
    "fr = []\n",
    "for i in range(len(dist)):\n",
    "    # false accepted\n",
    "    if issame[i] == 0 and dist[i]<t:\n",
    "        fa += [i]\n",
    "    if issame[i] == 1 and dist[i]>t:\n",
    "        fr += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Look at wrong pairs\n",
    "s = 10\n",
    "sr = 20\n",
    "n = 5\n",
    "print(issame[s:(n+s)])\n",
    "fig = plt.figure(figsize=(11,2.8*n))\n",
    "for i in range(s,s+n):\n",
    "    # False accepted\n",
    "    plt.subplot(n,4,4*(i-s)+1)\n",
    "    plt.imshow(pairs[2*fa[i+s]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(n,4,4*(i-s)+2)\n",
    "    plt.imshow(pairs[2*fa[i+s]+1])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(n,4,4*(i-s)+3)\n",
    "    plt.imshow(pairs[2*fr[i+sr]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(n,4,4*(i-s)+4)\n",
    "    plt.imshow(pairs[2*fr[i+sr]+1])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "less = np.less(dist, threshold)\n",
    "acc = np.logical_not(np.logical_xor(less, issame))\n",
    "acc = acc.astype(float)\n",
    "out = np.sum(acc)\n",
    "out = out/len(acc)\n",
    "\n",
    "print(\"Accuracy: \" + str(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tf.keras.Model(model.layers[0].input, model.layers[-1].output)\n",
    "predict=mod.predict(pairs)\n",
    "# Separates the pairs\n",
    "emb1 = predict[0::2]\n",
    "emb2 = predict[1::2]\n",
    "\n",
    "# Computes distance between pairs\n",
    "diff = np.square(emb1-emb2)\n",
    "dist = np.sum(diff,1)\n",
    "\n",
    "# Computes the ROC depending on different thresholds\n",
    "\n",
    "thresholds = np.arange(0.001,4,0.001)\n",
    "tprs = np.empty(len(thresholds))\n",
    "fprs = np.empty(len(thresholds))\n",
    "\n",
    "p = np.sum(issame.astype(float))\n",
    "n = np.sum(np.logical_not(issame).astype(float))\n",
    "\n",
    "for i in tqdm_notebook(range(len(thresholds))):\n",
    "    logical_pred = np.less(dist, thresholds[i])\n",
    "    tp = np.sum(np.logical_and(logical_pred,issame).astype(float))\n",
    "    fp = np.sum(np.logical_and(logical_pred,np.logical_not(issame)).astype(float))\n",
    "    tprs[i] = tp/p\n",
    "    fprs[i] = fp/n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('roc_dogfacenet_v11.npy', [tprs, fprs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs2,fprs2 = np.load('roc_dogfacenet_v12.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(fprs,tprs,label=\"VGG-like\")\n",
    "plt.plot(fprs2,tprs2,label=\"ResNet-like\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xticks(np.arange(0,1.1,0.1))\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "#plt.title(\"ROC curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second verification task: IN or OUT? actually I think that this task doesn't make any sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbof_try = 30 # We will do many try on the test dataset to obtain a more precize accuracy\n",
    "\n",
    "for propo in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    print(\"Current propotion of classes considered: \" + str(propo))\n",
    "    \n",
    "    mean_acc = 0\n",
    "    max_acc = 0\n",
    "    min_acc = 1\n",
    "    mean_t = 0\n",
    "    \n",
    "    for _ in tqdm_notebook(range(nbof_try)):\n",
    "        nbof_kimages=int(propo*len(np.unique(labels_test)))\n",
    "        kpred=np.empty((nbof_kimages,pred_test.shape[-1]))\n",
    "        y_kimages = np.unique(labels_test)[:nbof_kimages]\n",
    "\n",
    "        others_pred = np.copy(pred_test)\n",
    "        y_others = np.copy(labels_test)\n",
    "\n",
    "        for i in range(nbof_kimages):\n",
    "            keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i],y_others)]\n",
    "            choice = np.random.randint(len(keep_classes_images))\n",
    "\n",
    "            kpred[i] = others_pred[keep_classes_images[choice]]\n",
    "\n",
    "            others_pred = np.delete(others_pred,keep_classes_images[choice],0)\n",
    "            y_others = np.delete(y_others,keep_classes_images[choice],0)\n",
    "\n",
    "        # We find the best threshold for this dataset\n",
    "        best_acc = 0\n",
    "        best_t = 0.01\n",
    "        for threshold in np.arange(0.01,1,0.01):\n",
    "\n",
    "            acc = 0\n",
    "\n",
    "            class_pred = np.empty(len(others_pred))\n",
    "\n",
    "            for i in range(len(others_pred)):\n",
    "                # computes distance with the key dataset\n",
    "                dist = np.sum(np.square(kpred-others_pred[i]),1)\n",
    "                if np.min(dist) < threshold:\n",
    "                    if y_others[i] in y_kimages:\n",
    "                        acc += 1\n",
    "                else:\n",
    "                    if not y_others[i] in y_kimages:\n",
    "                        acc += 1\n",
    "            acc /= len(others_pred)\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_t = threshold\n",
    "\n",
    "        mean_acc += best_acc\n",
    "        mean_t += best_t\n",
    "        \n",
    "        if best_acc > max_acc:\n",
    "            max_acc = best_acc\n",
    "        if best_acc < min_acc:\n",
    "            min_acc = best_acc\n",
    "        \n",
    "    mean_acc /= nbof_try\n",
    "    \n",
    "    mean_t /= nbof_try\n",
    "    print(\"Mean accuracy for in/out: \" + str(mean_acc))\n",
    "    print(\"Max accuracy for in/out: \" + str(max_acc))\n",
    "    print(\"Min accuracy for in/out: \" + str(min_acc))\n",
    "    print(\"Mean threshold for in/out: \" + str(mean_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tf.keras.Model(model.layers[0].input, model.layers[-1].output)\n",
    "predict=mod.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=len(np.unique(labels_test)),max_iter=2000, random_state=0,tol=0.2).fit(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_cluster = [images_test[np.equal(kmeans.labels_,i)] for i in range(len(labels_test))]\n",
    "labels_cluster = [labels_test[np.equal(kmeans.labels_,i)] for i in range(len(labels_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "length = len(images_cluster[i])\n",
    "fig=plt.figure(figsize=(5,5))\n",
    "for j in range(3):\n",
    "    for k in range(3):\n",
    "        plt.subplot(3,3,j*3+k+1)\n",
    "        plt.imshow(images_cluster[i][j*3+k])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "#fig.savefig('D:/CREATIONS/PAPERS/DogFaceNet/clustering/dfn12.clustering.1000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(images_cluster)):\n",
    "    length = len(images_cluster[i])\n",
    "    if length > 0:\n",
    "        print(labels_cluster[i])\n",
    "        fig=plt.figure(figsize=(length*2,2))\n",
    "        for j in range(length):\n",
    "            plt.subplot(1,length,j+1)\n",
    "            plt.imshow(images_cluster[i][j])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        plt.show()\n",
    "        #fig.savefig('D:/CREATIONS/PAPERS/DogFaceNet/clustering/dfn12.clustering.'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition: K-NN\n",
    "m is the number of images that are going to be selected for k-NN \"training\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_im_c = np.zeros(len(np.unique(labels_test)))\n",
    "for i in range(len(labels_test)):\n",
    "    count_im_c[int(labels_test[i])] += 1\n",
    "print(\"Number of images per classes:\")\n",
    "count_im_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1,5):\n",
    "    \n",
    "    # First we drop the classes with less than m images per class:\n",
    "    to_drop = []\n",
    "    for i in range(len(count_im_c)):\n",
    "        if count_im_c[i] <= m:\n",
    "            to_drop += [i]\n",
    "    new_labels_test = np.copy(labels_test)\n",
    "    new_images_test = np.copy(images_test)\n",
    "    for i in range(len(to_drop)):\n",
    "        idx_to_drop = np.arange(len(new_labels_test))[np.equal(to_drop[i],new_labels_test)]\n",
    "        new_labels_test=np.delete(new_labels_test, idx_to_drop, 0)\n",
    "        new_images_test=np.delete(new_images_test, idx_to_drop, 0)\n",
    "    np.unique(new_labels_test)\n",
    "    \n",
    "    # Model prediction on the reduce dataset\n",
    "    new_pred_test = model.predict(new_images_test)\n",
    "\n",
    "    nbof_test = 1000\n",
    "    mean_acc = 0\n",
    "    mini = 1\n",
    "    maxi = 0\n",
    "    \n",
    "    # Definition of K\n",
    "    if m == 1:\n",
    "        K = 1\n",
    "    else:\n",
    "        K = m+1\n",
    "\n",
    "    for _ in tqdm_notebook(range(nbof_test)):\n",
    "        # I select m images per classes for k-NN training\n",
    "        nbof_kimages=m*len(np.unique(new_labels_test))\n",
    "        kpred=np.empty((nbof_kimages,new_pred_test.shape[-1]))\n",
    "        y_kimages = np.empty(nbof_kimages, dtype=int)\n",
    "        y_kuniques = np.unique(new_labels_test)\n",
    "        for i in range(len(y_kuniques)):\n",
    "            for j in range(m):\n",
    "                y_kimages[i*m+j] = y_kuniques[i]\n",
    "\n",
    "        others_pred = np.copy(new_pred_test)\n",
    "        y_others = np.copy(new_labels_test)\n",
    "\n",
    "        for i in range(len(y_kuniques)):\n",
    "            keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i*m],y_others)]\n",
    "            choices = np.empty(0,dtype=int)\n",
    "\n",
    "            if len(keep_classes_images) <= m:\n",
    "                print(\"Bug!\")\n",
    "                break\n",
    "\n",
    "            for j in range(m):\n",
    "                choice = np.random.randint(len(keep_classes_images))\n",
    "                while choice in choices:\n",
    "                    choice = np.random.randint(len(keep_classes_images))\n",
    "                choices=np.append(choices,choice)\n",
    "            #print(choices)\n",
    "            for j in range(m):\n",
    "                kpred[i*m+j] = others_pred[keep_classes_images[choices[j]]]\n",
    "\n",
    "            others_pred = np.delete(others_pred,keep_classes_images[choices],0)\n",
    "            y_others = np.delete(y_others,keep_classes_images[choices],0)\n",
    "\n",
    "        neigh = KNeighborsClassifier(n_neighbors=K, weights='distance')\n",
    "        neigh.fit(kpred, y_kimages)\n",
    "        acc = np.sum(np.equal(y_others,neigh.predict(others_pred)))/len(y_others)\n",
    "\n",
    "        if mini > acc:\n",
    "            mini = acc\n",
    "        if maxi < acc:\n",
    "            maxi = acc\n",
    "\n",
    "        mean_acc += acc\n",
    "    mean_acc /= nbof_test\n",
    "    print(\"Mean accuracy: \" + str(mean_acc))\n",
    "    print(\"Maximum accuracy: \" + str(maxi))\n",
    "    print(\"Minimum accuracy: \" + str(mini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbof_test = 1000\n",
    "mean_acc = 0\n",
    "mini = 1\n",
    "maxi = 0\n",
    "if m == 1:\n",
    "    K = 1\n",
    "else:\n",
    "    K = m+1\n",
    "\n",
    "for _ in tqdm_notebook(range(nbof_test)):\n",
    "    # Second we select m images per classes for k-NN training\n",
    "    nbof_kimages=m*len(np.unique(new_labels_test))\n",
    "    kpred=np.empty((nbof_kimages,new_pred_test.shape[-1]))\n",
    "    y_kimages = np.empty(nbof_kimages, dtype=int)\n",
    "    y_kuniques = np.unique(new_labels_test)\n",
    "    for i in range(len(y_kuniques)):\n",
    "        for j in range(m):\n",
    "            y_kimages[i*m+j] = y_kuniques[i]\n",
    "\n",
    "    others_pred = np.copy(new_pred_test)\n",
    "    y_others = np.copy(new_labels_test)\n",
    "\n",
    "    for i in range(len(y_kuniques)):\n",
    "        keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i*m],y_others)]\n",
    "        choices = np.empty(0,dtype=int)\n",
    "\n",
    "        if len(keep_classes_images) <= m:\n",
    "            print(\"Bug!\")\n",
    "            break\n",
    "\n",
    "        for j in range(m):\n",
    "            choice = np.random.randint(len(keep_classes_images))\n",
    "            while choice in choices:\n",
    "                choice = np.random.randint(len(keep_classes_images))\n",
    "            choices=np.append(choices,choice)\n",
    "        #print(choices)\n",
    "        for j in range(m):\n",
    "            kpred[i*m+j] = others_pred[keep_classes_images[choices[j]]]\n",
    "\n",
    "        others_pred = np.delete(others_pred,keep_classes_images[choices],0)\n",
    "        y_others = np.delete(y_others,keep_classes_images[choices],0)\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=K, weights='distance')\n",
    "    neigh.fit(kpred, y_kimages)\n",
    "    acc = np.sum(np.equal(y_others,neigh.predict(others_pred)))/len(y_others)\n",
    "    \n",
    "    if mini > acc:\n",
    "        mini = acc\n",
    "    if maxi < acc:\n",
    "        maxi = acc\n",
    "    \n",
    "    mean_acc += acc\n",
    "mean_acc /= nbof_test\n",
    "print(\"Mean accuracy: \" + str(mean_acc))\n",
    "print(\"Maximum accuracy: \" + str(maxi))\n",
    "print(\"Minimum accuracy: \" + str(mini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition: k-NN top 1/2/3/4/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_im_c = np.zeros(len(np.unique(labels_test)))\n",
    "for i in range(len(labels_test)):\n",
    "    count_im_c[int(labels_test[i])] += 1\n",
    "print(\"Number of images per classes:\")\n",
    "count_im_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rk = 5 # Top \"max_rk\" accuracy\n",
    "\n",
    "for m in range(1,5):\n",
    "    # First we drop the classes with less than m images per class:\n",
    "    to_drop = []\n",
    "    for i in range(len(count_im_c)):\n",
    "        if count_im_c[i] <= m:\n",
    "            to_drop += [i]\n",
    "    new_labels_test = np.copy(labels_test)\n",
    "    new_images_test = np.copy(images_test)\n",
    "    for i in range(len(to_drop)):\n",
    "        idx_to_drop = np.arange(len(new_labels_test))[np.equal(to_drop[i],new_labels_test)]\n",
    "        new_labels_test=np.delete(new_labels_test, idx_to_drop, 0)\n",
    "        new_images_test=np.delete(new_images_test, idx_to_drop, 0)\n",
    "    np.unique(new_labels_test)\n",
    "\n",
    "    new_pred_test = model.predict(new_images_test)\n",
    "\n",
    "    nbof_test = 100\n",
    "    mean_acc = 0\n",
    "    mini = 1\n",
    "    maxi = 0\n",
    "\n",
    "    if m == 1:\n",
    "        K = 1\n",
    "    else:\n",
    "        K = m+1\n",
    "\n",
    "    for _ in tqdm_notebook(range(nbof_test)):\n",
    "        # Second we select m images per classes for k-NN training\n",
    "        nbof_kimages=m*len(np.unique(new_labels_test))\n",
    "        kpred=np.empty((nbof_kimages,new_pred_test.shape[-1]))\n",
    "        y_kimages = np.empty(nbof_kimages, dtype=int)\n",
    "        y_kuniques = np.unique(new_labels_test)\n",
    "        for i in range(len(y_kuniques)):\n",
    "            for j in range(m):\n",
    "                y_kimages[i*m+j] = y_kuniques[i]\n",
    "\n",
    "        others_pred = np.copy(new_pred_test)\n",
    "        y_others = np.copy(new_labels_test)\n",
    "\n",
    "        for i in range(len(y_kuniques)):\n",
    "            keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i*m],y_others)]\n",
    "            choices = np.empty(0,dtype=int)\n",
    "\n",
    "            if len(keep_classes_images) <= m:\n",
    "                print(\"Bug!\")\n",
    "                break\n",
    "\n",
    "            for j in range(m):\n",
    "                choice = np.random.randint(len(keep_classes_images))\n",
    "                while choice in choices:\n",
    "                    choice = np.random.randint(len(keep_classes_images))\n",
    "                choices=np.append(choices,choice)\n",
    "            #print(choices)\n",
    "            for j in range(m):\n",
    "                kpred[i*m+j] = others_pred[keep_classes_images[choices[j]]]\n",
    "\n",
    "            others_pred = np.delete(others_pred,keep_classes_images[choices],0)\n",
    "            y_others = np.delete(y_others,keep_classes_images[choices],0)\n",
    "\n",
    "        neigh = KNeighborsClassifier(n_neighbors=K, weights='distance')\n",
    "        neigh.fit(kpred, y_kimages)\n",
    "\n",
    "        rk1_pred_y_others = neigh.predict(others_pred)\n",
    "        pred_y_others = np.zeros((len(others_pred),max_rk))\n",
    "        for i in range(len(pred_y_others)):\n",
    "            pred_y_others[i][0] = rk1_pred_y_others[i]\n",
    "\n",
    "        for i in range(1,max_rk):\n",
    "            for j in range(len(pred_y_others)):\n",
    "                previous_pred = [pred_y_others[j][k] for k in range(0,i)]\n",
    "                to_keep = np.logical_not(np.equal(previous_pred[0],y_kimages))\n",
    "                for k in range(1,len(previous_pred)):\n",
    "                    to_keep = np.logical_and(to_keep, np.logical_not(np.equal(previous_pred[k],y_kimages)))\n",
    "                new_kpred = kpred[to_keep]\n",
    "                new_y_kimages = y_kimages[to_keep]\n",
    "\n",
    "                neigh.fit(new_kpred, new_y_kimages)\n",
    "\n",
    "                pred_y_others[j][i] = neigh.predict([others_pred[j]])\n",
    "\n",
    "        #acc = np.sum(np.equal(y_others,neigh.predict(others_pred)))/len(y_others)\n",
    "        acc = 0\n",
    "        for i in range(len(pred_y_others)):\n",
    "            if y_others[i] in pred_y_others[i]:\n",
    "                acc += 1\n",
    "        acc /= len(pred_y_others)\n",
    "\n",
    "        if mini > acc:\n",
    "            mini = acc\n",
    "        if maxi < acc:\n",
    "            maxi = acc\n",
    "\n",
    "        mean_acc += acc\n",
    "    mean_acc /= nbof_test\n",
    "    print(\"Mean accuracy: \" + str(mean_acc))\n",
    "    print(\"Maximum accuracy: \" + str(maxi))\n",
    "    print(\"Minimum accuracy: \" + str(mini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "# First we drop the classes with less than m images per class:\n",
    "to_drop = []\n",
    "for i in range(len(count_im_c)):\n",
    "    if count_im_c[i] <= m:\n",
    "        to_drop += [i]\n",
    "new_labels_test = np.copy(labels_test)\n",
    "new_images_test = np.copy(images_test)\n",
    "for i in range(len(to_drop)):\n",
    "    idx_to_drop = np.arange(len(new_labels_test))[np.equal(to_drop[i],new_labels_test)]\n",
    "    new_labels_test=np.delete(new_labels_test, idx_to_drop, 0)\n",
    "    new_images_test=np.delete(new_images_test, idx_to_drop, 0)\n",
    "np.unique(new_labels_test)\n",
    "\n",
    "new_pred_test = model.predict(new_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbof_test = 100\n",
    "mean_acc = 0\n",
    "mini = 1\n",
    "maxi = 0\n",
    "max_rk = 5\n",
    "\n",
    "if m == 1:\n",
    "    K = 1\n",
    "else:\n",
    "    K = m+1\n",
    "\n",
    "for _ in tqdm_notebook(range(nbof_test)):\n",
    "    # Second we select m images per classes for k-NN training\n",
    "    nbof_kimages=m*len(np.unique(new_labels_test))\n",
    "    kpred=np.empty((nbof_kimages,new_pred_test.shape[-1]))\n",
    "    y_kimages = np.empty(nbof_kimages, dtype=int)\n",
    "    y_kuniques = np.unique(new_labels_test)\n",
    "    for i in range(len(y_kuniques)):\n",
    "        for j in range(m):\n",
    "            y_kimages[i*m+j] = y_kuniques[i]\n",
    "\n",
    "    others_pred = np.copy(new_pred_test)\n",
    "    y_others = np.copy(new_labels_test)\n",
    "\n",
    "    for i in range(len(y_kuniques)):\n",
    "        keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i*m],y_others)]\n",
    "        choices = np.empty(0,dtype=int)\n",
    "\n",
    "        if len(keep_classes_images) <= m:\n",
    "            print(\"Bug!\")\n",
    "            break\n",
    "\n",
    "        for j in range(m):\n",
    "            choice = np.random.randint(len(keep_classes_images))\n",
    "            while choice in choices:\n",
    "                choice = np.random.randint(len(keep_classes_images))\n",
    "            choices=np.append(choices,choice)\n",
    "        #print(choices)\n",
    "        for j in range(m):\n",
    "            kpred[i*m+j] = others_pred[keep_classes_images[choices[j]]]\n",
    "\n",
    "        others_pred = np.delete(others_pred,keep_classes_images[choices],0)\n",
    "        y_others = np.delete(y_others,keep_classes_images[choices],0)\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=K, weights='distance')\n",
    "    neigh.fit(kpred, y_kimages)\n",
    "    \n",
    "    rk1_pred_y_others = neigh.predict(others_pred)\n",
    "    pred_y_others = np.zeros((len(others_pred),max_rk))\n",
    "    for i in range(len(pred_y_others)):\n",
    "        pred_y_others[i][0] = rk1_pred_y_others[i]\n",
    "\n",
    "    for i in range(1,max_rk):\n",
    "        for j in range(len(pred_y_others)):\n",
    "            previous_pred = [pred_y_others[j][k] for k in range(0,i)]\n",
    "            to_keep = np.logical_not(np.equal(previous_pred[0],y_kimages))\n",
    "            for k in range(1,len(previous_pred)):\n",
    "                to_keep = np.logical_and(to_keep, np.logical_not(np.equal(previous_pred[k],y_kimages)))\n",
    "            new_kpred = kpred[to_keep]\n",
    "            new_y_kimages = y_kimages[to_keep]\n",
    "            \n",
    "            neigh.fit(new_kpred, new_y_kimages)\n",
    "    \n",
    "            pred_y_others[j][i] = neigh.predict([others_pred[j]])\n",
    "\n",
    "    #acc = np.sum(np.equal(y_others,neigh.predict(others_pred)))/len(y_others)\n",
    "    acc = 0\n",
    "    for i in range(len(pred_y_others)):\n",
    "        if y_others[i] in pred_y_others[i]:\n",
    "            acc += 1\n",
    "    acc /= len(pred_y_others)\n",
    "    \n",
    "    if mini > acc:\n",
    "        mini = acc\n",
    "    if maxi < acc:\n",
    "        maxi = acc\n",
    "    \n",
    "    mean_acc += acc\n",
    "mean_acc /= nbof_test\n",
    "print(\"Mean accuracy: \" + str(mean_acc))\n",
    "print(\"Maximum accuracy: \" + str(maxi))\n",
    "print(\"Minimum accuracy: \" + str(mini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-NN test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3\n",
    "# First we drop the classes with less than m images per class:\n",
    "to_drop = []\n",
    "for i in range(len(count_im_c)):\n",
    "    if count_im_c[i] <= m:\n",
    "        to_drop += [i]\n",
    "new_labels_test = np.copy(labels_test)\n",
    "new_images_test = np.copy(images_test)\n",
    "for i in range(len(to_drop)):\n",
    "    idx_to_drop = np.arange(len(new_labels_test))[np.equal(to_drop[i],new_labels_test)]\n",
    "    new_labels_test=np.delete(new_labels_test, idx_to_drop, 0)\n",
    "    new_images_test=np.delete(new_images_test, idx_to_drop, 0)\n",
    "np.unique(new_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_test = model.predict(new_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Second we select m images per classes for k-NN training\n",
    "nbof_kimages=m*len(np.unique(new_labels_test))\n",
    "kpred=np.empty((nbof_kimages,new_pred_test.shape[-1]))\n",
    "y_kimages = np.empty(nbof_kimages, dtype=int)\n",
    "y_kuniques = np.unique(new_labels_test)\n",
    "for i in range(len(y_kuniques)):\n",
    "    for j in range(m):\n",
    "        y_kimages[i*2+j] = y_kuniques[i]\n",
    "\n",
    "others_pred = np.copy(new_pred_test)\n",
    "y_others = np.copy(new_labels_test)\n",
    "\n",
    "for i in range(len(y_kuniques)):\n",
    "    keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i*2],y_others)]\n",
    "    choices = np.empty(0,dtype=int)\n",
    "    \n",
    "    if len(keep_classes_images) <= m:\n",
    "        print(\"Bug!\")\n",
    "        break\n",
    "        \n",
    "    for j in range(m):\n",
    "        choice = np.random.randint(len(keep_classes_images))\n",
    "        while choice in choices:\n",
    "            choice = np.random.randint(len(keep_classes_images))\n",
    "        choices=np.append(choices,choice)\n",
    "    #print(choices)\n",
    "    for j in range(m):\n",
    "        kpred[i*2+j] = others_pred[keep_classes_images[choices[j]]]\n",
    "\n",
    "    others_pred = np.delete(others_pred,keep_classes_images[choices],0)\n",
    "    y_others = np.delete(y_others,keep_classes_images[choices],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=m+1, weights='distance')\n",
    "neigh.fit(kpred, y_kimages)\n",
    "np.sum(np.equal(y_others,neigh.predict(others_pred)))/len(y_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "mean_acc = 0\n",
    "\n",
    "for j in tqdm_notebook(range(n)):\n",
    "    nbof_kimages=len(np.unique(new_labels_test))\n",
    "    kpred=np.empty((nbof_kimages,new_pred_test.shape[-1]))\n",
    "    y_kimages = np.unique(new_labels_test)[:nbof_kimages]\n",
    "\n",
    "    others_pred = np.copy(new_pred_test)\n",
    "    y_others = np.copy(new_labels_test)\n",
    "\n",
    "    for i in range(nbof_kimages):\n",
    "        keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i],y_others)]\n",
    "        choice = np.random.randint(len(keep_classes_images))\n",
    "\n",
    "        kpred[i] = others_pred[keep_classes_images[choice]]\n",
    "\n",
    "        others_pred = np.delete(others_pred,keep_classes_images[choice],0)\n",
    "        y_others = np.delete(y_others,keep_classes_images[choice],0)\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh.fit(kpred, y_kimages) \n",
    "\n",
    "    mean_acc += np.sum(np.equal(y_others,neigh.predict(others_pred)))/len(y_others)\n",
    "    \n",
    "mean_acc /= n\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "mean_acc = 0\n",
    "\n",
    "for j in tqdm_notebook(range(n)):\n",
    "    nbof_kimages=len(np.unique(labels_test))\n",
    "    kpred=np.empty((nbof_kimages,pred_test.shape[-1]))\n",
    "    y_kimages = np.unique(labels_test)[:nbof_kimages]\n",
    "\n",
    "    others_pred = np.copy(pred_test)\n",
    "    y_others = np.copy(labels_test)\n",
    "\n",
    "    for i in range(nbof_kimages):\n",
    "        keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i],y_others)]\n",
    "        choice = np.random.randint(len(keep_classes_images))\n",
    "\n",
    "        kpred[i] = others_pred[keep_classes_images[choice]]\n",
    "\n",
    "        others_pred = np.delete(others_pred,keep_classes_images[choice],0)\n",
    "        y_others = np.delete(y_others,keep_classes_images[choice],0)\n",
    "\n",
    "    neigh.fit(kpred, y_kimages) \n",
    "\n",
    "    mean_acc += np.sum(np.equal(y_others,neigh.predict(others_pred)))/len(y_others)\n",
    "    \n",
    "mean_acc /= n\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbof_kimages=len(np.unique(new_labels_test))\n",
    "kpred=np.empty((nbof_kimages,new_pred_test.shape[-1]))\n",
    "y_kimages = np.unique(new_labels_test)[:nbof_kimages]\n",
    "\n",
    "others_pred = np.copy(new_pred_test)\n",
    "y_others = np.copy(new_labels_test)\n",
    "\n",
    "for i in range(nbof_kimages):\n",
    "    keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i],y_others)]\n",
    "    choice = np.random.randint(len(keep_classes_images))\n",
    "    \n",
    "    kpred[i] = others_pred[keep_classes_images[choice]]\n",
    "    \n",
    "    others_pred = np.delete(others_pred,keep_classes_images[choice],0)\n",
    "    y_others = np.delete(y_others,keep_classes_images[choice],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(kpred, y_kimages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.equal(y_others,neigh.predict(others_pred)))/len(y_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = 0\n",
    "nbof_try = 1 # We will do many try on the test dataset to obtain a more precize accuracy\n",
    "\n",
    "for k in tqdm_notebook(range(nbof_try)):\n",
    "    nbof_kimages=int(1.0*len(np.unique(labels_test)))\n",
    "    kpred=np.empty((nbof_kimages,pred_test.shape[-1]))\n",
    "    y_kimages = np.unique(labels_test)[:nbof_kimages]\n",
    "\n",
    "    others_pred = np.copy(pred_test)\n",
    "    y_others = np.copy(labels_test)\n",
    "\n",
    "    for i in range(nbof_kimages):\n",
    "        keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i],y_others)]\n",
    "        choice = np.random.randint(len(keep_classes_images))\n",
    "\n",
    "        kpred[i] = others_pred[keep_classes_images[choice]]\n",
    "\n",
    "        others_pred = np.delete(others_pred,keep_classes_images[choice],0)\n",
    "        y_others = np.delete(y_others,keep_classes_images[choice],0)\n",
    "    \n",
    "    threshold = 0.6\n",
    "\n",
    "    acc = 0\n",
    "\n",
    "    class_pred = np.empty(len(others_pred))\n",
    "\n",
    "    for i in range(len(others_pred)):\n",
    "        # computes distance with the key dataset\n",
    "        dist = np.sum(np.square(kpred-others_pred[i]),1)\n",
    "        if np.min(dist) < threshold:\n",
    "            class_pred[i] = y_others[i]\n",
    "#             if y_others[i] in y_kimages:\n",
    "#                 acc += 1\n",
    "            if np.argmin(dist)==y_others[i]:\n",
    "                acc += 1\n",
    "        else:\n",
    "            class_pred[i] = -1\n",
    "            if not y_others[i] in y_kimages:\n",
    "                acc += 1\n",
    "\n",
    "    acc /= len(others_pred)\n",
    "    \n",
    "    mean_acc += acc\n",
    "    \n",
    "mean_acc /= nbof_try\n",
    "print(\"Mean accuracy for a one shot learner: \" + str(mean_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_mins(t,n):\n",
    "    idx_mins = []\n",
    "    mins = []\n",
    "    for i in range(n):\n",
    "        idx_crt_min = 0\n",
    "        crt_min = t[0]\n",
    "        for j in range(1,len(t)):\n",
    "            if t[j] < crt_min:\n",
    "                crt_min = t[j]\n",
    "                idx_crt_min = j\n",
    "        idx_mins += [idx_crt_min]\n",
    "        mins += [crt_min]\n",
    "        t = t[:idx_crt_min] + t[idx_crt_min+1:]\n",
    "    return idx_mins, mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition: One-shot learning (deprecated: use the above part with M=1 instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = 0\n",
    "nbof_try = 1000 # We will do many try on the test dataset to obtain a more precize accuracy\n",
    "\n",
    "for k in tqdm_notebook(range(nbof_try)):\n",
    "    nbof_kimages=int(1.0*len(np.unique(labels_test)))\n",
    "    kpred=np.empty((nbof_kimages,pred_test.shape[-1]))\n",
    "    y_kimages = np.unique(labels_test)[:nbof_kimages]\n",
    "\n",
    "    others_pred = np.copy(pred_test)\n",
    "    y_others = np.copy(labels_test)\n",
    "\n",
    "    for i in range(nbof_kimages):\n",
    "        keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i],y_others)]\n",
    "        choice = np.random.randint(len(keep_classes_images))\n",
    "\n",
    "        kpred[i] = others_pred[keep_classes_images[choice]]\n",
    "\n",
    "        others_pred = np.delete(others_pred,keep_classes_images[choice],0)\n",
    "        y_others = np.delete(y_others,keep_classes_images[choice],0)\n",
    "    \n",
    "    threshold = 0.6\n",
    "\n",
    "    acc = 0\n",
    "\n",
    "    class_pred = np.empty(len(others_pred))\n",
    "\n",
    "    for i in range(len(others_pred)):\n",
    "        # computes distance with the key dataset\n",
    "        dist = np.sum(np.square(kpred-others_pred[i]),1)\n",
    "        if np.min(dist) < threshold:\n",
    "            class_pred[i] = 1\n",
    "#             if y_others[i] in y_kimages:\n",
    "#                 acc += 1\n",
    "            if np.argmin(dist)==y_others[i]:\n",
    "                acc += 1\n",
    "        else:\n",
    "            class_pred[i] = -1\n",
    "            if not y_others[i] in y_kimages:\n",
    "                acc += 1\n",
    "\n",
    "    acc /= len(others_pred)\n",
    "    \n",
    "    mean_acc += acc\n",
    "    \n",
    "mean_acc /= nbof_try\n",
    "print(\"Mean accuracy for a one shot learner: \" + str(mean_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for one-shot learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train a one-shot learner on the test dataset:\n",
    "#  -we randomly select key images: one picture per classes among 80% of the classes\n",
    "#  -we take a new picture\n",
    "#  -we check if the dog if the dog is known or not:\n",
    "#   computes the distance between the embedding vector and every embeddings saved in\n",
    "#   the dataset and compares the given distance with a threshold\n",
    "#  -if not, return -1\n",
    "#  -if yes, return the corresponding class\n",
    "\n",
    "# Note: for the test we could have compute the prediction for every pictures and\n",
    "# then separate key frames from the others but we played RP here :)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We randomly select key images: one picture per classes among 80% of the classes\n",
    "nbof_kimages=int(0.8*len(np.unique(labels_test)))\n",
    "kimages=np.empty((nbof_kimages,h,w,c))\n",
    "y_kimages = np.unique(labels_test)[:nbof_kimages]\n",
    "\n",
    "others = np.copy(images_test)\n",
    "y_others = np.copy(labels_test)\n",
    "\n",
    "for i in range(nbof_kimages):\n",
    "    keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i],y_others)]\n",
    "    choice = np.random.randint(len(keep_classes_images))\n",
    "    \n",
    "    kimages[i] = others[keep_classes_images[choice]]\n",
    "    \n",
    "    others = np.delete(others,keep_classes_images[choice],0)\n",
    "    y_others = np.delete(y_others,keep_classes_images[choice],0)\n",
    "\n",
    "kpred = model.predict(kimages)\n",
    "\n",
    "# Prediction for every other pictures\n",
    "others_pred = model.predict(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train a one-shot learner on the test dataset:\n",
    "#  -we randomly select key images: one picture per classes among 80% of the classes\n",
    "#  -we take a new picture\n",
    "#  -we check if the dog if the dog is known or not:\n",
    "#   computes the distance between the embedding vector and every embeddings saved in\n",
    "#   the dataset and compares the given distance with a threshold\n",
    "#  -if not, return -1\n",
    "#  -if yes, return the corresponding class\n",
    "\n",
    "# Note: for the test we could have compute the prediction for every pictures and\n",
    "# then separate key frames from the others but we played RP here :)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We randomly select key images: one picture per classes among 80% of the classes\n",
    "nbof_kimages=int(0.8*len(np.unique(labels_test)))\n",
    "kpred=np.empty((nbof_kimages,pred_test.shape[-1]))\n",
    "y_kimages = np.unique(labels_test)[:nbof_kimages]\n",
    "\n",
    "others_pred = np.copy(pred_test)\n",
    "y_others = np.copy(labels_test)\n",
    "\n",
    "for i in range(nbof_kimages):\n",
    "    keep_classes_images = np.arange(len(y_others))[np.equal(y_kimages[i],y_others)]\n",
    "    choice = np.random.randint(len(keep_classes_images))\n",
    "    \n",
    "    kpred[i] = others_pred[keep_classes_images[choice]]\n",
    "    \n",
    "    others_pred = np.delete(others_pred,keep_classes_images[choice],0)\n",
    "    y_others = np.delete(y_others,keep_classes_images[choice],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the best threshold find on verification task\n",
    "threshold = 0.3\n",
    "\n",
    "# for i in range(len(others_pred)):\n",
    "\n",
    "acc = 0\n",
    "\n",
    "class_pred = np.empty(len(others_pred))\n",
    "\n",
    "for i in range(len(others_pred)):\n",
    "    # computes distance with the key dataset\n",
    "    dist = np.sum(np.square(kpred-others_pred[i]),1)\n",
    "    if np.min(dist) < threshold:\n",
    "        class_pred[i] = np.argmin(dist)\n",
    "        if np.argmin(dist)==y_others[i]:\n",
    "            acc += 1\n",
    "    else:\n",
    "        class_pred[i] = -1\n",
    "        if not y_others[i] in y_kimages:\n",
    "            acc += 1\n",
    "        \n",
    "acc /= len(others_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will find the best threshold for verification\n",
    "best_acc = 0\n",
    "best_t = 0.001\n",
    "for threshold in np.arange(0.001,1,0.001):\n",
    "\n",
    "    acc = 0\n",
    "\n",
    "    class_pred = np.empty(len(others_pred))\n",
    "\n",
    "    for i in range(len(others_pred)):\n",
    "        # computes distance with the key dataset\n",
    "        dist = np.sum(np.square(kpred-others_pred[i]),1)\n",
    "        if np.min(dist) < threshold:\n",
    "            class_pred[i] = np.argmin(dist)\n",
    "            if np.argmin(dist)==y_others[i]:\n",
    "                acc += 1\n",
    "#             if y_others[i] in y_kimages:\n",
    "#                 acc += 1\n",
    "        else:\n",
    "            class_pred[i] = -1\n",
    "            if not y_others[i] in y_kimages:\n",
    "                acc += 1\n",
    "    acc /= len(others_pred)\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_t = threshold\n",
    "\n",
    "\n",
    "print(best_acc)\n",
    "print(best_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "for i in range(38):\n",
    "    plt.subplot(5,8,i+1)\n",
    "    plt.imshow(kimages[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,18))\n",
    "for i in range(13*18):\n",
    "    plt.subplot(18,13,i+1)\n",
    "    plt.imshow(others[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition: Re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 30.\n",
    "m = 0.3\n",
    "def cosine(y_true,y_pred):\n",
    "    \n",
    "    exp_s = K.exp(s * y_pred)\n",
    "    exp_s_m = K.exp(s * (y_pred - m))\n",
    "    \n",
    "    masked_exp_s_m = exp_s_m * y_true\n",
    "    \n",
    "    inv_mask = 1. - y_true\n",
    "    masked_exp_s = exp_s * inv_mask\n",
    "    \n",
    "    den = K.sum(masked_exp_s + masked_exp_s_m, axis=-1, keepdims=True)\n",
    "    out = masked_exp_s_m / den\n",
    "    out = K.sum(out,axis=-1)\n",
    "    ret = - K.log(out)\n",
    "    ret = K.sum(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cosine(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Cosine, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[-1],self.output_dim))\n",
    "\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(Cosine, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.math.l2_normalize(x, axis=-1)\n",
    "        w = tf.math.l2_normalize(self.kernel, axis=0)\n",
    "        \n",
    "        return K.dot(x, w)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_exp = tf.keras.utils.to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = tf.keras.layers.Dense(128, activation='relu')(model.output)\n",
    "out = Cosine(len(labels_test_exp[0]))(model.output)\n",
    "#out = tf.keras.layers.Dense(24, activation='softmax')(out)\n",
    "recog = tf.keras.Model(model.input,out)\n",
    "for layer in model.layers: layer.trainable = False\n",
    "recog.compile(tf.keras.optimizers.Adam(),loss=cosine,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recog.fit(images_test,labels_test_exp,batch_size=64,epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation on the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3 = tf.keras.Model(model.layers[0].input, model.layers[9].output)\n",
    "predict3 = mod3.predict(images_train[0:100:10])\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(10):\n",
    "    plt.subplot(10,10,i*10+1)\n",
    "    sk.io.imshow(images_train[i*10])\n",
    "    \n",
    "    for j in range(9):\n",
    "        pred3 = np.mean(predict3[i][:,:,j*25:j*25+3],axis=-1)\n",
    "        plt.subplot(10,10,i*10+2+j)\n",
    "        sk.io.imshow(images_train[i*10])\n",
    "        plt.imshow(pred3,cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = 100\n",
    "mod1 = tf.keras.Model(model.layers[0].input, model.layers[1].output)\n",
    "predict1 = mod1.predict(images_train[0+s:100+s:10])\n",
    "\n",
    "mod2 = tf.keras.Model(model.layers[0].input, model.layers[9].output)\n",
    "predict2 = mod2.predict(images_train[0+s:100+s:10])\n",
    "\n",
    "mod3 = tf.keras.Model(model.layers[0].input, model.layers[14].output)\n",
    "predict3 = mod3.predict(images_train[0+s:100+s:10])\n",
    "\n",
    "plt.figure(figsize=(9,20))\n",
    "for i in range(10):\n",
    "    pred1 = np.mean(predict1[i],axis=-1)\n",
    "    pred2 = np.mean(predict2[i],axis=-1)\n",
    "    pred3 = np.mean(predict3[i],axis=-1)\n",
    "\n",
    "    \n",
    "    plt.subplot(10,4,i*4+1)\n",
    "    sk.io.imshow(images_train[i*10 + s])\n",
    "    plt.subplot(10,4,i*4+2)\n",
    "    plt.imshow(pred1,cmap='plasma')\n",
    "    plt.subplot(10,4,i*4+3)\n",
    "    plt.imshow(pred2,cmap='plasma')\n",
    "    plt.subplot(10,4,i*4+4)\n",
    "    plt.imshow(pred3,cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_datagen.flow(images_train,labels_train,batch_size = 64),\n",
    "    epochs = 12,\n",
    "    validation_data=(images_valid,labels_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../output/model/dogfacenet_v6_cosine.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

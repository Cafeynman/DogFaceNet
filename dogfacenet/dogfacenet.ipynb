{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DogFaceNet version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/dogfacenet/'\n",
    "PATH_IMAGES = PATH + 'images/'\n",
    "PATH_RESIZED = PATH + 'resized/'\n",
    "\n",
    "# Size of the input image into the network\n",
    "SIZE = (100,100,3)\n",
    "\n",
    "TEST_SPLIT = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing\n",
    "- Get the dataset from folders\n",
    "- Associate the corresponding classes\n",
    "- Resized the dataset\n",
    "- Shuffle the dataset?\n",
    "- Divide the dataset into validation, training and testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_crop(image):\n",
    "    \"\"\"\n",
    "    Takes the largest between height and width of the image and crops it into a square.\n",
    "    This square is located in the middle of the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    h,w,c = image.shape\n",
    "    \n",
    "    if w > h:\n",
    "        margin = w - h\n",
    "        margin = margin // 2\n",
    "        image = image[:,margin:margin+h,:]\n",
    "    elif w < h:\n",
    "        margin = h - w\n",
    "        margin = margin // 2\n",
    "        image = image[margin:margin+w,:,:]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6491e4baa6e74a5f88a1cbf88edfa807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "label = 0\n",
    "\n",
    "filenames = os.listdir(PATH_IMAGES)\n",
    "\n",
    "# Just save the pictures after resizing them\n",
    "for i in tqdm_notebook(range(598+869,len(filenames))):\n",
    "    for file in os.listdir(PATH_IMAGES + filenames[i]):\n",
    "        label += 1\n",
    "        \n",
    "        # Read and resized image\n",
    "        image = sk.io.imread(PATH_IMAGES + filenames[i] + '/' + file)\n",
    "        if len(image.shape) == 3:\n",
    "            image_cropped = square_crop(image)\n",
    "            image_resized = sk.transform.resize(image_cropped,SIZE)\n",
    "\n",
    "            # Save image\n",
    "            ## Check if the good folder exists\n",
    "            if filenames[i] not in os.listdir(PATH_RESIZED):\n",
    "                os.mkdir(PATH_RESIZED + filenames[i])\n",
    "            sk.io.imsave(PATH_RESIZED + filenames[i] + '/' + str(label) + '.jpg', image_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 5568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96d5ac08cfa4880b0ba785d5c6107fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1477), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(PATH_RESIZED)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Remove unique examples\n",
    "while i<len(filenames):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    if len(files)<=1:\n",
    "        filenames = filenames[:i] + filenames[i+1:]\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "# Compute the number of images\n",
    "nbof_images = 0\n",
    "for i in range(0,len(filenames)):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    nbof_images += len(files)\n",
    "\n",
    "print(\"Number of images: \" + str(nbof_images))\n",
    "    \n",
    "w, h, c = SIZE\n",
    "\n",
    "images = np.empty((nbof_images,w,h,c))\n",
    "labels = np.empty(nbof_images)\n",
    "        \n",
    "label = 0\n",
    "\n",
    "index = 0\n",
    "\n",
    "# Load images into numpy arrays\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    for file in files:\n",
    "        labels[index] = label\n",
    "        # Read image\n",
    "        image = sk.io.imread(PATH_RESIZED + filenames[i] + '/' + file)\n",
    "\n",
    "        # Add the image to the table\n",
    "        images[index] = image\n",
    "        \n",
    "        index += 1\n",
    "    label += 1\n",
    "    \n",
    "assert len(labels)==len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into train, valid and test:\n",
    "\n",
    "To create the validation dataset we use pictures of dogs were there is more than 3 pictures and took one of this picture.\n",
    "\n",
    "For the testing dataset we simply split the classes. We will then use the network as a one shot learner on this new dataset. With one picture the network will produce one embedding vector. For each embedding vector compute the L2 distance with each face to compute the most propable one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5568\n",
      "Number of test images: 278\n",
      "Number of validation images: 543\n",
      "Number of training images: 4747\n",
      "Is the number of images coherent? True\n"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "nbof_test = int(len(images)*TEST_SPLIT)\n",
    "\n",
    "images_test = images[:nbof_test]\n",
    "labels_test = labels[:nbof_test]\n",
    "\n",
    "\n",
    "# Count valid images:\n",
    "state = -1\n",
    "count_valid = 0\n",
    "count_train = 0\n",
    "count_image_class = 0\n",
    "\n",
    "for i in range(nbof_test,len(labels)):\n",
    "    if state != labels[i]:\n",
    "        state = labels[i]\n",
    "        count_image_class = 0\n",
    "    else:\n",
    "        count_image_class += 1\n",
    "    \n",
    "    if count_image_class == 3:\n",
    "        count_valid += 1\n",
    "    else:\n",
    "        count_train += 1\n",
    "\n",
    "print(\"Total number of images: \" + str(len(labels)))\n",
    "print(\"Number of test images: \" + str(len(labels_test)))\n",
    "print(\"Number of validation images: \" + str(count_valid))\n",
    "print(\"Number of training images: \" + str(count_train))\n",
    "\n",
    "images_valid = np.empty((count_valid,w,h,c))\n",
    "labels_valid = np.empty(count_valid)\n",
    "\n",
    "images_train = np.empty((count_train,w,h,c))\n",
    "labels_train = np.empty(count_train)\n",
    "\n",
    "state = -1\n",
    "count_valid = 0\n",
    "count_train = 0\n",
    "count_image_class = 0\n",
    "\n",
    "for i in range(nbof_test,len(labels)):\n",
    "    if state != labels[i]:\n",
    "        state = labels[i]\n",
    "        count_image_class = 0\n",
    "    else:\n",
    "        count_image_class += 1\n",
    "    \n",
    "    if count_image_class == 3:\n",
    "        # Add the validation image in the validation array\n",
    "        images_valid[count_valid] = images[i]\n",
    "        labels_valid[count_valid] = labels[i]\n",
    "        \n",
    "        count_valid += 1\n",
    "    else:\n",
    "        images_train[count_train] = images[i]\n",
    "        labels_train[count_train] = labels[i]\n",
    "        \n",
    "        count_train += 1\n",
    "\n",
    "# print(labels)\n",
    "# print(labels_test)\n",
    "# print(labels_train)\n",
    "# print(labels_valid)\n",
    "print(\"Is the number of images coherent? \" + str(len(labels)==(len(labels_test)+len(labels_train)+len(labels_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "- Define the ArcFace layer\n",
    "- Try first with an dummy one\n",
    "- Compile it with the arcface loss and and Adam optimizer\n",
    "\n",
    "Then use transfer learning with a more complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Arcface layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My custom layer for arcface\n",
    "# It takes two inputs: one for the embedding, one for the label\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "import math\n",
    "\n",
    "# Arcface should only be used for training\n",
    "class Arcface(Layer):\n",
    "\n",
    "    def __init__(self, out_num, s = 64., m = 0.5, **kwargs):\n",
    "        self.output_dim = out_num\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        super(Arcface, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape, initializer='uniform'):\n",
    "        assert isinstance(input_shape, list)\n",
    "        \n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.weights = self.add_weight(name='embedding_weights',\n",
    "                                                 shape=(input_shape[0][-1],self.out_num),\n",
    "                                                 initializer=initializer,\n",
    "                                                 dtype=tf.float32,\n",
    "                                                 trainable=True)\n",
    "        super(Arcface, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        assert isinstance(x, list)\n",
    "        embedding, labels = x\n",
    "        \n",
    "        cos_m = math.cos(self.m)\n",
    "        sin_m = math.sin(self.m)\n",
    "        mm = sin_m * self.m  # issue 1\n",
    "        threshold = math.cos(math.pi - self.m)\n",
    "        \n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keepdims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        \n",
    "        weights_norm = tf.norm(self.weights, axis=0, keepdims=True)\n",
    "        self.weights = tf.div(self.weights, weights_norm, name='norm_weights')\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, self.weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "        \n",
    "        # this condition controls the theta+m should be in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = self.s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "        mask = tf.one_hot(labels, depth=self.out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "\n",
    "        output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_loss_output')\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        shape_emb, shape_lab = input_shape\n",
    "        return [(shape_emb[0], self.out_num), shape_lab[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy(tf.keras.Model):\n",
    "    def __init__(self, out_num):\n",
    "        super(Dummy_embedding, self).__init__(name='dummy')\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10,(3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20,(3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(40,(3, 3))\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv4 = tf.keras.layers.Conv2D(80,(3, 3))\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.layers.Dense(emb_size)\n",
    "        \n",
    "        self.arcface = Arcface(out_num)\n",
    "        self\n",
    "    \n",
    "    def __call__(self, input_tensor, training):\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return tf.nn.l2_normalize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on the training/validation dataset to stop the worst examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate it on the test dataset: one shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

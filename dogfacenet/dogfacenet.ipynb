{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DogFaceNet version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/dogfacenet/'\n",
    "PATH_IMAGES = PATH + 'images/'\n",
    "PATH_RESIZED = PATH + 'resized/'\n",
    "\n",
    "# Size of the input image into the network\n",
    "SIZE = (100,100,3)\n",
    "\n",
    "TEST_SPLIT = 0.05\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing\n",
    "- Get the dataset from folders\n",
    "- Associate the corresponding classes\n",
    "- Resized the dataset\n",
    "- Shuffle the dataset?\n",
    "- Divide the dataset into validation, training and testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_crop(image):\n",
    "    \"\"\"\n",
    "    Takes the largest between height and width of the image and crops it into a square.\n",
    "    This square is located in the middle of the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    h,w,c = image.shape\n",
    "    \n",
    "    if w > h:\n",
    "        margin = w - h\n",
    "        margin = margin // 2\n",
    "        image = image[:,margin:margin+h,:]\n",
    "    elif w < h:\n",
    "        margin = h - w\n",
    "        margin = margin // 2\n",
    "        image = image[margin:margin+w,:,:]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6491e4baa6e74a5f88a1cbf88edfa807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "label = 0\n",
    "\n",
    "filenames = os.listdir(PATH_IMAGES)\n",
    "\n",
    "# Just save the pictures after resizing them\n",
    "for i in tqdm_notebook(range(598+869,len(filenames))):\n",
    "    for file in os.listdir(PATH_IMAGES + filenames[i]):\n",
    "        label += 1\n",
    "        \n",
    "        # Read and resized image\n",
    "        image = sk.io.imread(PATH_IMAGES + filenames[i] + '/' + file)\n",
    "        if len(image.shape) == 3:\n",
    "            image_cropped = square_crop(image)\n",
    "            image_resized = sk.transform.resize(image_cropped,SIZE)\n",
    "\n",
    "            # Save image\n",
    "            ## Check if the good folder exists\n",
    "            if filenames[i] not in os.listdir(PATH_RESIZED):\n",
    "                os.mkdir(PATH_RESIZED + filenames[i])\n",
    "            sk.io.imsave(PATH_RESIZED + filenames[i] + '/' + str(label) + '.jpg', image_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 5568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e8e315c7c4ea5ae121235e48d9084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1477), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(PATH_RESIZED)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Remove unique examples\n",
    "while i<len(filenames):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    if len(files)<=1:\n",
    "        filenames = filenames[:i] + filenames[i+1:]\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "# Compute the number of images\n",
    "nbof_images = 0\n",
    "for i in range(0,len(filenames)):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    nbof_images += len(files)\n",
    "\n",
    "print(\"Number of images: \" + str(nbof_images))\n",
    "    \n",
    "w, h, c = SIZE\n",
    "\n",
    "images = np.empty((nbof_images,w,h,c))\n",
    "labels = np.empty(nbof_images, dtype=int)\n",
    "\n",
    "label = 0\n",
    "\n",
    "index = 0\n",
    "\n",
    "# Load images into numpy arrays\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    for file in files:\n",
    "        labels[index] = label\n",
    "        # Read image\n",
    "        image = sk.io.imread(PATH_RESIZED + filenames[i] + '/' + file)\n",
    "\n",
    "        # Add the image to the table\n",
    "        images[index] = image\n",
    "        \n",
    "        index += 1\n",
    "    label += 1\n",
    "\n",
    "# Normalize images:\n",
    "images -= 127.5\n",
    "images *= 1/128\n",
    "assert len(labels)==len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old method!\n",
    "\n",
    "Divide the dataset into train, valid and test:\n",
    "\n",
    "To create the validation dataset we use pictures of dogs were there is more than 3 pictures and took one of this picture.\n",
    "\n",
    "For the testing dataset we simply split the classes. We will then use the network as a one shot learner on this new dataset. With one picture the network will produce one embedding vector. For each embedding vector compute the L2 distance with each face to compute the most propable one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5568\n",
      "Number of test images: 278\n",
      "Number of validation images: 543\n",
      "Number of training images: 4747\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-95fc612d2572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mcount_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;31m# print(labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# print(labels_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "nbof_test = int(len(images)*TEST_SPLIT)\n",
    "\n",
    "images_test = images[:nbof_test]\n",
    "labels_test = labels[:nbof_test]\n",
    "\n",
    "\n",
    "# Count valid images:\n",
    "state = -1\n",
    "count_valid = 0\n",
    "count_train = 0\n",
    "count_image_class = 0\n",
    "\n",
    "for i in range(nbof_test,len(labels)):\n",
    "    if state != labels[i]:\n",
    "        state = labels[i]\n",
    "        count_image_class = 0\n",
    "    else:\n",
    "        count_image_class += 1\n",
    "    \n",
    "    if count_image_class == 3:\n",
    "        count_valid += 1\n",
    "    else:\n",
    "        count_train += 1\n",
    "\n",
    "print(\"Total number of images: \" + str(len(labels)))\n",
    "print(\"Number of test images: \" + str(len(labels_test)))\n",
    "print(\"Number of validation images: \" + str(count_valid))\n",
    "print(\"Number of training images: \" + str(count_train))\n",
    "\n",
    "images_valid = np.empty((count_valid,w,h,c))\n",
    "labels_valid = np.empty(count_valid)\n",
    "\n",
    "images_train = np.empty((count_train,w,h,c))\n",
    "labels_train = np.empty(count_train)\n",
    "\n",
    "state = -1\n",
    "count_valid = 0\n",
    "count_train = 0\n",
    "count_image_class = 0\n",
    "\n",
    "for i in range(nbof_test,len(labels)):\n",
    "    if state != labels[i]:\n",
    "        state = labels[i]\n",
    "        count_image_class = 0\n",
    "    else:\n",
    "        count_image_class += 1\n",
    "    \n",
    "    if count_image_class == 3:\n",
    "        # Add the validation image in the validation array\n",
    "        images_valid[count_valid] = images[i]\n",
    "        labels_valid[count_valid] = labels[i]\n",
    "        \n",
    "        count_valid += 1\n",
    "    else:\n",
    "        images_train[count_train] = images[i]\n",
    "        labels_train[count_train] = labels[i]\n",
    "        \n",
    "        count_train += 1\n",
    "# print(labels)\n",
    "# print(labels_test)\n",
    "# print(labels_train)\n",
    "# print(labels_valid)\n",
    "print(\"Is the number of images coherent? \" + str(len(labels)==(len(labels_test)+len(labels_train)+len(labels_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New method\n",
    "- We divide the validation and test set from the training set with the classic division method: 85 percent training, 10 validating, 5 testing.\n",
    "- We then computes pairs of images in the validation set and testing set:\n",
    " - Some of these pairs are images of the same dog and some are picture of different dogs\n",
    " - We create a two lists:\n",
    "  - A list a images containing the pairs: two successive images are a pair of images. For example, image 0 and is a pair, image 2 and 3 is another pair, etc...\n",
    "  - A list of boolean called 'issame' indicating if a pair is a pair of images of the same dog or a pair of different dogs. For example, if image 0 and image 1 are showing the same dog value 0 and 1 in the list will be True. On the other hand if the image 2 and 3 represent two different dogs the value 2 and 3 in the list will be at False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5568\n",
      "Number of test images: 278\n",
      "Number of validation images: 556\n",
      "Number of training images: 4734\n",
      "Number of classes in the training set: 1300\n",
      "Number of pairs: 556\n",
      "Number of same images: 149\n",
      "Number of validation images: 556\n"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "nbof_test = int(len(images)*TEST_SPLIT)\n",
    "\n",
    "images_test = images[-nbof_test:]\n",
    "labels_test = labels[-nbof_test:]\n",
    "\n",
    "nbof_valid = int(len(images)*VALID_SPLIT)\n",
    "\n",
    "images_valid = images[-nbof_test-nbof_valid:-nbof_test]\n",
    "labels_valid = labels[-nbof_test-nbof_valid:-nbof_test]\n",
    "\n",
    "images_train = images[:-nbof_test-nbof_valid]\n",
    "labels_train = labels[:-nbof_test-nbof_valid]\n",
    "\n",
    "print(\"Total number of images: \" + str(len(labels)))\n",
    "print(\"Number of test images: \" + str(len(labels_test)))\n",
    "print(\"Number of validation images: \" + str(len(labels_valid)))\n",
    "print(\"Number of training images: \" + str(len(labels_train)))\n",
    "print(\"Number of classes in the training set: \" + str(labels_train[-1] - labels_train[0]))\n",
    "\n",
    "\n",
    "# Creates the pairs\n",
    "\n",
    "nbof_pairs = (len(images_valid)//2)*2 # it has to be multiple of 2\n",
    "\n",
    "print(\"Number of pairs: \" + str(nbof_pairs))\n",
    "\n",
    "pairs = np.empty((nbof_pairs,w,h,c))\n",
    "issame_in = np.empty(nbof_pairs, dtype=int)\n",
    "issame_out = np.empty((nbof_pairs,2))\n",
    "\n",
    "nbof_same = 0\n",
    "\n",
    "for i in range(0,nbof_pairs,2):\n",
    "    ## alea_issame will decide if the new pair will be a pair of same dog images or a pair of different\n",
    "    alea_issame = np.random.rand()\n",
    "\n",
    "    if alea_issame < 0.5: # Then it will be a pair of same dogs\n",
    "        # we randomly choose a dog\n",
    "        choice = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        # we extract the images of this class\n",
    "        chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice])])\n",
    "        \n",
    "        while len(labels_valid[np.equal(labels_valid,labels_valid[choice])]) < 2:\n",
    "            choice = np.random.randint(len(labels_valid))\n",
    "            chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice])])\n",
    "            \n",
    "        # we then randomly choose two pictures of this class\n",
    "        choice1 = np.random.randint(len(chosen_images))\n",
    "        pairs[i] = chosen_images[choice1]\n",
    "        save = np.copy(chosen_images)\n",
    "        chosen_images = chosen_images[:choice1] + chosen_images[choice1+1:]\n",
    "        if len(chosen_images) == 0:\n",
    "            print(\"Bug!\")\n",
    "            print(save)\n",
    "        choice2 = np.random.randint(len(chosen_images))\n",
    "        pairs[i+1] = chosen_images[choice2]\n",
    "\n",
    "        issame_out[i] = issame_out[i+1] = [1,0]\n",
    "        issame_in[i] = issame_in[i+1] = 1\n",
    "        \n",
    "        nbof_same += 1\n",
    "        \n",
    "    else: # Then it will be a pair of different dogs\n",
    "        # we randomly choose two dogs\n",
    "        choice1 = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        # we extract the images of the class\n",
    "        chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice1])])\n",
    "        \n",
    "        # we choose an image of this class\n",
    "        choice = np.random.randint(len(chosen_images))\n",
    "        #print(choice)\n",
    "        pairs[i] = images_valid[choice]\n",
    "        \n",
    "        choice2 = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        # check if we have two different classes\n",
    "        while labels_valid[choice2] == labels_valid[choice1]:\n",
    "            choice2 = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice2])])\n",
    "        \n",
    "        # we choose an image of this class\n",
    "        choice = np.random.randint(len(chosen_images))\n",
    "        \n",
    "        pairs[i+1] = images_valid[choice]\n",
    "        \n",
    "        issame_out[i] = issame_out[i+1] = [0,1]\n",
    "        issame_in[i] = issame_in[i+1] = 0\n",
    "\n",
    "print(\"Number of same images: \" + str(nbof_same))\n",
    "print(\"Number of validation images: \" + str(len(labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBOF_CLASSES = max(labels_train)+1\n",
    "#labels_train = tf.keras.utils.to_categorical(labels_train,NBOF_CLASSES)\n",
    "#labels_valid = tf.keras.utils.to_categorical(labels_valid-NBOF_CLASSES,NBOF_CLASSES)\n",
    "issame_train_in = np.ones(len(labels_train))\n",
    "issame_train_out = np.zeros((len(labels_train),2))\n",
    "issame_train_out[:,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input shapes: \n",
      "(4734, 100, 100, 3)\n",
      "(4734,)\n",
      "(4734,)\n",
      "Train output shape: \n",
      "(4734,)\n",
      "(4734, 2)\n",
      "Valid input shape: \n",
      "(556, 100, 100, 3)\n",
      "(556,)\n",
      "(556,)\n",
      "Valid output shape: \n",
      "(556,)\n",
      "(556, 2)\n"
     ]
    }
   ],
   "source": [
    "# Verify shapes\n",
    "# Train inputs\n",
    "print(\"Train input shapes: \")\n",
    "print(images_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(issame_train_in.shape)\n",
    "\n",
    "print(\"Train output shape: \")\n",
    "print(labels_train.shape)\n",
    "print(issame_train_out.shape)\n",
    "\n",
    "print(\"Valid input shape: \")\n",
    "print(images_valid.shape)\n",
    "print(labels_valid.shape)\n",
    "print(issame_in.shape)\n",
    "\n",
    "print(\"Valid output shape: \")\n",
    "print(labels_valid.shape)\n",
    "print(issame_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "- Define the ArcFace layer\n",
    "- Define the dummy model first\n",
    "- Compile it with the softmax loss and and Adam optimizer\n",
    "- Then use transfer learning with a more complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Arcface layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "mask = tf.one_hot(tf.constant([1,2,2,3]),4)\n",
    "with tf.Session() as sess:\n",
    "    mask_ = sess.run(mask)\n",
    "    print(mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My custom layer for arcface\n",
    "# It takes two inputs: one for the embedding, one for the label\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "import math\n",
    "\n",
    "# Arcface should only be used for training\n",
    "class Arcface(Layer):\n",
    "\n",
    "    def __init__(self, out_num, s = 64., m = 0.5, **kwargs):\n",
    "        self.out_num = out_num\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        super(Arcface, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape, initializer='uniform'):\n",
    "        assert isinstance(input_shape, list)\n",
    "        \n",
    "        shape = tf.TensorShape((input_shape[0][-1],self.out_num))\n",
    "        print(shape)\n",
    "        \n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                                 shape=shape,\n",
    "                                                 initializer=initializer,\n",
    "                                                 dtype=tf.float32,\n",
    "                                                 trainable=True)\n",
    "        super(Arcface, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        assert isinstance(x, list)\n",
    "        embedding, labels = x\n",
    "        \n",
    "        cos_m = math.cos(self.m)\n",
    "        sin_m = math.sin(self.m)\n",
    "        mm = sin_m * self.m  # issue 1\n",
    "        threshold = math.cos(math.pi - self.m)\n",
    "        \n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keepdims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        \n",
    "        weights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n",
    "        weights = tf.div(self.kernel, weights_norm, name='norm_weights')\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "        \n",
    "        # this condition controls the theta+m should be in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = self.s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "        mask = tf.one_hot(labels, depth=self.out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "\n",
    "        output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_loss_output')\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        shape_emb, shape_lab = input_shape\n",
    "        shape_emb[-1] = self.out_num\n",
    "        return tf.TensorShape(shape_emb)\n",
    "    \n",
    "#         shape = tf.TensorShape(input_shape).as_list()\n",
    "#         shape[-1] = self.num_classes\n",
    "#         return tf.TensorShape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "import math\n",
    "\n",
    "# Arcface should only be used for training\n",
    "class Arcface(Layer):\n",
    "\n",
    "    def __init__(self, out_num, s = 64., m = 0.5, **kwargs):\n",
    "        self.out_num = out_num\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        super(Arcface, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape, initializer='uniform'):\n",
    "        assert isinstance(input_shape, list)\n",
    "        \n",
    "        shape = tf.TensorShape((input_shape[0][-1],self.out_num))\n",
    "        print(shape)\n",
    "        \n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                                 shape=shape,\n",
    "                                                 initializer=initializer,\n",
    "                                                 dtype=tf.float32,\n",
    "                                                 trainable=True)\n",
    "        super(Arcface, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        assert isinstance(x, list)\n",
    "        emb, labels = x\n",
    "        labels_sq = tf.squeeze(labels,1)\n",
    "        #labels_sq = tf.reshape(labels,[None])\n",
    "        labels_int = tf.cast(labels_sq,tf.int32, name='labels_int')\n",
    "        print(labels_int.shape)\n",
    "        mask = tf.one_hot(labels_int, depth=self.out_num, name='one_hot_mask')\n",
    "        #mask = tf.squeeze(mask,1)\n",
    "        print(mask.shape)\n",
    "        #mask_shape = mask.shape.as_list()\n",
    "        #mask = tf.reshape(mask, (None,mask_shape[-1]))\n",
    "        #print(mask.shape)\n",
    "        def train_output():\n",
    "            cos_m = math.cos(self.m)\n",
    "            sin_m = math.sin(self.m)\n",
    "            mm = sin_m * self.m  # issue 1\n",
    "            threshold = math.cos(math.pi - self.m)\n",
    "\n",
    "            # inputs and weights norm\n",
    "            embedding_norm = tf.norm(emb, axis=1, keepdims=True)\n",
    "            embedding = tf.div(emb, embedding_norm, name='norm_embedding')\n",
    "\n",
    "            weights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n",
    "            weights = tf.div(self.kernel, weights_norm, name='norm_weights')\n",
    "            # cos(theta+m)\n",
    "            cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "            print(cos_t.shape)\n",
    "            cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "            sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "            sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "            cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "\n",
    "            # this condition controls the theta+m should be in range [0, pi]\n",
    "            #      0<=theta+m<=pi\n",
    "            #     -m<=theta<=pi-m\n",
    "            cond_v = cos_t - threshold\n",
    "            cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "            keep_val = self.s*(cos_t - mm)\n",
    "            cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "            \n",
    "            # mask = tf.squeeze(mask, 1)\n",
    "            inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "            s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "            mul1 = tf.multiply(s_cos_t, inv_mask)\n",
    "            print(mul1.shape)\n",
    "            mul2 = tf.multiply(cos_mt_temp, mask)\n",
    "            print(mul2.shape)\n",
    "            output = tf.add(mul1, mul2, name='arcface_loss_output')\n",
    "            print(output.shape)\n",
    "            print(cos_mt_temp.shape)\n",
    "            \n",
    "            return output\n",
    "        \n",
    "        def valid_output():\n",
    "            return mask\n",
    "        \n",
    "        return K.in_train_phase(train_output,valid_output,training=training)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        shape_emb, shape_lab = input_shape\n",
    "        shape_emb[-1] = self.out_num\n",
    "        return tf.TensorShape(shape_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, s = 64., m = 0.5, **kwargs):\n",
    "        self.out_num = output_dim\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "        \n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        shape = (input_shape[1].value, self.out_num)\n",
    "        print(shape)\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        #assert isinstance(x, list)\n",
    "        embedding = x\n",
    "        \n",
    "        cos_m = math.cos(self.m)\n",
    "        sin_m = math.sin(self.m)\n",
    "        mm = sin_m * self.m  # issue 1\n",
    "        threshold = math.cos(math.pi - self.m)\n",
    "        \n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keepdims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        \n",
    "        weights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n",
    "        weights = tf.div(self.kernel, weights_norm, name='norm_weights')\n",
    "        #print(self.weights)\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "        \n",
    "        # this condition controls the theta+m should be in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = self.s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "        #mask = tf.one_hot(labels, depth=self.out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        #inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        \n",
    "        s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "        \n",
    "        return s_cos_t\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0].value, self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the validation layer:\n",
    "- The bigger the validation batch the better it is (no less than 64 pictures -> 32 pairs)\n",
    "- It computes the ROC curve\n",
    "- Finds the best threshold\n",
    "- Returns a list of 2D vectors [1,0] if the pair was the same dog, [0,1] if it was a different dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "0.6226596832275391\n",
      "[1. 1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# tests unitaires\n",
    "\n",
    "tf.reset_default_graph()\n",
    "emb_raw = tf.constant([[12.,2],[8,4],[3,8],[2,10],[50,10],[10,30]])\n",
    "\n",
    "actual_issame = tf.constant([1.,1,1,1,0,0])\n",
    "emb = tf.math.l2_normalize(emb_raw,0)\n",
    "\n",
    "# Normalizes\n",
    "#emb = tf.math.l2_normalize(emb_,0)\n",
    "\n",
    "# Separates the pairs\n",
    "emb1 = emb[0::2]\n",
    "emb2 = emb[1::2]\n",
    "\n",
    "# Computes distance between pairs\n",
    "diff = tf.squared_difference(emb1,emb2)\n",
    "dist = tf.reduce_sum(diff,1)\n",
    "\n",
    "dist = tf.reshape(tf.stack([dist,dist], axis=-1), [-1])\n",
    "print(dist.shape)\n",
    "best_threshold = 0\n",
    "#for t in np.arange(0,1,0.001):\n",
    "t = 0.01\n",
    "\n",
    "actual_issame_bool = tf.cast(actual_issame,dtype=tf.bool)\n",
    "\n",
    "def fn(t):\n",
    "    less = tf.less(dist,t)\n",
    "\n",
    "    acc = tf.logical_not(tf.logical_xor(less,actual_issame_bool))\n",
    "    acc = tf.cast(acc,tf.float32)\n",
    "    \n",
    "    out = tf.reshape(tf.reduce_sum(acc),[])\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "thresholds = tf.range(0,1,0.001)\n",
    "apply_t = tf.map_fn(fn, thresholds)\n",
    "best_t = tf.argmax(apply_t)\n",
    "\n",
    "best = thresholds[best_t]\n",
    "\n",
    "# Redo the manipulation with the best threshold\n",
    "less = tf.less(dist,best)\n",
    "less = tf.cast(less,tf.float32)\n",
    "#less = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], less)\n",
    "\n",
    "\n",
    "# # Creates different threshold in order to find the best one\n",
    "# np_threshold = np.vstack([np.arange(0,1,0.01)]*3).T\n",
    "\n",
    "# # Reshapes the distance\n",
    "# dist2 = tf.stack([dist]*len(np_threshold))\n",
    "\n",
    "# # Reshapes the true values\n",
    "# actual_issame = tf.constant([[True,True,False]]*len(np_threshold),dtype=bool)\n",
    "\n",
    "# threshold = tf.constant(np_threshold, dtype=tf.float32)\n",
    "\n",
    "# # Uses the created thresholds to compute the predictions\n",
    "# predict_issame = tf.less(dist2,threshold)\n",
    "\n",
    "# # Computes the accuracy\n",
    "# truth = tf.logical_not(tf.logical_xor(predict_issame, actual_issame))\n",
    "\n",
    "# r = tf.reduce_sum(tf.cast(truth,tf.float32),1)\n",
    "\n",
    "# # Finds the best accuracy with respect to the threshold\n",
    "# m = tf.argmax(r)\n",
    "\n",
    "# # best_threshold = threshold[m]\n",
    "# # accuracy = r[m]/3\n",
    "\n",
    "# # Ouputs the best output and reshapes the output in a softmax way\n",
    "# bool_output = predict_issame[m]\n",
    "# int_output = tf.cast(bool_output,tf.int32)\n",
    "# output = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], int_output)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    t1 = time.time()\n",
    "    dist_ = sess.run(less)\n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    print(dist_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14561080932617188\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# tests unitaires\n",
    "\n",
    "tf.reset_default_graph()\n",
    "emb_raw = tf.constant([[12.,2],[8,4],[3,8],[2,10],[50,10],[10,30]])\n",
    "emb_ = tf.math.l2_normalize(emb_raw,0)\n",
    "\n",
    "# Normalizes\n",
    "emb = tf.math.l2_normalize(emb_,0)\n",
    "\n",
    "# Separates the pairs\n",
    "emb1 = emb[0::2]\n",
    "emb2 = emb[1::2]\n",
    "\n",
    "# Computes distance between pairs\n",
    "diff = tf.squared_difference(emb1,emb2)\n",
    "dist = tf.reduce_sum(diff,1)\n",
    "\n",
    "\n",
    "\n",
    "# Creates different threshold in order to find the best one\n",
    "np_threshold = np.vstack([np.arange(0,1,0.01)]*3).T\n",
    "\n",
    "# Reshapes the distance\n",
    "dist2 = tf.stack([dist]*len(np_threshold))\n",
    "\n",
    "# Reshapes the true values\n",
    "actual_issame = tf.constant([[True,True,False]]*len(np_threshold),dtype=bool)\n",
    "\n",
    "threshold = tf.constant(np_threshold, dtype=tf.float32)\n",
    "\n",
    "# Uses the created thresholds to compute the predictions\n",
    "predict_issame = tf.less(dist2,threshold)\n",
    "\n",
    "# Computes the accuracy\n",
    "truth = tf.logical_not(tf.logical_xor(predict_issame, actual_issame))\n",
    "\n",
    "r = tf.reduce_sum(tf.cast(truth,tf.float32),1)\n",
    "\n",
    "# Finds the best accuracy with respect to the threshold\n",
    "m = tf.argmax(r)\n",
    "\n",
    "# best_threshold = threshold[m]\n",
    "# accuracy = r[m]/3\n",
    "\n",
    "# Ouputs the best output and reshapes the output in a softmax way\n",
    "bool_output = predict_issame[m]\n",
    "int_output = tf.cast(bool_output,tf.int32)\n",
    "output = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], int_output)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    t1 = time.time()\n",
    "    act,pred,a_ = sess.run([actual_issame,truth,output])\n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    print(a_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Should only be used for validating\n",
    "class Validation(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Validation, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        self.emb_shape = input_shape[0]\n",
    "        super(Validation, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        \"\"\"\n",
    "        Inputs: a tuple containing the embeddings and the issame list\n",
    "        - embeddings: shape=(batch_size, embedding_size), type=float\n",
    "        - issame: shape=(batch_size), type=bool\n",
    "        \n",
    "        Outputs: a tensor of shape=(batch_size,2), the ouput is either [1,0] (is same) or [0,1] (is different)\n",
    "        \"\"\"\n",
    "        assert isinstance(x, list)\n",
    "        \n",
    "        embeddings, iss = x\n",
    "        \n",
    "        \n",
    "        \n",
    "        def train_output():\n",
    "            return iss\n",
    "        \n",
    "        def valid_output():\n",
    "            issame = tf.squeeze(iss)\n",
    "            #self.emb_shape = embeddings.shape\n",
    "            emb = tf.math.l2_normalize(embeddings,0)\n",
    "            # emb contains a list of pictures\n",
    "            # pictures with an even index are first pictures of the pairs\n",
    "            # pictures with an odd index are second pictures of the pairs\n",
    "            emb1 = embeddings[0::2]\n",
    "            emb2 = embeddings[1::2]\n",
    "            #emb1, emb2 = tf.split(embeddings, [32,32],0)\n",
    "            \n",
    "          # Compute the distance for each pair of vector\n",
    "            dist = tf.reduce_sum(tf.squared_difference(emb1,emb2),1)\n",
    "            dist = tf.reshape(tf.stack([dist,dist], axis=-1), [-1])\n",
    "            actual_issame_bool = tf.cast(issame,dtype=tf.bool)\n",
    "\n",
    "            def fn(t):\n",
    "                less = tf.less(dist,t)\n",
    "                acc = tf.logical_not(tf.logical_xor(less,actual_issame_bool))\n",
    "                acc = tf.cast(acc,tf.float32)\n",
    "                out = tf.reshape(tf.reduce_sum(acc),[])\n",
    "                return out\n",
    "\n",
    "\n",
    "            thresholds = tf.range(0,1,0.001)\n",
    "            apply_t = tf.map_fn(fn, thresholds)\n",
    "            best_t = tf.argmax(apply_t)\n",
    "\n",
    "            best = thresholds[best_t]\n",
    "\n",
    "          # Redo the manipulation with the best threshold\n",
    "            less = tf.less(dist,0.01)\n",
    "            less = tf.cast(less,tf.float32)\n",
    "            less = tf.expand_dims(less,1) # <- bug fixed\n",
    "            return less\n",
    "\n",
    "            \n",
    "        return K.in_train_phase(train_output,valid_output,training=training)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        emb_shape, _ = input_shape\n",
    "        return (emb_shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Dummy layers to try the testing/training phases\n",
    "class test(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(test, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(test, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        def train_output():\n",
    "            ret = tf.multiply(x,0.)\n",
    "            ret = tf.add(ret,1.)\n",
    "            #ret.set_shape(x.get_shape())\n",
    "            return ret\n",
    "        \n",
    "        def valid_output():\n",
    "            ret = tf.zeros_like(x)\n",
    "            return ret\n",
    "            \n",
    "        return K.in_train_phase(train_output,valid_output,training=training)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Dummy layers to try the testing/training phases\n",
    "class test(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(test, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(test, self).build(input_shape)\n",
    "\n",
    "    def call(self, y, training=None):\n",
    "        \n",
    "        x,iss = y\n",
    "        def train_output():\n",
    "            #ret = tf.multiply(x,0.)\n",
    "            #ret = tf.add(ret,1.)\n",
    "            #ret.set_shape(x.get_shape())\n",
    "            ret = iss\n",
    "            #ret.set_shape((iss.get_shape()[0],2))\n",
    "            return ret\n",
    "        \n",
    "        def valid_output():\n",
    "            ret = tf.zeros_like(iss)\n",
    "            return ret\n",
    "            \n",
    "        return K.in_train_phase(train_output,valid_output,training=training)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummiest(tf.keras.Model):\n",
    "    def __init__(self, emb_size = 32):\n",
    "        \"\"\"\n",
    "        -emb_size: size of the embedding\n",
    "        -out_num: number of identities in the \n",
    "        \"\"\"\n",
    "        super(EvenMoreDummy, self).__init__(name='even_more_dummy')\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10,(3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20,(3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(40,(3, 3))\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.layers.Dense(emb_size)\n",
    "        self.f = tf.layers.Dense(1301, name='out')\n",
    "    \n",
    "    def call(self, images, training=None):\n",
    "        \n",
    "        x = self.conv1(images)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        emb = tf.math.l2_normalize(x)\n",
    "        \n",
    "        return self.f(emb)\n",
    "\n",
    "model = Dummiest(32)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tests unitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "class EvenMoreDummy(tf.keras.Model):\n",
    "    def __init__(self, emb_size = 32):\n",
    "        \"\"\"\n",
    "        -emb_size: size of the embedding\n",
    "        -out_num: number of identities in the \n",
    "        \"\"\"\n",
    "        super(EvenMoreDummy, self).__init__(name='even_more_dummy')\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10,(3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20,(3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(40,(3, 3))\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.layers.Dense(emb_size)\n",
    "        self.drop = tf.keras.layers.Dropout(0.5)\n",
    "        self.f = tf.layers.Dense(1301, name='out')\n",
    "        self.test = test()\n",
    "    \n",
    "    def call(self, images, training=None):\n",
    "        \n",
    "        x = self.conv1(images)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.drop(x)\n",
    "        emb = tf.math.l2_normalize(x)\n",
    "        emb = self.f(emb)\n",
    "        emb = self.test(emb)\n",
    "\n",
    "        return emb\n",
    "\n",
    "model = EvenMoreDummy(32)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1301)\n",
      "(?,)\n",
      "(?, 1301)\n",
      "(?, 1301)\n",
      "(?, 1301)\n",
      "(?, 1301)\n",
      "(?, 1301)\n",
      "(?, 1301)\n"
     ]
    }
   ],
   "source": [
    "# Try to use the functional API\n",
    "tf.reset_default_graph()\n",
    "def net(inputs_shapes, emb_size=32):\n",
    "    images_shape, labels_shape, issame_shape = inputs_shapes\n",
    "    input_image = tf.keras.Input(images_shape,name='image_input')\n",
    "    x = tf.keras.layers.Conv2D(10,(3, 3))(input_image)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(20,(3, 3))(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(40,(3, 3))(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    emb = tf.keras.layers.Dense(emb_size, activity_regularizer='l2')(x)\n",
    "    #out = tf.keras.layers.Dense(1301, name='arcface')(emb)\n",
    "    \n",
    "    input_labels = tf.keras.Input(labels_shape,name='input_labels')\n",
    "    out = Arcface(1301, name='arcface')([emb,input_labels])\n",
    "                                         \n",
    "    input_issame = tf.keras.Input(issame_shape,name='issame_input')\n",
    "    valid = Validation(name='validation')([emb,input_issame])\n",
    "    \n",
    "    return tf.keras.Model(inputs=[input_image,input_labels,input_issame], outputs=[out,valid])\n",
    "\n",
    "w, h, c = SIZE\n",
    "inputs_shapes = [(w, h, c,),(1,),(1,)]\n",
    "model = net(inputs_shapes)\n",
    "model.compile(tf.train.AdamOptimizer(),loss={'arcface':'mse','validation':'binary_crossentropy'},metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_out = tf.keras.utils.to_categorical(labels_train,NBOF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4734,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train = np.ones(labels_train.shape)\n",
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_valid_out = tf.keras.utils.to_categorical(labels_valid-NBOF_CLASSES,NBOF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1300, 1300, 1300, 1301, 1301, 1301, 1301, 1301, 1302, 1302, 1302,\n",
       "       1302, 1302, 1302, 1302, 1303, 1303, 1303, 1303, 1303, 1303, 1304,\n",
       "       1304, 1304, 1304, 1305, 1305, 1305, 1306, 1306, 1306, 1307, 1307,\n",
       "       1308, 1308, 1309, 1309, 1309, 1310, 1310, 1310, 1311, 1311, 1311,\n",
       "       1312, 1312, 1313, 1313, 1314, 1314, 1314, 1315, 1315, 1315, 1315,\n",
       "       1315, 1315, 1315, 1315, 1316, 1316, 1316, 1317, 1317, 1317, 1317,\n",
       "       1318, 1318, 1318, 1318, 1318, 1319, 1319, 1319, 1319, 1319, 1319,\n",
       "       1319, 1320, 1320, 1321, 1321, 1321, 1322, 1322, 1322, 1322, 1323,\n",
       "       1323, 1323, 1323, 1323, 1323, 1324, 1324, 1324, 1324, 1325, 1325,\n",
       "       1325, 1326, 1326, 1327, 1327, 1328, 1328, 1329, 1329, 1330, 1330,\n",
       "       1330, 1330, 1330, 1331, 1331, 1331, 1332, 1332, 1332, 1332, 1333,\n",
       "       1333, 1333, 1334, 1334, 1334, 1335, 1335, 1335, 1336, 1336, 1336,\n",
       "       1336, 1336, 1336, 1336, 1337, 1337, 1338, 1338, 1339, 1339, 1340,\n",
       "       1340, 1340, 1341, 1341, 1342, 1342, 1342, 1343, 1343, 1344, 1344,\n",
       "       1344, 1345, 1345, 1346, 1346, 1347, 1347, 1348, 1348, 1348, 1349,\n",
       "       1349, 1350, 1350, 1350, 1350, 1351, 1351, 1351, 1351, 1351, 1352,\n",
       "       1352, 1352, 1352, 1352, 1353, 1353, 1353, 1353, 1354, 1354, 1354,\n",
       "       1354, 1355, 1355, 1355, 1355, 1355, 1355, 1356, 1356, 1357, 1357,\n",
       "       1357, 1358, 1358, 1358, 1358, 1359, 1359, 1359, 1359, 1359, 1359,\n",
       "       1360, 1360, 1360, 1361, 1361, 1362, 1362, 1363, 1363, 1363, 1364,\n",
       "       1364, 1365, 1365, 1366, 1366, 1366, 1366, 1367, 1367, 1368, 1368,\n",
       "       1368, 1369, 1369, 1370, 1370, 1370, 1371, 1371, 1372, 1372, 1372,\n",
       "       1372, 1372, 1372, 1372, 1372, 1372, 1372, 1373, 1373, 1373, 1373,\n",
       "       1373, 1374, 1374, 1374, 1374, 1374, 1374, 1374, 1375, 1375, 1376,\n",
       "       1376, 1376, 1377, 1377, 1378, 1378, 1378, 1378, 1378, 1378, 1379,\n",
       "       1379, 1379, 1380, 1380, 1380, 1381, 1381, 1381, 1382, 1382, 1383,\n",
       "       1383, 1384, 1384, 1385, 1385, 1386, 1386, 1387, 1387, 1388, 1388,\n",
       "       1389, 1389, 1390, 1390, 1390, 1390, 1391, 1391, 1391, 1391, 1392,\n",
       "       1392, 1392, 1393, 1393, 1394, 1394, 1394, 1395, 1395, 1395, 1396,\n",
       "       1396, 1396, 1396, 1397, 1397, 1398, 1398, 1399, 1399, 1399, 1400,\n",
       "       1400, 1401, 1401, 1401, 1402, 1402, 1402, 1403, 1403, 1403, 1403,\n",
       "       1403, 1404, 1404, 1404, 1404, 1404, 1405, 1405, 1405, 1405, 1405,\n",
       "       1405, 1406, 1406, 1406, 1407, 1407, 1408, 1408, 1409, 1409, 1410,\n",
       "       1410, 1411, 1411, 1412, 1412, 1412, 1412, 1413, 1413, 1413, 1414,\n",
       "       1414, 1415, 1415, 1415, 1416, 1416, 1416, 1417, 1417, 1417, 1418,\n",
       "       1418, 1418, 1418, 1419, 1419, 1420, 1420, 1420, 1421, 1421, 1421,\n",
       "       1422, 1422, 1422, 1423, 1423, 1424, 1424, 1425, 1425, 1426, 1426,\n",
       "       1427, 1427, 1428, 1428, 1428, 1429, 1429, 1430, 1430, 1430, 1430,\n",
       "       1430, 1431, 1431, 1431, 1431, 1432, 1432, 1433, 1433, 1433, 1433,\n",
       "       1433, 1434, 1434, 1434, 1435, 1435, 1436, 1436, 1437, 1437, 1438,\n",
       "       1438, 1439, 1439, 1439, 1439, 1439, 1439, 1440, 1440, 1440, 1440,\n",
       "       1440, 1440, 1440, 1441, 1441, 1442, 1442, 1442, 1443, 1443, 1443,\n",
       "       1443, 1443, 1444, 1444, 1445, 1445, 1446, 1446, 1446, 1447, 1447,\n",
       "       1447, 1448, 1448, 1448, 1448, 1448, 1449, 1449, 1449, 1449, 1450,\n",
       "       1450, 1450, 1451, 1451, 1451, 1451, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1453])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_valid = np.zeros(labels_valid.shape)\n",
    "labels_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inputs:\n",
      "[[[[ 0.01171875 -0.44921875 -0.29296875]\n",
      "   [ 0.05078125 -0.45703125 -0.28515625]\n",
      "   [ 0.19140625 -0.39453125 -0.16015625]\n",
      "   ...\n",
      "   [ 0.98828125  0.99609375  0.99609375]\n",
      "   [ 0.98828125  0.99609375  0.99609375]\n",
      "   [ 0.98046875  0.98828125  0.99609375]]\n",
      "\n",
      "  [[-0.14453125 -0.55859375 -0.43359375]\n",
      "   [-0.13671875 -0.58203125 -0.43359375]\n",
      "   [-0.04296875 -0.55078125 -0.36328125]\n",
      "   ...\n",
      "   [ 0.94140625  0.94921875  0.96484375]\n",
      "   [ 0.96484375  0.97265625  0.98828125]\n",
      "   [ 0.87890625  0.88671875  0.90234375]]\n",
      "\n",
      "  [[-0.09765625 -0.39453125 -0.30859375]\n",
      "   [-0.11328125 -0.44140625 -0.34765625]\n",
      "   [-0.08984375 -0.48828125 -0.33984375]\n",
      "   ...\n",
      "   [ 0.98828125  0.99609375  0.99609375]\n",
      "   [ 0.97265625  0.98046875  0.99609375]\n",
      "   [ 0.76171875  0.76953125  0.78515625]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.21484375 -0.12109375 -0.45703125]\n",
      "   [ 0.09765625 -0.25390625 -0.57421875]\n",
      "   [ 0.30078125 -0.07421875 -0.35546875]\n",
      "   ...\n",
      "   [-0.03515625  0.05078125 -0.48828125]\n",
      "   [-0.01953125  0.06640625 -0.47265625]\n",
      "   [-0.05078125  0.02734375 -0.51171875]]\n",
      "\n",
      "  [[ 0.05859375 -0.26953125 -0.59765625]\n",
      "   [ 0.09765625 -0.24609375 -0.55078125]\n",
      "   [ 0.44921875  0.08984375 -0.17578125]\n",
      "   ...\n",
      "   [-0.16796875 -0.04296875 -0.59765625]\n",
      "   [-0.15234375 -0.02734375 -0.58203125]\n",
      "   [-0.16015625 -0.05859375 -0.60546875]]\n",
      "\n",
      "  [[ 0.51953125  0.21484375 -0.08984375]\n",
      "   [ 0.43359375  0.09765625 -0.17578125]\n",
      "   [ 0.44921875  0.09765625 -0.16015625]\n",
      "   ...\n",
      "   [-0.11328125  0.04296875 -0.51953125]\n",
      "   [-0.09765625  0.05859375 -0.50390625]\n",
      "   [-0.08984375  0.04296875 -0.51171875]]]\n",
      "\n",
      "\n",
      " [[[ 0.17578125  0.28515625  0.30859375]\n",
      "   [ 0.21484375  0.32421875  0.34765625]\n",
      "   [ 0.30078125  0.38671875  0.41796875]\n",
      "   ...\n",
      "   [ 0.96484375  0.99609375  0.98828125]\n",
      "   [ 0.96484375  0.99609375  0.98828125]\n",
      "   [ 0.96484375  0.99609375  0.98828125]]\n",
      "\n",
      "  [[ 0.72265625  0.83203125  0.85546875]\n",
      "   [ 0.18359375  0.26953125  0.30078125]\n",
      "   [ 0.23828125  0.32421875  0.35546875]\n",
      "   ...\n",
      "   [ 0.96484375  0.99609375  0.98828125]\n",
      "   [ 0.96484375  0.99609375  0.98828125]\n",
      "   [ 0.96484375  0.99609375  0.98828125]]\n",
      "\n",
      "  [[ 0.83984375  0.92578125  0.95703125]\n",
      "   [ 0.47265625  0.55859375  0.58984375]\n",
      "   [ 0.18359375  0.25390625  0.29296875]\n",
      "   ...\n",
      "   [ 0.98046875  0.99609375  0.98828125]\n",
      "   [ 0.98046875  0.99609375  0.98828125]\n",
      "   [ 0.98046875  0.99609375  0.98828125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.11328125 -0.07421875 -0.27734375]\n",
      "   [ 0.09765625 -0.08984375 -0.29296875]\n",
      "   [ 0.05078125 -0.15234375 -0.34765625]\n",
      "   ...\n",
      "   [ 0.34765625  0.26171875  0.01171875]\n",
      "   [ 0.28515625  0.19921875 -0.05078125]\n",
      "   [ 0.41796875  0.33203125  0.08203125]]\n",
      "\n",
      "  [[ 0.43359375  0.24609375  0.05859375]\n",
      "   [ 0.32421875  0.13671875 -0.05078125]\n",
      "   [ 0.16015625 -0.04296875 -0.23828125]\n",
      "   ...\n",
      "   [ 0.32421875  0.23828125 -0.01171875]\n",
      "   [ 0.27734375  0.19140625 -0.05859375]\n",
      "   [ 0.25390625  0.16796875 -0.08203125]]\n",
      "\n",
      "  [[ 0.42578125  0.23046875  0.05859375]\n",
      "   [ 0.16796875 -0.04296875 -0.20703125]\n",
      "   [-0.12109375 -0.32421875 -0.50390625]\n",
      "   ...\n",
      "   [ 0.25390625  0.16796875 -0.08203125]\n",
      "   [ 0.23046875  0.14453125 -0.10546875]\n",
      "   [ 0.16015625  0.07421875 -0.17578125]]]\n",
      "\n",
      "\n",
      " [[[ 0.00390625  0.06640625  0.34765625]\n",
      "   [ 0.04296875  0.11328125  0.37109375]\n",
      "   [ 0.14453125  0.21484375  0.44140625]\n",
      "   ...\n",
      "   [-0.46484375 -0.44921875 -0.48828125]\n",
      "   [-0.52734375 -0.51171875 -0.55078125]\n",
      "   [-0.51953125 -0.50390625 -0.54296875]]\n",
      "\n",
      "  [[ 0.32421875  0.38671875  0.66796875]\n",
      "   [ 0.23046875  0.30078125  0.55859375]\n",
      "   [ 0.18359375  0.23828125  0.46484375]\n",
      "   ...\n",
      "   [-0.52734375 -0.50390625 -0.55859375]\n",
      "   [-0.58203125 -0.55859375 -0.62890625]\n",
      "   [-0.54296875 -0.51953125 -0.58984375]]\n",
      "\n",
      "  [[ 0.23046875  0.27734375  0.52734375]\n",
      "   [ 0.30078125  0.35546875  0.58203125]\n",
      "   [ 0.19921875  0.25390625  0.45703125]\n",
      "   ...\n",
      "   [-0.51953125 -0.48828125 -0.59765625]\n",
      "   [-0.58984375 -0.55859375 -0.66796875]\n",
      "   [-0.58203125 -0.55078125 -0.66015625]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.05078125 -0.23828125 -0.53515625]\n",
      "   [-0.05859375 -0.26171875 -0.55078125]\n",
      "   [-0.05859375 -0.25390625 -0.56640625]\n",
      "   ...\n",
      "   [ 0.37109375 -0.40234375  0.04296875]\n",
      "   [ 0.30859375 -0.46484375 -0.01953125]\n",
      "   [ 0.28515625 -0.48828125 -0.04296875]]\n",
      "\n",
      "  [[-0.02734375 -0.19921875 -0.48828125]\n",
      "   [-0.21484375 -0.40234375 -0.69921875]\n",
      "   [-0.14453125 -0.34765625 -0.63671875]\n",
      "   ...\n",
      "   [ 0.70703125 -0.06640625  0.37890625]\n",
      "   [ 0.66015625 -0.11328125  0.33203125]\n",
      "   [ 0.54296875 -0.23046875  0.21484375]]\n",
      "\n",
      "  [[-0.15234375 -0.30859375 -0.58203125]\n",
      "   [-0.39453125 -0.55078125 -0.83984375]\n",
      "   [-0.20703125 -0.37890625 -0.66796875]\n",
      "   ...\n",
      "   [ 0.52734375 -0.24609375  0.19921875]\n",
      "   [ 0.69140625 -0.08203125  0.36328125]\n",
      "   [ 0.65234375 -0.12109375  0.32421875]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.05078125  0.19921875  0.30859375]\n",
      "   [-0.13671875  0.00390625  0.08203125]\n",
      "   [-0.19140625 -0.08984375 -0.04296875]\n",
      "   ...\n",
      "   [-0.27734375 -0.28515625 -0.30078125]\n",
      "   [-0.26171875 -0.26953125 -0.28515625]\n",
      "   [-0.26171875 -0.26953125 -0.28515625]]\n",
      "\n",
      "  [[-0.21484375 -0.10546875 -0.03515625]\n",
      "   [-0.25390625 -0.15234375 -0.10546875]\n",
      "   [-0.19921875 -0.13671875 -0.12109375]\n",
      "   ...\n",
      "   [-0.23046875 -0.23828125 -0.25390625]\n",
      "   [-0.21484375 -0.22265625 -0.23828125]\n",
      "   [-0.21484375 -0.22265625 -0.23828125]]\n",
      "\n",
      "  [[-0.17578125 -0.11328125 -0.08984375]\n",
      "   [-0.06640625 -0.03515625 -0.02734375]\n",
      "   [ 0.05859375  0.05078125  0.01953125]\n",
      "   ...\n",
      "   [-0.25390625 -0.26171875 -0.29296875]\n",
      "   [-0.23828125 -0.24609375 -0.27734375]\n",
      "   [-0.23828125 -0.24609375 -0.27734375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.44140625  0.41796875  0.30078125]\n",
      "   [ 0.51953125  0.49609375  0.37890625]\n",
      "   [ 0.42578125  0.37890625  0.26953125]\n",
      "   ...\n",
      "   [ 0.56640625  0.47265625  0.36328125]\n",
      "   [ 0.58203125  0.48828125  0.37890625]\n",
      "   [ 0.56640625  0.47265625  0.36328125]]\n",
      "\n",
      "  [[ 0.39453125  0.37109375  0.25390625]\n",
      "   [ 0.51171875  0.48828125  0.37109375]\n",
      "   [ 0.41796875  0.37109375  0.26171875]\n",
      "   ...\n",
      "   [ 0.44921875  0.35546875  0.24609375]\n",
      "   [ 0.48828125  0.39453125  0.28515625]\n",
      "   [ 0.49609375  0.40234375  0.29296875]]\n",
      "\n",
      "  [[ 0.43359375  0.41015625  0.29296875]\n",
      "   [ 0.49609375  0.47265625  0.35546875]\n",
      "   [ 0.38671875  0.33984375  0.23046875]\n",
      "   ...\n",
      "   [ 0.50390625  0.41015625  0.30078125]\n",
      "   [ 0.55859375  0.46484375  0.35546875]\n",
      "   [ 0.55859375  0.46484375  0.35546875]]]\n",
      "\n",
      "\n",
      " [[[-0.69921875 -0.72265625 -0.65234375]\n",
      "   [-0.98828125 -0.99609375 -0.94140625]\n",
      "   [-0.73828125 -0.74609375 -0.68359375]\n",
      "   ...\n",
      "   [-0.44140625 -0.35546875 -0.38671875]\n",
      "   [-0.40234375 -0.31640625 -0.34765625]\n",
      "   [-0.47265625 -0.38671875 -0.41796875]]\n",
      "\n",
      "  [[-0.67578125 -0.69921875 -0.62890625]\n",
      "   [-0.94140625 -0.95703125 -0.87109375]\n",
      "   [-0.95703125 -0.95703125 -0.87890625]\n",
      "   ...\n",
      "   [-0.47265625 -0.40234375 -0.42578125]\n",
      "   [-0.48046875 -0.41015625 -0.43359375]\n",
      "   [-0.44921875 -0.37890625 -0.40234375]]\n",
      "\n",
      "  [[-0.90234375 -0.91796875 -0.81640625]\n",
      "   [-0.86328125 -0.87890625 -0.77734375]\n",
      "   [-0.83984375 -0.83984375 -0.74609375]\n",
      "   ...\n",
      "   [-0.27734375 -0.20703125 -0.23046875]\n",
      "   [-0.59765625 -0.52734375 -0.55078125]\n",
      "   [-0.66015625 -0.58984375 -0.61328125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.30078125  0.32421875  0.36328125]\n",
      "   [ 0.23046875  0.28515625  0.34765625]\n",
      "   [-0.12890625 -0.03515625  0.07421875]\n",
      "   ...\n",
      "   [ 0.45703125  0.37890625  0.28515625]\n",
      "   [ 0.37890625  0.30078125  0.20703125]\n",
      "   [ 0.42578125  0.34765625  0.25390625]]\n",
      "\n",
      "  [[ 0.31640625  0.33984375  0.37890625]\n",
      "   [ 0.20703125  0.26171875  0.32421875]\n",
      "   [-0.00390625  0.08984375  0.19921875]\n",
      "   ...\n",
      "   [ 0.46484375  0.38671875  0.29296875]\n",
      "   [ 0.37890625  0.30078125  0.20703125]\n",
      "   [ 0.42578125  0.34765625  0.25390625]]\n",
      "\n",
      "  [[ 0.34765625  0.37109375  0.41015625]\n",
      "   [ 0.15234375  0.20703125  0.26953125]\n",
      "   [ 0.05859375  0.15234375  0.26171875]\n",
      "   ...\n",
      "   [ 0.49609375  0.41796875  0.32421875]\n",
      "   [ 0.39453125  0.31640625  0.22265625]\n",
      "   [ 0.44140625  0.36328125  0.26953125]]]\n",
      "\n",
      "\n",
      " [[[-0.65234375 -0.56640625 -0.81640625]\n",
      "   [-0.36328125 -0.28515625 -0.55078125]\n",
      "   [-0.24609375 -0.16796875 -0.44140625]\n",
      "   ...\n",
      "   [ 0.07421875  0.24609375  0.35546875]\n",
      "   [-0.16796875 -0.01953125  0.09765625]\n",
      "   [-0.30859375 -0.17578125 -0.05078125]]\n",
      "\n",
      "  [[-0.54296875 -0.48828125 -0.74609375]\n",
      "   [-0.46484375 -0.41015625 -0.66796875]\n",
      "   [-0.44140625 -0.39453125 -0.66015625]\n",
      "   ...\n",
      "   [-0.11328125  0.05859375  0.16015625]\n",
      "   [-0.27734375 -0.12890625 -0.01953125]\n",
      "   [-0.41796875 -0.27734375 -0.16796875]]\n",
      "\n",
      "  [[-0.45703125 -0.44921875 -0.69140625]\n",
      "   [-0.49609375 -0.48828125 -0.73046875]\n",
      "   [-0.51953125 -0.51171875 -0.76171875]\n",
      "   ...\n",
      "   [-0.12890625  0.01953125  0.12890625]\n",
      "   [-0.33203125 -0.18359375 -0.07421875]\n",
      "   [-0.33984375 -0.19921875 -0.10546875]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.16015625 -0.01953125 -0.66015625]\n",
      "   [-0.23046875 -0.08984375 -0.73046875]\n",
      "   [-0.25390625 -0.12109375 -0.74609375]\n",
      "   ...\n",
      "   [ 0.16015625  0.05859375 -0.28515625]\n",
      "   [-0.11328125 -0.23046875 -0.56640625]\n",
      "   [-0.00390625 -0.12109375 -0.45703125]]\n",
      "\n",
      "  [[ 0.07421875  0.21484375 -0.42578125]\n",
      "   [-0.16015625 -0.01953125 -0.66015625]\n",
      "   [-0.12890625  0.00390625 -0.62109375]\n",
      "   ...\n",
      "   [-0.07421875 -0.19140625 -0.52734375]\n",
      "   [-0.37109375 -0.48828125 -0.82421875]\n",
      "   [-0.25390625 -0.37109375 -0.70703125]]\n",
      "\n",
      "  [[ 0.01953125  0.16015625 -0.49609375]\n",
      "   [-0.09765625  0.04296875 -0.59765625]\n",
      "   [ 0.08984375  0.23046875 -0.41015625]\n",
      "   ...\n",
      "   [-0.01171875 -0.12890625 -0.46484375]\n",
      "   [-0.16015625 -0.27734375 -0.61328125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [ 0.06640625 -0.05078125 -0.38671875]]]]\n",
      "[   0    0    0 ... 1299 1299 1300]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "Train outputs\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "Valid inputs\n",
      "[[[[ 0.78515625  0.55078125  0.28515625]\n",
      "   [-0.24609375 -0.46484375 -0.75390625]\n",
      "   [-0.02734375 -0.24609375 -0.53515625]\n",
      "   ...\n",
      "   [-0.54296875 -0.58203125 -0.73046875]\n",
      "   [-0.05859375 -0.10546875 -0.23046875]\n",
      "   [ 0.91015625  0.86328125  0.75390625]]\n",
      "\n",
      "  [[ 0.68359375  0.45703125  0.19140625]\n",
      "   [-0.12109375 -0.34765625 -0.61328125]\n",
      "   [ 0.01171875 -0.20703125 -0.49609375]\n",
      "   ...\n",
      "   [-0.76953125 -0.80859375 -0.95703125]\n",
      "   [-0.44921875 -0.49609375 -0.62109375]\n",
      "   [ 0.83203125  0.78515625  0.67578125]]\n",
      "\n",
      "  [[ 0.76171875  0.55859375  0.30078125]\n",
      "   [-0.12109375 -0.32421875 -0.59765625]\n",
      "   [ 0.10546875 -0.09765625 -0.37109375]\n",
      "   ...\n",
      "   [-0.79296875 -0.83984375 -0.96484375]\n",
      "   [-0.55078125 -0.57421875 -0.69140625]\n",
      "   [ 0.83203125  0.80078125  0.70703125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.66015625  0.73828125  0.44921875]\n",
      "   [ 0.02734375  0.15234375 -0.41796875]\n",
      "   [-0.02734375  0.14453125 -0.70703125]\n",
      "   ...\n",
      "   [-0.17578125 -0.19140625 -0.48828125]\n",
      "   [-0.23828125 -0.26171875 -0.53515625]\n",
      "   [ 0.85546875  0.83203125  0.57421875]]\n",
      "\n",
      "  [[ 0.68359375  0.76171875  0.47265625]\n",
      "   [ 0.05078125  0.17578125 -0.39453125]\n",
      "   [ 0.06640625  0.23828125 -0.61328125]\n",
      "   ...\n",
      "   [-0.28515625 -0.31640625 -0.60546875]\n",
      "   [-0.26953125 -0.29296875 -0.56640625]\n",
      "   [ 0.81640625  0.79296875  0.53515625]]\n",
      "\n",
      "  [[ 0.62890625  0.70703125  0.41796875]\n",
      "   [ 0.08203125  0.20703125 -0.36328125]\n",
      "   [ 0.13671875  0.30859375 -0.54296875]\n",
      "   ...\n",
      "   [-0.37890625 -0.41015625 -0.68359375]\n",
      "   [-0.23828125 -0.26953125 -0.54296875]\n",
      "   [ 0.83203125  0.79296875  0.55859375]]]\n",
      "\n",
      "\n",
      " [[[ 0.98046875  0.99609375  0.88671875]\n",
      "   [ 0.98828125  0.98046875  0.94921875]\n",
      "   [ 0.99609375  0.97265625  0.99609375]\n",
      "   ...\n",
      "   [ 0.98828125  0.98828125  0.98828125]\n",
      "   [ 0.98828125  0.98828125  0.98828125]\n",
      "   [ 0.98828125  0.98828125  0.98828125]]\n",
      "\n",
      "  [[ 0.99609375  0.99609375  0.90234375]\n",
      "   [ 0.99609375  0.99609375  0.96484375]\n",
      "   [ 0.99609375  0.97265625  0.99609375]\n",
      "   ...\n",
      "   [ 0.98828125  0.98828125  0.98828125]\n",
      "   [ 0.98828125  0.98828125  0.98828125]\n",
      "   [ 0.98828125  0.98828125  0.98828125]]\n",
      "\n",
      "  [[ 0.98828125  0.99609375  0.90234375]\n",
      "   [ 0.99609375  0.99609375  0.96484375]\n",
      "   [ 0.99609375  0.98046875  0.99609375]\n",
      "   ...\n",
      "   [ 0.98828125  0.98828125  0.98828125]\n",
      "   [ 0.98828125  0.98828125  0.98828125]\n",
      "   [ 0.98828125  0.98828125  0.98828125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.97265625  0.98046875  0.99609375]\n",
      "   [ 0.98828125  0.99609375  0.95703125]\n",
      "   [ 0.94921875  0.97265625  0.88671875]\n",
      "   ...\n",
      "   [ 0.98828125  0.98828125  0.98828125]\n",
      "   [ 0.99609375  0.99609375  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.99609375]]\n",
      "\n",
      "  [[ 0.98046875  0.98828125  0.99609375]\n",
      "   [ 0.98828125  0.99609375  0.95703125]\n",
      "   [ 0.96484375  0.98828125  0.90234375]\n",
      "   ...\n",
      "   [ 0.98828125  0.98828125  0.98828125]\n",
      "   [ 0.99609375  0.99609375  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.99609375]]\n",
      "\n",
      "  [[ 0.98046875  0.98828125  0.99609375]\n",
      "   [ 0.98046875  0.99609375  0.94921875]\n",
      "   [ 0.97265625  0.99609375  0.91015625]\n",
      "   ...\n",
      "   [ 0.98828125  0.98828125  0.98828125]\n",
      "   [ 0.99609375  0.99609375  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.99609375]]]\n",
      "\n",
      "\n",
      " [[[ 0.96484375  0.99609375  0.98046875]\n",
      "   [ 0.96484375  0.99609375  0.98828125]\n",
      "   [ 0.96484375  0.99609375  0.99609375]\n",
      "   ...\n",
      "   [ 0.98046875  0.98046875  0.98046875]\n",
      "   [ 0.98046875  0.98046875  0.98046875]\n",
      "   [ 0.98046875  0.98046875  0.98046875]]\n",
      "\n",
      "  [[ 0.97265625  0.99609375  0.98046875]\n",
      "   [ 0.96484375  0.99609375  0.98828125]\n",
      "   [ 0.96484375  0.99609375  0.99609375]\n",
      "   ...\n",
      "   [ 0.98046875  0.98046875  0.98046875]\n",
      "   [ 0.98046875  0.98046875  0.98046875]\n",
      "   [ 0.98046875  0.98046875  0.98046875]]\n",
      "\n",
      "  [[ 0.97265625  0.99609375  0.98046875]\n",
      "   [ 0.96484375  0.99609375  0.97265625]\n",
      "   [ 0.96484375  0.99609375  0.99609375]\n",
      "   ...\n",
      "   [ 0.98046875  0.98046875  0.98046875]\n",
      "   [ 0.98046875  0.98046875  0.98046875]\n",
      "   [ 0.98046875  0.98046875  0.98046875]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.99609375  0.98046875  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.96484375]\n",
      "   [ 0.99609375  0.99609375  0.90234375]\n",
      "   ...\n",
      "   [ 0.99609375  0.99609375  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.99609375]]\n",
      "\n",
      "  [[ 0.99609375  0.98046875  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.96484375]\n",
      "   [ 0.99609375  0.99609375  0.90234375]\n",
      "   ...\n",
      "   [ 0.99609375  0.99609375  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.99609375]]\n",
      "\n",
      "  [[ 0.99609375  0.98046875  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.96484375]\n",
      "   [ 0.99609375  0.99609375  0.90234375]\n",
      "   ...\n",
      "   [ 0.99609375  0.99609375  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.99609375]\n",
      "   [ 0.99609375  0.99609375  0.99609375]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.44921875 -0.31640625 -0.23828125]\n",
      "   [-0.45703125 -0.32421875 -0.24609375]\n",
      "   [-0.43359375 -0.30078125 -0.22265625]\n",
      "   ...\n",
      "   [-0.87890625 -0.76171875 -0.73828125]\n",
      "   [-0.87109375 -0.76171875 -0.75390625]\n",
      "   [-0.80859375 -0.71484375 -0.71484375]]\n",
      "\n",
      "  [[-0.44140625 -0.30859375 -0.23046875]\n",
      "   [-0.45703125 -0.32421875 -0.24609375]\n",
      "   [-0.43359375 -0.30078125 -0.22265625]\n",
      "   ...\n",
      "   [-0.87890625 -0.76171875 -0.73828125]\n",
      "   [-0.87890625 -0.76953125 -0.76171875]\n",
      "   [-0.82421875 -0.73046875 -0.73046875]]\n",
      "\n",
      "  [[-0.44140625 -0.30859375 -0.23046875]\n",
      "   [-0.44921875 -0.31640625 -0.23828125]\n",
      "   [-0.42578125 -0.29296875 -0.21484375]\n",
      "   ...\n",
      "   [-0.87890625 -0.76171875 -0.73828125]\n",
      "   [-0.89453125 -0.78515625 -0.77734375]\n",
      "   [-0.84765625 -0.75390625 -0.75390625]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.15234375  0.16015625  0.19921875]\n",
      "   [ 0.12109375  0.01953125 -0.04296875]\n",
      "   [ 0.27734375  0.01171875 -0.19921875]\n",
      "   ...\n",
      "   [-0.41015625 -0.30859375 -0.26171875]\n",
      "   [-0.41015625 -0.30859375 -0.26171875]\n",
      "   [-0.41015625 -0.30859375 -0.26171875]]\n",
      "\n",
      "  [[ 0.04296875  0.06640625  0.12109375]\n",
      "   [ 0.03515625 -0.05078125 -0.09765625]\n",
      "   [ 0.22265625 -0.02734375 -0.22265625]\n",
      "   ...\n",
      "   [-0.42578125 -0.32421875 -0.27734375]\n",
      "   [-0.42578125 -0.32421875 -0.27734375]\n",
      "   [-0.42578125 -0.32421875 -0.27734375]]\n",
      "\n",
      "  [[-0.00390625  0.02734375  0.09765625]\n",
      "   [-0.00390625 -0.05859375 -0.10546875]\n",
      "   [ 0.19140625 -0.04296875 -0.23046875]\n",
      "   ...\n",
      "   [-0.44140625 -0.33984375 -0.29296875]\n",
      "   [-0.44140625 -0.33984375 -0.29296875]\n",
      "   [-0.44140625 -0.33984375 -0.29296875]]]\n",
      "\n",
      "\n",
      " [[[-0.30078125 -0.04296875 -0.25390625]\n",
      "   [-0.20703125  0.01171875 -0.18359375]\n",
      "   [-0.37109375 -0.19140625 -0.39453125]\n",
      "   ...\n",
      "   [ 0.44921875  0.38671875  0.23828125]\n",
      "   [ 0.53515625  0.47265625  0.32421875]\n",
      "   [ 0.51953125  0.45703125  0.30859375]]\n",
      "\n",
      "  [[-0.00390625  0.26953125  0.03515625]\n",
      "   [-0.34765625 -0.11328125 -0.33203125]\n",
      "   [-0.08203125  0.11328125 -0.11328125]\n",
      "   ...\n",
      "   [ 0.41015625  0.35546875  0.20703125]\n",
      "   [ 0.47265625  0.41796875  0.26953125]\n",
      "   [ 0.45703125  0.40234375  0.25390625]]\n",
      "\n",
      "  [[-0.05859375  0.23046875 -0.03515625]\n",
      "   [-0.32421875 -0.05859375 -0.31640625]\n",
      "   [-0.05859375  0.15234375 -0.08984375]\n",
      "   ...\n",
      "   [ 0.59765625  0.54296875  0.39453125]\n",
      "   [ 0.64453125  0.58984375  0.44140625]\n",
      "   [ 0.63671875  0.58203125  0.43359375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.23828125  0.00390625 -0.07421875]\n",
      "   [ 0.17578125 -0.00390625 -0.05078125]\n",
      "   [ 0.05859375 -0.07421875 -0.13671875]\n",
      "   ...\n",
      "   [-0.01171875  0.11328125 -0.16796875]\n",
      "   [-0.23046875 -0.09765625 -0.37890625]\n",
      "   [-0.41015625 -0.25390625 -0.54296875]]\n",
      "\n",
      "  [[ 0.26953125  0.03515625 -0.04296875]\n",
      "   [ 0.12109375 -0.05859375 -0.10546875]\n",
      "   [ 0.10546875 -0.02734375 -0.08984375]\n",
      "   ...\n",
      "   [-0.16015625 -0.05078125 -0.30859375]\n",
      "   [-0.21484375 -0.09765625 -0.35546875]\n",
      "   [-0.19140625 -0.05859375 -0.32421875]]\n",
      "\n",
      "  [[ 0.19921875 -0.03515625 -0.11328125]\n",
      "   [-0.01953125 -0.19921875 -0.24609375]\n",
      "   [ 0.08984375 -0.04296875 -0.10546875]\n",
      "   ...\n",
      "   [-0.22265625 -0.13671875 -0.37109375]\n",
      "   [-0.60546875 -0.50390625 -0.73828125]\n",
      "   [-0.69921875 -0.58203125 -0.82421875]]]\n",
      "\n",
      "\n",
      " [[[ 0.48828125  0.58203125  0.75390625]\n",
      "   [ 0.48828125  0.58203125  0.75390625]\n",
      "   [ 0.49609375  0.58984375  0.76171875]\n",
      "   ...\n",
      "   [ 0.36328125  0.51953125  0.73046875]\n",
      "   [ 0.35546875  0.51171875  0.72265625]\n",
      "   [ 0.34765625  0.50390625  0.71484375]]\n",
      "\n",
      "  [[ 0.48828125  0.58203125  0.75390625]\n",
      "   [ 0.49609375  0.58984375  0.76171875]\n",
      "   [ 0.49609375  0.58984375  0.76171875]\n",
      "   ...\n",
      "   [ 0.37109375  0.52734375  0.73828125]\n",
      "   [ 0.36328125  0.51953125  0.73046875]\n",
      "   [ 0.35546875  0.51171875  0.72265625]]\n",
      "\n",
      "  [[ 0.50390625  0.59765625  0.76953125]\n",
      "   [ 0.50390625  0.59765625  0.76953125]\n",
      "   [ 0.50390625  0.59765625  0.76953125]\n",
      "   ...\n",
      "   [ 0.37890625  0.53515625  0.73046875]\n",
      "   [ 0.37109375  0.52734375  0.72265625]\n",
      "   [ 0.36328125  0.51953125  0.71484375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.42578125 -0.51953125 -0.69140625]\n",
      "   [-0.40234375 -0.49609375 -0.68359375]\n",
      "   [-0.47265625 -0.55078125 -0.76171875]\n",
      "   ...\n",
      "   [-0.46484375 -0.51953125 -0.87890625]\n",
      "   [-0.51171875 -0.56640625 -0.92578125]\n",
      "   [-0.51953125 -0.57421875 -0.93359375]]\n",
      "\n",
      "  [[-0.44140625 -0.53515625 -0.70703125]\n",
      "   [-0.48828125 -0.58203125 -0.76953125]\n",
      "   [-0.52734375 -0.60546875 -0.81640625]\n",
      "   ...\n",
      "   [-0.51171875 -0.56640625 -0.91015625]\n",
      "   [-0.55078125 -0.60546875 -0.94921875]\n",
      "   [-0.52734375 -0.58203125 -0.92578125]]\n",
      "\n",
      "  [[-0.34765625 -0.44140625 -0.61328125]\n",
      "   [-0.38671875 -0.48046875 -0.66796875]\n",
      "   [-0.50390625 -0.58203125 -0.79296875]\n",
      "   ...\n",
      "   [-0.44140625 -0.49609375 -0.82421875]\n",
      "   [-0.47265625 -0.52734375 -0.85546875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [-0.41796875 -0.47265625 -0.80078125]]]]\n",
      "[1300 1300 1300 1301 1301 1301 1301 1301 1302 1302 1302 1302 1302 1302\n",
      " 1302 1303 1303 1303 1303 1303 1303 1304 1304 1304 1304 1305 1305 1305\n",
      " 1306 1306 1306 1307 1307 1308 1308 1309 1309 1309 1310 1310 1310 1311\n",
      " 1311 1311 1312 1312 1313 1313 1314 1314 1314 1315 1315 1315 1315 1315\n",
      " 1315 1315 1315 1316 1316 1316 1317 1317 1317 1317 1318 1318 1318 1318\n",
      " 1318 1319 1319 1319 1319 1319 1319 1319 1320 1320 1321 1321 1321 1322\n",
      " 1322 1322 1322 1323 1323 1323 1323 1323 1323 1324 1324 1324 1324 1325\n",
      " 1325 1325 1326 1326 1327 1327 1328 1328 1329 1329 1330 1330 1330 1330\n",
      " 1330 1331 1331 1331 1332 1332 1332 1332 1333 1333 1333 1334 1334 1334\n",
      " 1335 1335 1335 1336 1336 1336 1336 1336 1336 1336 1337 1337 1338 1338\n",
      " 1339 1339 1340 1340 1340 1341 1341 1342 1342 1342 1343 1343 1344 1344\n",
      " 1344 1345 1345 1346 1346 1347 1347 1348 1348 1348 1349 1349 1350 1350\n",
      " 1350 1350 1351 1351 1351 1351 1351 1352 1352 1352 1352 1352 1353 1353\n",
      " 1353 1353 1354 1354 1354 1354 1355 1355 1355 1355 1355 1355 1356 1356\n",
      " 1357 1357 1357 1358 1358 1358 1358 1359 1359 1359 1359 1359 1359 1360\n",
      " 1360 1360 1361 1361 1362 1362 1363 1363 1363 1364 1364 1365 1365 1366\n",
      " 1366 1366 1366 1367 1367 1368 1368 1368 1369 1369 1370 1370 1370 1371\n",
      " 1371 1372 1372 1372 1372 1372 1372 1372 1372 1372 1372 1373 1373 1373\n",
      " 1373 1373 1374 1374 1374 1374 1374 1374 1374 1375 1375 1376 1376 1376\n",
      " 1377 1377 1378 1378 1378 1378 1378 1378 1379 1379 1379 1380 1380 1380\n",
      " 1381 1381 1381 1382 1382 1383 1383 1384 1384 1385 1385 1386 1386 1387\n",
      " 1387 1388 1388 1389 1389 1390 1390 1390 1390 1391 1391 1391 1391 1392\n",
      " 1392 1392 1393 1393 1394 1394 1394 1395 1395 1395 1396 1396 1396 1396\n",
      " 1397 1397 1398 1398 1399 1399 1399 1400 1400 1401 1401 1401 1402 1402\n",
      " 1402 1403 1403 1403 1403 1403 1404 1404 1404 1404 1404 1405 1405 1405\n",
      " 1405 1405 1405 1406 1406 1406 1407 1407 1408 1408 1409 1409 1410 1410\n",
      " 1411 1411 1412 1412 1412 1412 1413 1413 1413 1414 1414 1415 1415 1415\n",
      " 1416 1416 1416 1417 1417 1417 1418 1418 1418 1418 1419 1419 1420 1420\n",
      " 1420 1421 1421 1421 1422 1422 1422 1423 1423 1424 1424 1425 1425 1426\n",
      " 1426 1427 1427 1428 1428 1428 1429 1429 1430 1430 1430 1430 1430 1431\n",
      " 1431 1431 1431 1432 1432 1433 1433 1433 1433 1433 1434 1434 1434 1435\n",
      " 1435 1436 1436 1437 1437 1438 1438 1439 1439 1439 1439 1439 1439 1440\n",
      " 1440 1440 1440 1440 1440 1440 1441 1441 1442 1442 1442 1443 1443 1443\n",
      " 1443 1443 1444 1444 1445 1445 1446 1446 1446 1447 1447 1447 1448 1448\n",
      " 1448 1448 1448 1449 1449 1449 1449 1450 1450 1450 1451 1451 1451 1451\n",
      " 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452\n",
      " 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452\n",
      " 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452\n",
      " 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452 1452\n",
      " 1452 1452 1452 1452 1452 1452 1452 1452 1452 1453]\n",
      "[1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1\n",
      " 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0\n",
      " 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0\n",
      " 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0]\n",
      "Valid outputs\n",
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1\n",
      " 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0\n",
      " 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0\n",
      " 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "# Check the inputs\n",
    "print(\"Train inputs:\")\n",
    "print(images_train)\n",
    "print(labels_train)\n",
    "print(issame_train_in)\n",
    "\n",
    "print(\"Train outputs\")\n",
    "print(labels_train_out)\n",
    "print(issame_train_in)\n",
    "\n",
    "print(\"Valid inputs\")\n",
    "print(images_valid)\n",
    "print(labels_valid)\n",
    "print(issame_in)\n",
    "\n",
    "print(\"Valid outputs\")\n",
    "print(labels_valid_out)\n",
    "print(issame_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4734 samples, validate on 556 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 1:08 - loss: 0.8264 - arcface_loss: 0.8021 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 37s - loss: 0.8284 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 27s - loss: 0.8279 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 22s - loss: 0.8275 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 18s - loss: 0.8278 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 16s - loss: 0.8284 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 15s - loss: 0.8293 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 14s - loss: 0.8292 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 13s - loss: 0.8288 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 12s - loss: 0.8289 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 11s - loss: 0.8286 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 10s - loss: 0.8287 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 10s - loss: 0.8290 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.00 - ETA: 9s - loss: 0.8289 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - ETA: 9s - loss: 0.8288 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 9s - loss: 0.8286 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 8s - loss: 0.8282 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 8s - loss: 0.8286 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 8s - loss: 0.8283 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8289 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8290 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8294 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8292 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8294 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8295 - arcface_loss: 0.8053 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8297 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8297 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8295 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8294 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8295 - arcface_loss: 0.8053 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8294 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8294 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8294 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8297 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8298 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8298 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8299 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8300 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8300 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8302 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8303 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8304 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8306 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8307 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8309 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8308 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8310 - arcface_loss: 0.8068 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8309 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8310 - arcface_loss: 0.8068 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8311 - arcface_loss: 0.8068 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8312 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8311 - arcface_loss: 0.8069 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8313 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8313 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8313 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8313 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8315 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8317 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8317 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8317 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8317 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 1s - loss: 0.8317 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8317 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8315 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 9s 2ms/step - loss: 0.8315 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4225 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8294 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8276 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8280 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8291 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8285 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8293 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8291 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8293 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8297 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8301 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8310 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8313 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8320 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8319 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8315 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8316 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8315 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8315 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8312 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8308 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8308 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8305 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8304 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8303 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8303 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8301 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8301 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8303 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8304 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8304 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8302 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8300 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8300 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8299 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8299 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8300 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8300 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8300 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8300 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8300 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8300 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8301 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8301 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8303 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8304 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8304 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8305 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8304 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8305 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8304 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8304 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8304 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8303 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 8s 2ms/step - loss: 0.8304 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4222 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8287 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8366 - arcface_loss: 0.8126 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8336 - arcface_loss: 0.8094 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8355 - arcface_loss: 0.8112 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8342 - arcface_loss: 0.8099 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8354 - arcface_loss: 0.8112 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8349 - arcface_loss: 0.8107 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8352 - arcface_loss: 0.8109 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8350 - arcface_loss: 0.8108 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8343 - arcface_loss: 0.8100 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8343 - arcface_loss: 0.8101 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8340 - arcface_loss: 0.8097 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8341 - arcface_loss: 0.8099 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8342 - arcface_loss: 0.8099 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8342 - arcface_loss: 0.8099 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8340 - arcface_loss: 0.8097 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8339 - arcface_loss: 0.8096 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8340 - arcface_loss: 0.8097 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8339 - arcface_loss: 0.8096 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8337 - arcface_loss: 0.8094 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8334 - arcface_loss: 0.8091 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8331 - arcface_loss: 0.8088 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8329 - arcface_loss: 0.8086 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8331 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8327 - arcface_loss: 0.8084 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8328 - arcface_loss: 0.8084 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8327 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8326 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8328 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8327 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8327 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8325 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8326 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8327 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8325 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8324 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8324 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8324 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8323 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8321 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8320 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8321 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8322 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8321 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8322 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8322 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8323 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8323 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8323 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8323 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8323 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8323 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8325 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8324 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8325 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8325 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8326 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8327 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8326 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8327 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8328 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8329 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8329 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8329 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 8s 2ms/step - loss: 0.8329 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4225 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8345 - arcface_loss: 0.8099 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8311 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8305 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8316 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8321 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8308 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8305 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8306 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8312 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8315 - arcface_loss: 0.8069 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8310 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8315 - arcface_loss: 0.8069 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8311 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8310 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8309 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8311 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8307 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8307 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8305 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8305 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8305 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8307 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8305 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8309 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8306 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8311 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8311 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8310 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8309 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8310 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8309 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8308 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8308 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8308 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8306 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8305 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8306 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8305 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8307 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8307 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8307 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8307 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8308 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8307 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8308 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8308 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8307 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8306 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8305 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8305 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8305 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8304 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8305 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8304 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8304 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8305 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8305 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8305 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8306 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8306 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8306 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8308 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 8s 2ms/step - loss: 0.8307 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4222 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8268 - arcface_loss: 0.8027 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8280 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8290 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8291 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8284 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8286 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8290 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8293 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8291 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8292 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8285 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8287 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8285 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8291 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8290 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8295 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8292 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8296 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8298 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8299 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8299 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8302 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8304 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8307 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8306 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8308 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8307 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8308 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8307 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8307 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8306 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8305 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8304 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8304 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8302 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8303 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8302 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8303 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8302 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8300 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8300 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8299 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8300 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8299 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8298 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8298 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8298 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8298 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8298 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8298 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8299 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8301 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8301 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8301 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8304 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8304 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8305 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8304 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8305 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8305 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8306 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8306 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8306 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8306 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8307 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8308 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4220 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8325 - arcface_loss: 0.8086 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8331 - arcface_loss: 0.8091 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8328 - arcface_loss: 0.8086 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8329 - arcface_loss: 0.8086 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8328 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8325 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8315 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8312 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8310 - arcface_loss: 0.8068 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8303 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8303 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8300 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8302 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8298 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8299 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8298 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8302 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8303 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8304 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8303 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8304 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8305 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8306 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8306 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8307 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8306 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8304 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8302 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8304 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8304 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8303 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8303 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8304 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8302 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8302 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8301 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8302 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8302 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8302 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8304 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8304 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8304 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8305 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8305 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8305 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8305 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8302 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8304 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8302 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8302 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8304 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8303 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8303 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8303 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8302 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4218 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8211 - arcface_loss: 0.7973 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8237 - arcface_loss: 0.8002 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8244 - arcface_loss: 0.8008 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8251 - arcface_loss: 0.8015 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8256 - arcface_loss: 0.8020 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8259 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8259 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8267 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8267 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8271 - arcface_loss: 0.8035 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8269 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8274 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8273 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8274 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8273 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8271 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8268 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8268 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8266 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8266 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8273 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8272 - arcface_loss: 0.8035 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8277 - arcface_loss: 0.8041 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8280 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8279 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8279 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8278 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8281 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8283 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8282 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8284 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8284 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8284 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8284 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8283 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8284 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8283 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8283 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8284 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8285 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8286 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8288 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8289 - arcface_loss: 0.8053 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8288 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8289 - arcface_loss: 0.8053 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8289 - arcface_loss: 0.8053 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8290 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8290 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8290 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8290 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8290 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8291 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8290 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8290 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8291 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8291 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8290 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8291 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8291 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8292 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8291 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8292 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8292 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8292 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8292 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8292 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8292 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8291 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8292 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8292 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8292 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8291 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8292 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4215 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8331 - arcface_loss: 0.8097 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8318 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8313 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8313 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8308 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8307 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8300 - arcface_loss: 0.8064 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8294 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8293 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8297 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8299 - arcface_loss: 0.8062 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8308 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8303 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8308 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8307 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8312 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8312 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8319 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8317 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8319 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8316 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8318 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8315 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8317 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8316 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8315 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8315 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8312 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8315 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8315 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8314 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8313 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8312 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8311 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8312 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8311 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8311 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8310 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8310 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8310 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8310 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8310 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8313 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8315 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8315 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8315 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8317 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8319 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8318 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8321 - arcface_loss: 0.8084 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8321 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8323 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8324 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8324 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8324 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8324 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8324 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8324 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8324 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8323 - arcface_loss: 0.8086 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8323 - arcface_loss: 0.8086 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8323 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8322 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8322 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8322 - arcface_loss: 0.8084 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8320 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8319 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8318 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8318 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8318 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8318 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8317 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8317 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8316 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4221 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8343 - arcface_loss: 0.8102 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8284 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8313 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8310 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8332 - arcface_loss: 0.8089 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8328 - arcface_loss: 0.8086 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8346 - arcface_loss: 0.8104 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8337 - arcface_loss: 0.8095 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8338 - arcface_loss: 0.8096 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8332 - arcface_loss: 0.8089 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8335 - arcface_loss: 0.8092 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8329 - arcface_loss: 0.8086 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8330 - arcface_loss: 0.8088 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8327 - arcface_loss: 0.8084 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8326 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8325 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8326 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8325 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8329 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8329 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8331 - arcface_loss: 0.8088 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8330 - arcface_loss: 0.8087 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8328 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8329 - arcface_loss: 0.8086 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8326 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8326 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8326 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8325 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8324 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8324 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8320 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8321 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8320 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8322 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8322 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8325 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8325 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8327 - arcface_loss: 0.8083 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8325 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8328 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8327 - arcface_loss: 0.8084 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8327 - arcface_loss: 0.8084 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8325 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8325 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8324 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8324 - arcface_loss: 0.8081 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8324 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8323 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8323 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8323 - arcface_loss: 0.8079 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8322 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8321 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8321 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8320 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8320 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8319 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8318 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8318 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8317 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8316 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8316 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8315 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8314 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8314 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8314 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8313 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8313 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8313 - arcface_loss: 0.8069 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8312 - arcface_loss: 0.8069 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8312 - arcface_loss: 0.8068 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8311 - arcface_loss: 0.8068 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8310 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8310 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8309 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4220 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8267 - arcface_loss: 0.8025 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8244 - arcface_loss: 0.8001 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8244 - arcface_loss: 0.8004 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8251 - arcface_loss: 0.8011 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8257 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8264 - arcface_loss: 0.8026 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8264 - arcface_loss: 0.8025 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8264 - arcface_loss: 0.8026 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8266 - arcface_loss: 0.8028 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8265 - arcface_loss: 0.8027 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8266 - arcface_loss: 0.8028 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8268 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8266 - arcface_loss: 0.8028 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8267 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8269 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8268 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8271 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8271 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8273 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8273 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8281 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8279 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8285 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8282 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8283 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8283 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8283 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8280 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8281 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8283 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8283 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8280 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8280 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8280 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8283 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8283 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8283 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8281 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8281 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8281 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8283 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8284 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8285 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8286 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8287 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8288 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8288 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8289 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8288 - arcface_loss: 0.8053 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8288 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8287 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8288 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8286 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8288 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8287 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8287 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8286 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8286 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8286 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8286 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8287 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8287 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8287 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8286 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8286 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8287 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8286 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8286 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8286 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4213 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8237 - arcface_loss: 0.8003 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8216 - arcface_loss: 0.7980 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8237 - arcface_loss: 0.8002 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8237 - arcface_loss: 0.8002 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8243 - arcface_loss: 0.8008 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8243 - arcface_loss: 0.8009 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8249 - arcface_loss: 0.8016 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8255 - arcface_loss: 0.8022 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8255 - arcface_loss: 0.8022 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8256 - arcface_loss: 0.8023 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8256 - arcface_loss: 0.8023 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8257 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8258 - arcface_loss: 0.8025 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8262 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8265 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8263 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8263 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8264 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8265 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8267 - arcface_loss: 0.8035 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8266 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8264 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8264 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8264 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8264 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8264 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8265 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8264 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8265 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8265 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8265 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8265 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8266 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8265 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8266 - arcface_loss: 0.8035 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8266 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8267 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8267 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8267 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8269 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8268 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8267 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8267 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8268 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8269 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8270 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8270 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8271 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8272 - arcface_loss: 0.8041 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8273 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8274 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8274 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8275 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8276 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8277 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8276 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8277 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8277 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8277 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8278 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8278 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8279 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8281 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8281 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8282 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8282 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8053 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8285 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8286 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8287 - arcface_loss: 0.8057 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4212 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8417 - arcface_loss: 0.8188 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8389 - arcface_loss: 0.8157 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8412 - arcface_loss: 0.8180 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8377 - arcface_loss: 0.8145 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8386 - arcface_loss: 0.8153 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8369 - arcface_loss: 0.8136 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8380 - arcface_loss: 0.8147 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8370 - arcface_loss: 0.8137 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8367 - arcface_loss: 0.8134 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8358 - arcface_loss: 0.8125 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8357 - arcface_loss: 0.8124 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8352 - arcface_loss: 0.8118 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8351 - arcface_loss: 0.8117 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8353 - arcface_loss: 0.8119 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8347 - arcface_loss: 0.8113 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8341 - arcface_loss: 0.8106 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8339 - arcface_loss: 0.8104 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8332 - arcface_loss: 0.8098 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8327 - arcface_loss: 0.8092 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8324 - arcface_loss: 0.8089 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8320 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8317 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8314 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8313 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8310 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8308 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8307 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8305 - arcface_loss: 0.8069 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8305 - arcface_loss: 0.8069 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8303 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8305 - arcface_loss: 0.8068 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8304 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8304 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8302 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8304 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8303 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8303 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8302 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8302 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8301 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8303 - arcface_loss: 0.8066 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8301 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8305 - arcface_loss: 0.8068 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8304 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8304 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8304 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8308 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8307 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8308 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8309 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8310 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8310 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8310 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8310 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8311 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8310 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8309 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8309 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8308 - arcface_loss: 0.8071 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8307 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8311 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8311 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8312 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8312 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8313 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8313 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8315 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8314 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8315 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8313 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8314 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8313 - arcface_loss: 0.8075 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8314 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8314 - arcface_loss: 0.8077 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4220 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8316 - arcface_loss: 0.8074 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8260 - arcface_loss: 0.8020 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8254 - arcface_loss: 0.8014 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8244 - arcface_loss: 0.8003 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8247 - arcface_loss: 0.8006 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8248 - arcface_loss: 0.8007 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8248 - arcface_loss: 0.8007 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8256 - arcface_loss: 0.8015 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8259 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8262 - arcface_loss: 0.8021 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8259 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8262 - arcface_loss: 0.8021 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8260 - arcface_loss: 0.8019 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8264 - arcface_loss: 0.8023 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8266 - arcface_loss: 0.8026 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8271 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8272 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8273 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8277 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8278 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8283 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8280 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8283 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8281 - arcface_loss: 0.8041 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8283 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8282 - arcface_loss: 0.8041 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8284 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8284 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8284 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8285 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8285 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8284 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8284 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8283 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8282 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8281 - arcface_loss: 0.8041 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8285 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8286 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8287 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8288 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8288 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8288 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8287 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8287 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8287 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8286 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8286 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8284 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8286 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8284 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8285 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8286 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8285 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8285 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8286 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8285 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8285 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8285 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8286 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4214 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8192 - arcface_loss: 0.7955 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8259 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8271 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8264 - arcface_loss: 0.8028 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8281 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8272 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8278 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8274 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8279 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8272 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8279 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8276 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8273 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8270 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8271 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8274 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8279 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8281 - arcface_loss: 0.8048 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8278 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8278 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8277 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8281 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8278 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8281 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8278 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8279 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8276 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8276 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8274 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8273 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8272 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8271 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8271 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8270 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8272 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8271 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8271 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8271 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8271 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8272 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8272 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8272 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8271 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8272 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8272 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8272 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8272 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8272 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8272 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8272 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8273 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8273 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8274 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8273 - arcface_loss: 0.8040 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8274 - arcface_loss: 0.8041 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8274 - arcface_loss: 0.8041 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8275 - arcface_loss: 0.8041 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8275 - arcface_loss: 0.8042 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8276 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8276 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8277 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8276 - arcface_loss: 0.8043 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 8s 2ms/step - loss: 0.8278 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4211 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 7s - loss: 0.8230 - arcface_loss: 0.8002 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8232 - arcface_loss: 0.8002 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 7s - loss: 0.8236 - arcface_loss: 0.8006 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8238 - arcface_loss: 0.8007 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8234 - arcface_loss: 0.8004 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8237 - arcface_loss: 0.8007 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8233 - arcface_loss: 0.8003 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8234 - arcface_loss: 0.8004 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8235 - arcface_loss: 0.8005 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8241 - arcface_loss: 0.8010 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8242 - arcface_loss: 0.8012 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8242 - arcface_loss: 0.8011 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8243 - arcface_loss: 0.8012 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8243 - arcface_loss: 0.8013 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8242 - arcface_loss: 0.8012 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8250 - arcface_loss: 0.8020 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8254 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8254 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8253 - arcface_loss: 0.8023 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8255 - arcface_loss: 0.8025 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8254 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8254 - arcface_loss: 0.8023 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8253 - arcface_loss: 0.8022 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8252 - arcface_loss: 0.8022 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8248 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8248 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8246 - arcface_loss: 0.8016 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8246 - arcface_loss: 0.8015 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8247 - arcface_loss: 0.8017 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8248 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8247 - arcface_loss: 0.8017 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8246 - arcface_loss: 0.8016 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8248 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8249 - arcface_loss: 0.8019 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8251 - arcface_loss: 0.8021 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8252 - arcface_loss: 0.8022 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8253 - arcface_loss: 0.8023 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8254 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8253 - arcface_loss: 0.8023 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8255 - arcface_loss: 0.8025 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8254 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8254 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8256 - arcface_loss: 0.8026 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8255 - arcface_loss: 0.8025 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8256 - arcface_loss: 0.8026 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8257 - arcface_loss: 0.8027 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8257 - arcface_loss: 0.8027 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8258 - arcface_loss: 0.8028 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8258 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8258 - arcface_loss: 0.8028 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8257 - arcface_loss: 0.8027 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8257 - arcface_loss: 0.8027 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8257 - arcface_loss: 0.8027 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8257 - arcface_loss: 0.8027 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8257 - arcface_loss: 0.8028 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8257 - arcface_loss: 0.8028 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8257 - arcface_loss: 0.8028 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8258 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8258 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8260 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8260 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8261 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8261 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8260 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8261 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8261 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8264 - arcface_loss: 0.8035 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8265 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8267 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8268 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8270 - arcface_loss: 0.8041 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 8s 2ms/step - loss: 0.8276 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4207 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 5s - loss: 0.8283 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8411 - arcface_loss: 0.8183 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8365 - arcface_loss: 0.8136 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8428 - arcface_loss: 0.8200 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8409 - arcface_loss: 0.8180 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8428 - arcface_loss: 0.8199 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8421 - arcface_loss: 0.8191 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8417 - arcface_loss: 0.8186 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8407 - arcface_loss: 0.8176 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8406 - arcface_loss: 0.8174 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8396 - arcface_loss: 0.8164 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8394 - arcface_loss: 0.8162 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8383 - arcface_loss: 0.8150 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8388 - arcface_loss: 0.8155 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8377 - arcface_loss: 0.8144 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8378 - arcface_loss: 0.8144 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8371 - arcface_loss: 0.8137 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8371 - arcface_loss: 0.8136 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8365 - arcface_loss: 0.8131 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8362 - arcface_loss: 0.8127 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8360 - arcface_loss: 0.8124 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8357 - arcface_loss: 0.8122 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8352 - arcface_loss: 0.8116 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8348 - arcface_loss: 0.8112 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8345 - arcface_loss: 0.8108 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8342 - arcface_loss: 0.8105 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8338 - arcface_loss: 0.8101 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8335 - arcface_loss: 0.8098 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8331 - arcface_loss: 0.8094 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8328 - arcface_loss: 0.8091 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8326 - arcface_loss: 0.8088 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8323 - arcface_loss: 0.8085 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8320 - arcface_loss: 0.8082 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8319 - arcface_loss: 0.8080 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8317 - arcface_loss: 0.8078 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8315 - arcface_loss: 0.8076 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8312 - arcface_loss: 0.8073 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8310 - arcface_loss: 0.8072 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8309 - arcface_loss: 0.8070 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8307 - arcface_loss: 0.8068 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8306 - arcface_loss: 0.8067 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8304 - arcface_loss: 0.8065 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8302 - arcface_loss: 0.8063 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8300 - arcface_loss: 0.8061 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8299 - arcface_loss: 0.8060 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8298 - arcface_loss: 0.8059 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8297 - arcface_loss: 0.8058 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8295 - arcface_loss: 0.8056 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8294 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8293 - arcface_loss: 0.8055 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8293 - arcface_loss: 0.8054 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8292 - arcface_loss: 0.8053 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8291 - arcface_loss: 0.8052 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8290 - arcface_loss: 0.8051 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8288 - arcface_loss: 0.8050 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8288 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8287 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8287 - arcface_loss: 0.8049 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8286 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8285 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8284 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8284 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8283 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8282 - arcface_loss: 0.8044 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734/4734 [==============================] - ETA: 0s - loss: 0.8283 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8283 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8283 - arcface_loss: 0.8045 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8284 - arcface_loss: 0.8047 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - 7s 2ms/step - loss: 0.8283 - arcface_loss: 0.8046 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000 - val_loss: 7.4209 - val_arcface_loss: 7.6449e-04 - val_validation_loss: 7.3977 - val_arcface_acc: 0.0144 - val_validation_acc: 0.5360\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4734 [========================>.....] - ETA: 6s - loss: 0.8270 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8254 - arcface_loss: 0.8023 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8242 - arcface_loss: 0.8011 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8242 - arcface_loss: 0.8012 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8247 - arcface_loss: 0.8017 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8240 - arcface_loss: 0.8010 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8242 - arcface_loss: 0.8011 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 6s - loss: 0.8240 - arcface_loss: 0.8009 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8241 - arcface_loss: 0.8010 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8249 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8254 - arcface_loss: 0.8023 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8248 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8246 - arcface_loss: 0.8016 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8246 - arcface_loss: 0.8016 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8245 - arcface_loss: 0.8014 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8244 - arcface_loss: 0.8013 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8244 - arcface_loss: 0.8014 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8243 - arcface_loss: 0.8013 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 5s - loss: 0.8243 - arcface_loss: 0.8013 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8243 - arcface_loss: 0.8013 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8244 - arcface_loss: 0.8015 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8245 - arcface_loss: 0.8015 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8244 - arcface_loss: 0.8014 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8247 - arcface_loss: 0.8018 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8253 - arcface_loss: 0.8024 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8251 - arcface_loss: 0.8022 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8255 - arcface_loss: 0.8026 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8254 - arcface_loss: 0.8025 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8258 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 4s - loss: 0.8260 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8262 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8265 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8266 - arcface_loss: 0.8037 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8267 - arcface_loss: 0.8039 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8266 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8266 - arcface_loss: 0.8038 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8265 - arcface_loss: 0.8036 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8264 - arcface_loss: 0.8035 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8263 - arcface_loss: 0.8034 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8262 - arcface_loss: 0.8033 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 3s - loss: 0.8261 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8261 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8260 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8260 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8258 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8260 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8258 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 2s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8261 - arcface_loss: 0.8032 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8260 - arcface_loss: 0.8031 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8258 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8258 - arcface_loss: 0.8029 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 1s - loss: 0.8258 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4224/4734 [=========================>....] - ETA: 0s - loss: 0.8259 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.000 - ETA: 0s - loss: 0.8258 - arcface_loss: 0.8030 - validation_loss: 1.1921e-07 - arcface_acc: 0.0000e+00 - validation_acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-f074bb8a982a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#validation_data = ([images_valid,issame_in], labels_valid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#validation_data=([images_valid,labels_valid,issame_in],[labels_valid,issame_out])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../output/logs/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2969\u001b[0m         \u001b[0mtensor_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m         array_vals.append(np.asarray(value,\n\u001b[1;32m-> 2971\u001b[1;33m                                      dtype=tensor_type.as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2973\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    #[images_train,issame_train_in],\n",
    "    [images_train,labels_train,issame_train_in],\n",
    "    #[labels_train,issame_train_out],\n",
    "    #[labels_train,issame_train_out],\n",
    "    [labels_train_out,issame_train_in],\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_data = ([images_valid,labels_valid,issame_in], [labels_valid_out,issame_in]),\n",
    "    #validation_data = ([images_valid,issame_in], labels_valid)\n",
    "    #validation_data=([images_valid,labels_valid,issame_in],[labels_valid,issame_out])\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='../output/logs/')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        (None, 100, 100, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 98, 98, 10)   280         image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 49, 49, 10)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 47, 47, 20)   1820        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 23, 23, 20)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 21, 21, 40)   7240        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 40)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 40)           0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           1312        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "input_labels (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "issame_input (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "arcface (Arcface)               (None, 1301)         41632       dense[0][0]                      \n",
      "                                                                 input_labels[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "validation (Validation)         (None, 1)            0           dense[0][0]                      \n",
      "                                                                 issame_input[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 52,284\n",
      "Trainable params: 52,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on the training/validation dataset to stop the worst examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict,_=model.predict([images_train[0:10],labels_train[0:10],issame_train_in[0:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py:80: UserWarning: Float image out of standard range; displaying image with stretched contrast.\n",
      "  warn(\"Float image out of standard range; displaying \"\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2000f3e5d30>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skimage as sk\n",
    "sk.io.imshow(images_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6868594, 0.7891156]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict([images_test[0:1],labels_test[0:1],issame_in[0:1]])\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate it on the test dataset: one shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DogFaceNet version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/dogfacenet/'\n",
    "PATH_IMAGES = PATH + 'images/'\n",
    "PATH_RESIZED = PATH + 'resized/'\n",
    "\n",
    "# Size of the input image into the network\n",
    "SIZE = (100,100,3)\n",
    "\n",
    "TEST_SPLIT = 0.05\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing\n",
    "- Get the dataset from folders\n",
    "- Associate the corresponding classes\n",
    "- Resized the dataset\n",
    "- Shuffle the dataset?\n",
    "- Divide the dataset into validation, training and testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_crop(image):\n",
    "    \"\"\"\n",
    "    Takes the largest between height and width of the image and crops it into a square.\n",
    "    This square is located in the middle of the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    h,w,c = image.shape\n",
    "    \n",
    "    if w > h:\n",
    "        margin = w - h\n",
    "        margin = margin // 2\n",
    "        image = image[:,margin:margin+h,:]\n",
    "    elif w < h:\n",
    "        margin = h - w\n",
    "        margin = margin // 2\n",
    "        image = image[margin:margin+w,:,:]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6491e4baa6e74a5f88a1cbf88edfa807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "label = 0\n",
    "\n",
    "filenames = os.listdir(PATH_IMAGES)\n",
    "\n",
    "# Just save the pictures after resizing them\n",
    "for i in tqdm_notebook(range(598+869,len(filenames))):\n",
    "    for file in os.listdir(PATH_IMAGES + filenames[i]):\n",
    "        label += 1\n",
    "        \n",
    "        # Read and resized image\n",
    "        image = sk.io.imread(PATH_IMAGES + filenames[i] + '/' + file)\n",
    "        if len(image.shape) == 3:\n",
    "            image_cropped = square_crop(image)\n",
    "            image_resized = sk.transform.resize(image_cropped,SIZE)\n",
    "\n",
    "            # Save image\n",
    "            ## Check if the good folder exists\n",
    "            if filenames[i] not in os.listdir(PATH_RESIZED):\n",
    "                os.mkdir(PATH_RESIZED + filenames[i])\n",
    "            sk.io.imsave(PATH_RESIZED + filenames[i] + '/' + str(label) + '.jpg', image_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 5568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326bfe61549544d783c528473f1aa94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1477), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(PATH_RESIZED)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Remove unique examples\n",
    "while i<len(filenames):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    if len(files)<=1:\n",
    "        filenames = filenames[:i] + filenames[i+1:]\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "# Compute the number of images\n",
    "nbof_images = 0\n",
    "for i in range(0,len(filenames)):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    nbof_images += len(files)\n",
    "\n",
    "print(\"Number of images: \" + str(nbof_images))\n",
    "    \n",
    "w, h, c = SIZE\n",
    "\n",
    "images = np.empty((nbof_images,w,h,c))\n",
    "labels = np.empty(nbof_images, dtype=int)\n",
    "\n",
    "label = 0\n",
    "\n",
    "index = 0\n",
    "\n",
    "# Load images into numpy arrays\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    for file in files:\n",
    "        labels[index] = label\n",
    "        # Read image\n",
    "        image = sk.io.imread(PATH_RESIZED + filenames[i] + '/' + file)\n",
    "\n",
    "        # Add the image to the table\n",
    "        images[index] = image\n",
    "        \n",
    "        index += 1\n",
    "    label += 1\n",
    "    \n",
    "assert len(labels)==len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old method!\n",
    "\n",
    "Divide the dataset into train, valid and test:\n",
    "\n",
    "To create the validation dataset we use pictures of dogs were there is more than 3 pictures and took one of this picture.\n",
    "\n",
    "For the testing dataset we simply split the classes. We will then use the network as a one shot learner on this new dataset. With one picture the network will produce one embedding vector. For each embedding vector compute the L2 distance with each face to compute the most propable one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5568\n",
      "Number of test images: 278\n",
      "Number of validation images: 543\n",
      "Number of training images: 4747\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-95fc612d2572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mcount_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;31m# print(labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# print(labels_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "nbof_test = int(len(images)*TEST_SPLIT)\n",
    "\n",
    "images_test = images[:nbof_test]\n",
    "labels_test = labels[:nbof_test]\n",
    "\n",
    "\n",
    "# Count valid images:\n",
    "state = -1\n",
    "count_valid = 0\n",
    "count_train = 0\n",
    "count_image_class = 0\n",
    "\n",
    "for i in range(nbof_test,len(labels)):\n",
    "    if state != labels[i]:\n",
    "        state = labels[i]\n",
    "        count_image_class = 0\n",
    "    else:\n",
    "        count_image_class += 1\n",
    "    \n",
    "    if count_image_class == 3:\n",
    "        count_valid += 1\n",
    "    else:\n",
    "        count_train += 1\n",
    "\n",
    "print(\"Total number of images: \" + str(len(labels)))\n",
    "print(\"Number of test images: \" + str(len(labels_test)))\n",
    "print(\"Number of validation images: \" + str(count_valid))\n",
    "print(\"Number of training images: \" + str(count_train))\n",
    "\n",
    "images_valid = np.empty((count_valid,w,h,c))\n",
    "labels_valid = np.empty(count_valid)\n",
    "\n",
    "images_train = np.empty((count_train,w,h,c))\n",
    "labels_train = np.empty(count_train)\n",
    "\n",
    "state = -1\n",
    "count_valid = 0\n",
    "count_train = 0\n",
    "count_image_class = 0\n",
    "\n",
    "for i in range(nbof_test,len(labels)):\n",
    "    if state != labels[i]:\n",
    "        state = labels[i]\n",
    "        count_image_class = 0\n",
    "    else:\n",
    "        count_image_class += 1\n",
    "    \n",
    "    if count_image_class == 3:\n",
    "        # Add the validation image in the validation array\n",
    "        images_valid[count_valid] = images[i]\n",
    "        labels_valid[count_valid] = labels[i]\n",
    "        \n",
    "        count_valid += 1\n",
    "    else:\n",
    "        images_train[count_train] = images[i]\n",
    "        labels_train[count_train] = labels[i]\n",
    "        \n",
    "        count_train += 1\n",
    "# print(labels)\n",
    "# print(labels_test)\n",
    "# print(labels_train)\n",
    "# print(labels_valid)\n",
    "print(\"Is the number of images coherent? \" + str(len(labels)==(len(labels_test)+len(labels_train)+len(labels_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New method\n",
    "- We divide the validation and test set from the training set with the classic division method: 85 percent training, 10 validating, 5 testing.\n",
    "- We then computes pairs of images in the validation set and testing set:\n",
    " - Some of these pairs are images of the same dog and some are picture of different dogs\n",
    " - We create a two lists:\n",
    "  - A list a images containing the pairs: two successive images are a pair of images. For example, image 0 and is a pair, image 2 and 3 is another pair, etc...\n",
    "  - A list of boolean called 'issame' indicating if a pair is a pair of images of the same dog or a pair of different dogs. For example, if image 0 and image 1 are showing the same dog value 0 and 1 in the list will be True. On the other hand if the image 2 and 3 represent two different dogs the value 2 and 3 in the list will be at False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5568\n",
      "Number of test images: 278\n",
      "Number of validation images: 556\n",
      "Number of training images: 4734\n",
      "Number of classes in the training set: 1300\n",
      "Number of pairs: 556\n",
      "Number of same images: 133\n",
      "Number of validation images: 556\n"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "nbof_test = int(len(images)*TEST_SPLIT)\n",
    "\n",
    "images_test = images[-nbof_test:]\n",
    "labels_test = labels[-nbof_test:]\n",
    "\n",
    "nbof_valid = int(len(images)*VALID_SPLIT)\n",
    "\n",
    "images_valid = images[-nbof_test-nbof_valid:-nbof_test]\n",
    "labels_valid = labels[-nbof_test-nbof_valid:-nbof_test]\n",
    "\n",
    "images_train = images[:-nbof_test-nbof_valid]\n",
    "labels_train = labels[:-nbof_test-nbof_valid]\n",
    "\n",
    "print(\"Total number of images: \" + str(len(labels)))\n",
    "print(\"Number of test images: \" + str(len(labels_test)))\n",
    "print(\"Number of validation images: \" + str(len(labels_valid)))\n",
    "print(\"Number of training images: \" + str(len(labels_train)))\n",
    "print(\"Number of classes in the training set: \" + str(labels_train[-1] - labels_train[0]))\n",
    "\n",
    "\n",
    "# Creates the pairs\n",
    "\n",
    "nbof_pairs = (len(images_valid)//2)*2 # it has to be multiple of 2\n",
    "\n",
    "print(\"Number of pairs: \" + str(nbof_pairs))\n",
    "\n",
    "pairs = np.empty((nbof_pairs,w,h,c))\n",
    "issame_in = np.empty(nbof_pairs, dtype=int)\n",
    "issame_out = np.empty((nbof_pairs,2))\n",
    "\n",
    "nbof_same = 0\n",
    "\n",
    "for i in range(0,nbof_pairs,2):\n",
    "    ## alea_issame will decide if the new pair will be a pair of same dog images or a pair of different\n",
    "    alea_issame = np.random.rand()\n",
    "\n",
    "    if alea_issame < 0.5: # Then it will be a pair of same dogs\n",
    "        # we randomly choose a dog\n",
    "        choice = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        # we extract the images of this class\n",
    "        chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice])])\n",
    "        \n",
    "        while len(labels_valid[np.equal(labels_valid,labels_valid[choice])]) < 2:\n",
    "            choice = np.random.randint(len(labels_valid))\n",
    "            chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice])])\n",
    "            \n",
    "        # we then randomly choose two pictures of this class\n",
    "        choice1 = np.random.randint(len(chosen_images))\n",
    "        pairs[i] = chosen_images[choice1]\n",
    "        save = np.copy(chosen_images)\n",
    "        chosen_images = chosen_images[:choice1] + chosen_images[choice1+1:]\n",
    "        if len(chosen_images) == 0:\n",
    "            print(\"Bug!\")\n",
    "            print(save)\n",
    "        choice2 = np.random.randint(len(chosen_images))\n",
    "        pairs[i+1] = chosen_images[choice2]\n",
    "\n",
    "        issame_out[i] = issame_out[i+1] = [1,0]\n",
    "        issame_in[i] = issame_in[i+1] = 1\n",
    "        \n",
    "        nbof_same += 1\n",
    "        \n",
    "    else: # Then it will be a pair of different dogs\n",
    "        # we randomly choose two dogs\n",
    "        choice1 = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        # we extract the images of the class\n",
    "        chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice1])])\n",
    "        \n",
    "        # we choose an image of this class\n",
    "        choice = np.random.randint(len(chosen_images))\n",
    "        #print(choice)\n",
    "        pairs[i] = images_valid[choice]\n",
    "        \n",
    "        choice2 = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        # check if we have two different classes\n",
    "        while labels_valid[choice2] == labels_valid[choice1]:\n",
    "            choice2 = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice2])])\n",
    "        \n",
    "        # we choose an image of this class\n",
    "        choice = np.random.randint(len(chosen_images))\n",
    "        \n",
    "        pairs[i+1] = images_valid[choice]\n",
    "        \n",
    "        issame_out[i] = issame_out[i+1] = [0,1]\n",
    "        issame_in[i] = issame_in[i+1] = 0\n",
    "\n",
    "print(\"Number of same images: \" + str(nbof_same))\n",
    "print(\"Number of validation images: \" + str(len(labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBOF_CLASSES = max(labels_train)+1\n",
    "labels_train = tf.keras.utils.to_categorical(labels_train,NBOF_CLASSES)\n",
    "labels_valid = tf.keras.utils.to_categorical(labels_valid-NBOF_CLASSES,NBOF_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "- Define the ArcFace layer\n",
    "- Define the dummy model first\n",
    "- Compile it with the softmax loss and and Adam optimizer\n",
    "- Then use transfer learning with a more complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Arcface layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My custom layer for arcface\n",
    "# It takes two inputs: one for the embedding, one for the label\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "import math\n",
    "\n",
    "# Arcface should only be used for training\n",
    "class Arcface(Layer):\n",
    "\n",
    "    def __init__(self, out_num, s = 64., m = 0.5, **kwargs):\n",
    "        self.out_num = out_num\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        super(Arcface, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape, initializer='uniform'):\n",
    "        assert isinstance(input_shape, list)\n",
    "        \n",
    "        shape = tf.TensorShape((input_shape[0][-1],self.out_num))\n",
    "        print(shape)\n",
    "        \n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                                 shape=shape,\n",
    "                                                 initializer=initializer,\n",
    "                                                 dtype=tf.float32,\n",
    "                                                 trainable=True)\n",
    "        super(Arcface, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        assert isinstance(x, list)\n",
    "        embedding, labels = x\n",
    "        \n",
    "        cos_m = math.cos(self.m)\n",
    "        sin_m = math.sin(self.m)\n",
    "        mm = sin_m * self.m  # issue 1\n",
    "        threshold = math.cos(math.pi - self.m)\n",
    "        \n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keepdims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        \n",
    "        weights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n",
    "        weights = tf.div(self.kernel, weights_norm, name='norm_weights')\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "        \n",
    "        # this condition controls the theta+m should be in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = self.s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "        mask = tf.one_hot(labels, depth=self.out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "\n",
    "        output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_loss_output')\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        shape_emb, shape_lab = input_shape\n",
    "        shape_emb[-1] = self.out_num\n",
    "        return tf.TensorShape(shape_emb)\n",
    "    \n",
    "#         shape = tf.TensorShape(input_shape).as_list()\n",
    "#         shape[-1] = self.num_classes\n",
    "#         return tf.TensorShape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "import math\n",
    "\n",
    "# Arcface should only be used for training\n",
    "class Arcface(Layer):\n",
    "\n",
    "    def __init__(self, out_num, s = 64., m = 0.5, **kwargs):\n",
    "        self.out_num = out_num\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        super(Arcface, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape, initializer='uniform'):\n",
    "        assert isinstance(input_shape, list)\n",
    "        \n",
    "        shape = tf.TensorShape((input_shape[0][-1],self.out_num))\n",
    "        print(shape)\n",
    "        \n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                                 shape=shape,\n",
    "                                                 initializer=initializer,\n",
    "                                                 dtype=tf.float32,\n",
    "                                                 trainable=True)\n",
    "        super(Arcface, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        assert isinstance(x, list)\n",
    "        embedding, labels = x\n",
    "        \n",
    "        cos_m = math.cos(self.m)\n",
    "        sin_m = math.sin(self.m)\n",
    "        mm = sin_m * self.m  # issue 1\n",
    "        threshold = math.cos(math.pi - self.m)\n",
    "        \n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keepdims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        \n",
    "        weights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n",
    "        weights = tf.div(self.kernel, weights_norm, name='norm_weights')\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "        \n",
    "        # this condition controls the theta+m should be in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = self.s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "        \n",
    "        labels_int = tf.cast(labels,tf.int32, name='labels_int')\n",
    "        mask = tf.one_hot(labels_int, depth=self.out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "        mul1 = tf.multiply(s_cos_t, inv_mask)\n",
    "        print(mul1.shape)\n",
    "        mul2 = tf.multiply(cos_mt_temp, mask)\n",
    "        print(mul2.shape)\n",
    "        output = tf.add(mul1, mul2, name='arcface_loss_output')\n",
    "        print(output.shape)\n",
    "        print(cos_mt_temp.shape)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        shape_emb, shape_lab = input_shape\n",
    "        shape_emb[-1] = self.out_num\n",
    "        return tf.TensorShape(shape_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, s = 64., m = 0.5, **kwargs):\n",
    "        self.out_num = output_dim\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "        \n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        shape = (input_shape[1].value, self.out_num)\n",
    "        print(shape)\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        #assert isinstance(x, list)\n",
    "        embedding = x\n",
    "        \n",
    "        cos_m = math.cos(self.m)\n",
    "        sin_m = math.sin(self.m)\n",
    "        mm = sin_m * self.m  # issue 1\n",
    "        threshold = math.cos(math.pi - self.m)\n",
    "        \n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keepdims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        \n",
    "        weights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n",
    "        weights = tf.div(self.kernel, weights_norm, name='norm_weights')\n",
    "        #print(self.weights)\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "        \n",
    "        # this condition controls the theta+m should be in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = self.s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "        #mask = tf.one_hot(labels, depth=self.out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        #inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        \n",
    "        s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "        \n",
    "        return s_cos_t\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0].value, self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the validation layer:\n",
    "- The bigger the validation batch the better it is (no less than 64 pictures -> 32 pairs)\n",
    "- It computes the ROC curve\n",
    "- Finds the best threshold\n",
    "- Returns a list of 2D vectors [1,0] if the pair was the same dog, [0,1] if it was a different dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8407671451568604\n",
      "[array([[1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [1, 0],\n",
      "       [0, 1],\n",
      "       [0, 1]])]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# tests unitaires\n",
    "\n",
    "tf.reset_default_graph()\n",
    "emb_raw = tf.constant([[12.,2],[8,4],[3,8],[2,10],[50,10],[10,30]])\n",
    "\n",
    "actual_issame = tf.constant([1.,1,1,1,0,0])\n",
    "emb_ = tf.math.l2_normalize(emb_raw,0)\n",
    "\n",
    "# Normalizes\n",
    "emb = tf.math.l2_normalize(emb_,0)\n",
    "\n",
    "# Separates the pairs\n",
    "emb1 = emb[0::2]\n",
    "emb2 = emb[1::2]\n",
    "\n",
    "# Computes distance between pairs\n",
    "diff = tf.squared_difference(emb1,emb2)\n",
    "dist = tf.reduce_sum(diff,1)\n",
    "\n",
    "dist = tf.reshape(tf.stack([dist,dist], axis=-1), [-1])\n",
    "\n",
    "best_threshold = 0\n",
    "#for t in np.arange(0,1,0.001):\n",
    "t = 0.01\n",
    "\n",
    "def fn(t):\n",
    "    less = tf.less(dist,t)\n",
    "\n",
    "    actual_issame_bool = tf.cast(actual_issame,dtype=tf.bool)\n",
    "    acc = tf.logical_not(tf.logical_xor(less,actual_issame_bool))\n",
    "    acc = tf.cast(acc,tf.float32)\n",
    "    out = tf.reshape(tf.reduce_sum(acc),[])\n",
    "    return out\n",
    "\n",
    "\n",
    "thresholds = tf.range(0,1,0.001)\n",
    "apply_t = tf.map_fn(fn, thresholds)\n",
    "best_t = tf.argmax(apply_t)\n",
    "\n",
    "best = thresholds[best_t]\n",
    "\n",
    "# Redo the manipulation with the best threshold\n",
    "less = tf.less(dist,best)\n",
    "less = tf.cast(less,tf.int32)\n",
    "less = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], less)\n",
    "\n",
    "\n",
    "# # Creates different threshold in order to find the best one\n",
    "# np_threshold = np.vstack([np.arange(0,1,0.01)]*3).T\n",
    "\n",
    "# # Reshapes the distance\n",
    "# dist2 = tf.stack([dist]*len(np_threshold))\n",
    "\n",
    "# # Reshapes the true values\n",
    "# actual_issame = tf.constant([[True,True,False]]*len(np_threshold),dtype=bool)\n",
    "\n",
    "# threshold = tf.constant(np_threshold, dtype=tf.float32)\n",
    "\n",
    "# # Uses the created thresholds to compute the predictions\n",
    "# predict_issame = tf.less(dist2,threshold)\n",
    "\n",
    "# # Computes the accuracy\n",
    "# truth = tf.logical_not(tf.logical_xor(predict_issame, actual_issame))\n",
    "\n",
    "# r = tf.reduce_sum(tf.cast(truth,tf.float32),1)\n",
    "\n",
    "# # Finds the best accuracy with respect to the threshold\n",
    "# m = tf.argmax(r)\n",
    "\n",
    "# # best_threshold = threshold[m]\n",
    "# # accuracy = r[m]/3\n",
    "\n",
    "# # Ouputs the best output and reshapes the output in a softmax way\n",
    "# bool_output = predict_issame[m]\n",
    "# int_output = tf.cast(bool_output,tf.int32)\n",
    "# output = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], int_output)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    t1 = time.time()\n",
    "    dist_ = sess.run([less])\n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    print(dist_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.258671522140503\n",
      "[[ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]]\n",
      "[[False False  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]\n",
      " [ True  True False]]\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# tests unitaires\n",
    "\n",
    "tf.reset_default_graph()\n",
    "emb_raw = tf.constant([[12.,2],[8,4],[3,8],[2,10],[50,10],[10,30]])\n",
    "emb_ = tf.math.l2_normalize(emb_raw,0)\n",
    "\n",
    "# Normalizes\n",
    "emb = tf.math.l2_normalize(emb_,0)\n",
    "\n",
    "# Separates the pairs\n",
    "emb1 = emb[0::2]\n",
    "emb2 = emb[1::2]\n",
    "\n",
    "# Computes distance between pairs\n",
    "diff = tf.squared_difference(emb1,emb2)\n",
    "dist = tf.reduce_sum(diff,1)\n",
    "\n",
    "\n",
    "\n",
    "# Creates different threshold in order to find the best one\n",
    "np_threshold = np.vstack([np.arange(0,1,0.01)]*3).T\n",
    "\n",
    "# Reshapes the distance\n",
    "dist2 = tf.stack([dist]*len(np_threshold))\n",
    "\n",
    "# Reshapes the true values\n",
    "actual_issame = tf.constant([[True,True,False]]*len(np_threshold),dtype=bool)\n",
    "\n",
    "threshold = tf.constant(np_threshold, dtype=tf.float32)\n",
    "\n",
    "# Uses the created thresholds to compute the predictions\n",
    "predict_issame = tf.less(dist2,threshold)\n",
    "\n",
    "# Computes the accuracy\n",
    "truth = tf.logical_not(tf.logical_xor(predict_issame, actual_issame))\n",
    "\n",
    "r = tf.reduce_sum(tf.cast(truth,tf.float32),1)\n",
    "\n",
    "# Finds the best accuracy with respect to the threshold\n",
    "m = tf.argmax(r)\n",
    "\n",
    "# best_threshold = threshold[m]\n",
    "# accuracy = r[m]/3\n",
    "\n",
    "# Ouputs the best output and reshapes the output in a softmax way\n",
    "bool_output = predict_issame[m]\n",
    "int_output = tf.cast(bool_output,tf.int32)\n",
    "output = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], int_output)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    t1 = time.time()\n",
    "    act,pred,a_ = sess.run([actual_issame,truth,output])\n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    print(a_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Should only be used for validating\n",
    "class Validation(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Validation, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        self.emb_shape = input_shape[0]\n",
    "        super(Validation, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Inputs: a tuple containing the embeddings and the issame list\n",
    "        - embeddings: shape=(batch_size, embedding_size), type=float\n",
    "        - issame: shape=(batch_size), type=bool\n",
    "        \n",
    "        Outputs: a tensor of shape=(batch_size,2), the ouput is either [1,0] (is same) or [0,1] (is different)\n",
    "        \"\"\"\n",
    "        assert isinstance(x, list)\n",
    "        \n",
    "        embeddings, issame = x\n",
    "        self.emb_shape = embeddings.shape\n",
    "        print(self.emb_shape)\n",
    "\n",
    "        emb = tf.math.l2_normalize(embeddings,0)\n",
    "        # emb contains a list of pictures\n",
    "        # pictures with an even index are first pictures of the pairs\n",
    "        # pictures with an odd index are second pictures of the pairs\n",
    "        emb1 = emb[0::2]\n",
    "        emb2 = emb[1::2]\n",
    "        \n",
    "        # Compute the distance for each pair of vector\n",
    "        dist = tf.reduce_sum(tf.squared_difference(emb1,emb2),1)\n",
    "        \n",
    "        dist = tf.reshape(tf.stack([dist,dist], axis=-1), [-1])\n",
    "\n",
    "\n",
    "        def fn(t):\n",
    "            less = tf.less(dist,t)\n",
    "\n",
    "            actual_issame_bool = tf.cast(issame,dtype=tf.bool)\n",
    "            acc = tf.logical_not(tf.logical_xor(less,actual_issame_bool))\n",
    "            acc = tf.cast(acc,tf.float32)\n",
    "            out = tf.reshape(tf.reduce_sum(acc),[])\n",
    "            return out\n",
    "\n",
    "\n",
    "        thresholds = tf.range(0,1,0.001)\n",
    "        apply_t = tf.map_fn(fn, thresholds)\n",
    "        best_t = tf.argmax(apply_t)\n",
    "\n",
    "        best = thresholds[best_t]\n",
    "\n",
    "        # Redo the manipulation with the best threshold\n",
    "        less = tf.less(dist,best)\n",
    "        less = tf.cast(less,tf.int32)\n",
    "        output = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], less)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        emb_shape, _ = input_shape\n",
    "        return (BATCH_SIZE, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy(tf.keras.Model):\n",
    "    def __init__(self, out_num, emb_size = 32):\n",
    "        \"\"\"\n",
    "        -emb_size: size of the embedding\n",
    "        -out_num: number of identities in the \n",
    "        \"\"\"\n",
    "        super(Dummy, self).__init__(name='dummy')\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10,(3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20,(3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(40,(3, 3))\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv4 = tf.keras.layers.Conv2D(80,(3, 3))\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.layers.Dense(emb_size)\n",
    "        \n",
    "        self.arcface = Arcface(out_num)\n",
    "        self.validation = Validation()\n",
    "    \n",
    "    def call(self, input_tensor, training):\n",
    "        images, labels, issame = input_tensor\n",
    "        x = self.conv1(images)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dense(x)\n",
    "        embeddings = tf.math.l2_normalize(x)\n",
    "        \n",
    "        if traning:\n",
    "            output = self.arcface((embeddings,labels))\n",
    "        else:\n",
    "            output = self.validation((embeddings,issame))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoreDummy(tf.keras.Model):\n",
    "    def __init__(self, out_num, emb_size = 32):\n",
    "        \"\"\"\n",
    "        -emb_size: size of the embedding\n",
    "        -out_num: number of identities in the \n",
    "        \"\"\"\n",
    "        super(MoreDummy, self).__init__(name='more_dummy')\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10,(3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20,(3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(40,(3, 3))\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv4 = tf.keras.layers.Conv2D(80,(3, 3))\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.layers.Dense(emb_size)\n",
    "\n",
    "        self.arcface = Arcface(out_num)\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        images, labels = input_tensor\n",
    "        x = self.conv1(images)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dense(x)\n",
    "        embeddings = tf.math.l2_normalize(x)\n",
    "        \n",
    "        output = self.arcface([embeddings,labels])\n",
    "        \n",
    "        return output\n",
    "    \n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         # You need to override this function if you want to use the subclassed model\n",
    "#         # as part of a functional-style model.\n",
    "#         # Otherwise, this method is optional.\n",
    "#         shape = tf.TensorShape(self.out_num).as_list()\n",
    "#         shape[-1] = self.num_classes\n",
    "#         return tf.TensorShape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoreDummy(1300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tests unitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    " #tf.reset_default_graph()\n",
    "class EvenMoreDummy(tf.keras.Model):\n",
    "    def __init__(self, emb_size = 32):\n",
    "        \"\"\"\n",
    "        -emb_size: size of the embedding\n",
    "        -out_num: number of identities in the \n",
    "        \"\"\"\n",
    "        super(EvenMoreDummy, self).__init__(name='even_more_dummy')\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10,(3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20,(3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(40,(3, 3))\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        #self.conv4 = tf.keras.layers.Conv2D(80,(3, 3))\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.layers.Dense(emb_size)\n",
    "        \n",
    "        #self.arcface = Arcface(1300, name='output')\n",
    "        #self.mylayer = MyLayer(1300, name='output')\n",
    "        self.f = tf.layers.Dense(1301, name='out')\n",
    "        #self.out = tf.layers.Dense(2, trainable=False, name='test')\n",
    "        self.valid = Validation()\n",
    "        #self.poopool = tf.keras.layers.MaxPooling1D(2)\n",
    "    \n",
    "    def call(self, input_tensor, training=True):\n",
    "        images,labels,issame = input_tensor\n",
    "        x = self.conv1(images)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dense(x)\n",
    "        emb = tf.math.l2_normalize(x)\n",
    "        \n",
    "        if not training:\n",
    "            issame = self.valid([emb,issame])\n",
    "        \n",
    "        return [self.f(emb),issame]\n",
    "#         if training:\n",
    "#             #output = self.arcface([emb,labels])\n",
    "#             #output = self.mylayer(emb)\n",
    "#             #output = self.out(emb)\n",
    "#             return self.f(emb)\n",
    "#         else:\n",
    "#             return self.out(emb)\n",
    "#             output = self.valid([emb,issame])\n",
    "            \n",
    "        \n",
    "    \n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         # You need to override this function if you want to use the subclassed model\n",
    "#         # as part of a functional-style model.\n",
    "#         # Otherwise, this method is optional.\n",
    "#         shape = tf.TensorShape(self.out_num).as_list()\n",
    "#         shape[-1] = self.num_classes\n",
    "#         return tf.TensorShape(shape)\n",
    "\n",
    "model = EvenMoreDummy(32)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "issame_train = np.zeros((len(labels_train),2))\n",
    "issame_train[:,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Mul' Op has type float64 that does not match type int32 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    511\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[1;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[0;32m    984\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float64: 'Tensor(\"loss_7/output_2_loss/Log:0\", shape=(?, 2), dtype=float64)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-1cae45b16d1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0missame_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#     validation_data=([images_valid,labels_valid,issame_in],[labels_valid,issame_out])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps_per_epoch'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1536\u001b[1;33m         validation_split=validation_split)\n\u001b[0m\u001b[0;32m   1537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1538\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[1;32m--> 992\u001b[1;33m                                                      class_weight, batch_size)\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                      \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m                      \u001b[0mloss_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m                      target_tensors=target_tensors)\n\u001b[0m\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;31m# In graph mode, if we had just set inputs and targets as symbolic tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m       \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[0mloss_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_weights_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m           \u001b[0moutput_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweighted_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[1;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \"\"\"\n\u001b[0;32m    597\u001b[0m     \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m     \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m       \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    118\u001b[0m            'keras.losses.categorical_crossentropy')\n\u001b[0;32m    119\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m   3587\u001b[0m     \u001b[0mepsilon_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3588\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mepsilon_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3589\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3590\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3591\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1129\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   5356\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5357\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 5358\u001b[1;33m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   5359\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5360\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    544\u001b[0m                   \u001b[1;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[1;32m--> 546\u001b[1;33m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input 'y' of 'Mul' Op has type float64 that does not match type int32 of argument 'x'."
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    [images_train,labels_train,issame_train],\n",
    "    [labels_train,issame_train],\n",
    "    epochs=20,\n",
    "    batch_size=64\n",
    "#     validation_data=([images_valid,labels_valid,issame_in],[labels_valid,issame_out])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            multiple                  280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            multiple                  7240      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  164       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  multiple                  6505      \n",
      "=================================================================\n",
      "Total params: 16,009\n",
      "Trainable params: 16,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on the training/validation dataset to stop the worst examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6868594, 0.7891156]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict([images_test[0:1],labels_test[0:1],issame_in[0:1]])\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate it on the test dataset: one shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

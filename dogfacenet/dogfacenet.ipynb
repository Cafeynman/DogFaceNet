{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DogFaceNet version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/dogfacenet/'\n",
    "PATH_IMAGES = PATH + 'images/'\n",
    "PATH_RESIZED = PATH + 'resized/'\n",
    "\n",
    "# Size of the input image into the network\n",
    "SIZE = (100,100,3)\n",
    "\n",
    "TEST_SPLIT = 0.05\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing\n",
    "- Get the dataset from folders\n",
    "- Associate the corresponding classes\n",
    "- Resized the dataset\n",
    "- Shuffle the dataset?\n",
    "- Divide the dataset into validation, training and testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_crop(image):\n",
    "    \"\"\"\n",
    "    Takes the largest between height and width of the image and crops it into a square.\n",
    "    This square is located in the middle of the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    h,w,c = image.shape\n",
    "    \n",
    "    if w > h:\n",
    "        margin = w - h\n",
    "        margin = margin // 2\n",
    "        image = image[:,margin:margin+h,:]\n",
    "    elif w < h:\n",
    "        margin = h - w\n",
    "        margin = margin // 2\n",
    "        image = image[margin:margin+w,:,:]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6491e4baa6e74a5f88a1cbf88edfa807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "label = 0\n",
    "\n",
    "filenames = os.listdir(PATH_IMAGES)\n",
    "\n",
    "# Just save the pictures after resizing them\n",
    "for i in tqdm_notebook(range(598+869,len(filenames))):\n",
    "    for file in os.listdir(PATH_IMAGES + filenames[i]):\n",
    "        label += 1\n",
    "        \n",
    "        # Read and resized image\n",
    "        image = sk.io.imread(PATH_IMAGES + filenames[i] + '/' + file)\n",
    "        if len(image.shape) == 3:\n",
    "            image_cropped = square_crop(image)\n",
    "            image_resized = sk.transform.resize(image_cropped,SIZE)\n",
    "\n",
    "            # Save image\n",
    "            ## Check if the good folder exists\n",
    "            if filenames[i] not in os.listdir(PATH_RESIZED):\n",
    "                os.mkdir(PATH_RESIZED + filenames[i])\n",
    "            sk.io.imsave(PATH_RESIZED + filenames[i] + '/' + str(label) + '.jpg', image_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 5568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b215d9839184b09860d314c85485338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1477), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(PATH_RESIZED)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Remove unique examples\n",
    "while i<len(filenames):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    if len(files)<=1:\n",
    "        filenames = filenames[:i] + filenames[i+1:]\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "# Compute the number of images\n",
    "nbof_images = 0\n",
    "for i in range(0,len(filenames)):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    nbof_images += len(files)\n",
    "\n",
    "print(\"Number of images: \" + str(nbof_images))\n",
    "    \n",
    "w, h, c = SIZE\n",
    "\n",
    "images = np.empty((nbof_images,w,h,c))\n",
    "labels = np.empty(nbof_images, dtype=int)\n",
    "\n",
    "label = 0\n",
    "\n",
    "index = 0\n",
    "\n",
    "# Load images into numpy arrays\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    files = os.listdir(PATH_RESIZED + filenames[i])\n",
    "    for file in files:\n",
    "        labels[index] = label\n",
    "        # Read image\n",
    "        image = sk.io.imread(PATH_RESIZED + filenames[i] + '/' + file)\n",
    "\n",
    "        # Add the image to the table\n",
    "        images[index] = image\n",
    "        \n",
    "        index += 1\n",
    "    label += 1\n",
    "    \n",
    "assert len(labels)==len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old method!\n",
    "\n",
    "Divide the dataset into train, valid and test:\n",
    "\n",
    "To create the validation dataset we use pictures of dogs were there is more than 3 pictures and took one of this picture.\n",
    "\n",
    "For the testing dataset we simply split the classes. We will then use the network as a one shot learner on this new dataset. With one picture the network will produce one embedding vector. For each embedding vector compute the L2 distance with each face to compute the most propable one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5568\n",
      "Number of test images: 278\n",
      "Number of validation images: 543\n",
      "Number of training images: 4747\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-95fc612d2572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mcount_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;31m# print(labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# print(labels_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "nbof_test = int(len(images)*TEST_SPLIT)\n",
    "\n",
    "images_test = images[:nbof_test]\n",
    "labels_test = labels[:nbof_test]\n",
    "\n",
    "\n",
    "# Count valid images:\n",
    "state = -1\n",
    "count_valid = 0\n",
    "count_train = 0\n",
    "count_image_class = 0\n",
    "\n",
    "for i in range(nbof_test,len(labels)):\n",
    "    if state != labels[i]:\n",
    "        state = labels[i]\n",
    "        count_image_class = 0\n",
    "    else:\n",
    "        count_image_class += 1\n",
    "    \n",
    "    if count_image_class == 3:\n",
    "        count_valid += 1\n",
    "    else:\n",
    "        count_train += 1\n",
    "\n",
    "print(\"Total number of images: \" + str(len(labels)))\n",
    "print(\"Number of test images: \" + str(len(labels_test)))\n",
    "print(\"Number of validation images: \" + str(count_valid))\n",
    "print(\"Number of training images: \" + str(count_train))\n",
    "\n",
    "images_valid = np.empty((count_valid,w,h,c))\n",
    "labels_valid = np.empty(count_valid)\n",
    "\n",
    "images_train = np.empty((count_train,w,h,c))\n",
    "labels_train = np.empty(count_train)\n",
    "\n",
    "state = -1\n",
    "count_valid = 0\n",
    "count_train = 0\n",
    "count_image_class = 0\n",
    "\n",
    "for i in range(nbof_test,len(labels)):\n",
    "    if state != labels[i]:\n",
    "        state = labels[i]\n",
    "        count_image_class = 0\n",
    "    else:\n",
    "        count_image_class += 1\n",
    "    \n",
    "    if count_image_class == 3:\n",
    "        # Add the validation image in the validation array\n",
    "        images_valid[count_valid] = images[i]\n",
    "        labels_valid[count_valid] = labels[i]\n",
    "        \n",
    "        count_valid += 1\n",
    "    else:\n",
    "        images_train[count_train] = images[i]\n",
    "        labels_train[count_train] = labels[i]\n",
    "        \n",
    "        count_train += 1\n",
    "# print(labels)\n",
    "# print(labels_test)\n",
    "# print(labels_train)\n",
    "# print(labels_valid)\n",
    "print(\"Is the number of images coherent? \" + str(len(labels)==(len(labels_test)+len(labels_train)+len(labels_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New method\n",
    "- We divide the validation and test set from the training set with the classic division method: 85 percent training, 10 validating, 5 testing.\n",
    "- We then computes pairs of images in the validation set and testing set:\n",
    " - Some of these pairs are images of the same dog and some are picture of different dogs\n",
    " - We create a two lists:\n",
    "  - A list a images containing the pairs: two successive images are a pair of images. For example, image 0 and is a pair, image 2 and 3 is another pair, etc...\n",
    "  - A list of boolean called 'issame' indicating if a pair is a pair of images of the same dog or a pair of different dogs. For example, if image 0 and image 1 are showing the same dog value 0 and 1 in the list will be True. On the other hand if the image 2 and 3 represent two different dogs the value 2 and 3 in the list will be at False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5568\n",
      "Number of test images: 278\n",
      "Number of validation images: 556\n",
      "Number of training images: 4734\n",
      "Number of classes in the training set: 1300\n",
      "Number of pairs: 556\n",
      "Number of same images: 159\n",
      "Number of validation images: 556\n"
     ]
    }
   ],
   "source": [
    "w, h, c = SIZE\n",
    "\n",
    "nbof_test = int(len(images)*TEST_SPLIT)\n",
    "\n",
    "images_test = images[-nbof_test:]\n",
    "labels_test = labels[-nbof_test:]\n",
    "\n",
    "nbof_valid = int(len(images)*VALID_SPLIT)\n",
    "\n",
    "images_valid = images[-nbof_test-nbof_valid:-nbof_test]\n",
    "labels_valid = labels[-nbof_test-nbof_valid:-nbof_test]\n",
    "\n",
    "images_train = images[:-nbof_test-nbof_valid]\n",
    "labels_train = labels[:-nbof_test-nbof_valid]\n",
    "\n",
    "print(\"Total number of images: \" + str(len(labels)))\n",
    "print(\"Number of test images: \" + str(len(labels_test)))\n",
    "print(\"Number of validation images: \" + str(len(labels_valid)))\n",
    "print(\"Number of training images: \" + str(len(labels_train)))\n",
    "print(\"Number of classes in the training set: \" + str(labels_train[-1] - labels_train[0]))\n",
    "\n",
    "\n",
    "# Creates the pairs\n",
    "\n",
    "nbof_pairs = (len(images_valid)//2)*2 # it has to be multiple of 2\n",
    "\n",
    "print(\"Number of pairs: \" + str(nbof_pairs))\n",
    "\n",
    "pairs = np.empty((nbof_pairs,w,h,c))\n",
    "issame_in = np.empty(nbof_pairs, dtype=int)\n",
    "issame_out = np.empty((nbof_pairs,2))\n",
    "\n",
    "nbof_same = 0\n",
    "\n",
    "for i in range(0,nbof_pairs,2):\n",
    "    ## alea_issame will decide if the new pair will be a pair of same dog images or a pair of different\n",
    "    alea_issame = np.random.rand()\n",
    "\n",
    "    if alea_issame < 0.5: # Then it will be a pair of same dogs\n",
    "        # we randomly choose a dog\n",
    "        choice = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        # we extract the images of this class\n",
    "        chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice])])\n",
    "        \n",
    "        while len(labels_valid[np.equal(labels_valid,labels_valid[choice])]) < 2:\n",
    "            choice = np.random.randint(len(labels_valid))\n",
    "            chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice])])\n",
    "            \n",
    "        # we then randomly choose two pictures of this class\n",
    "        choice1 = np.random.randint(len(chosen_images))\n",
    "        pairs[i] = chosen_images[choice1]\n",
    "        save = np.copy(chosen_images)\n",
    "        chosen_images = chosen_images[:choice1] + chosen_images[choice1+1:]\n",
    "        if len(chosen_images) == 0:\n",
    "            print(\"Bug!\")\n",
    "            print(save)\n",
    "        choice2 = np.random.randint(len(chosen_images))\n",
    "        pairs[i+1] = chosen_images[choice2]\n",
    "\n",
    "        issame_out[i] = issame_out[i+1] = [1,0]\n",
    "        issame_in[i] = issame_in[i+1] = 1\n",
    "        \n",
    "        nbof_same += 1\n",
    "        \n",
    "    else: # Then it will be a pair of different dogs\n",
    "        # we randomly choose two dogs\n",
    "        choice1 = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        # we extract the images of the class\n",
    "        chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice1])])\n",
    "        \n",
    "        # we choose an image of this class\n",
    "        choice = np.random.randint(len(chosen_images))\n",
    "        #print(choice)\n",
    "        pairs[i] = images_valid[choice]\n",
    "        \n",
    "        choice2 = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        # check if we have two different classes\n",
    "        while labels_valid[choice2] == labels_valid[choice1]:\n",
    "            choice2 = np.random.randint(len(labels_valid))\n",
    "        \n",
    "        chosen_images = list(images_valid[np.equal(labels_valid,labels_valid[choice2])])\n",
    "        \n",
    "        # we choose an image of this class\n",
    "        choice = np.random.randint(len(chosen_images))\n",
    "        \n",
    "        pairs[i+1] = images_valid[choice]\n",
    "        \n",
    "        issame_out[i] = issame_out[i+1] = [0,1]\n",
    "        issame_in[i] = issame_in[i+1] = 0\n",
    "\n",
    "print(\"Number of same images: \" + str(nbof_same))\n",
    "print(\"Number of validation images: \" + str(len(labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBOF_CLASSES = max(labels_train)+1\n",
    "#labels_train = tf.keras.utils.to_categorical(labels_train,NBOF_CLASSES)\n",
    "#labels_valid = tf.keras.utils.to_categorical(labels_valid-NBOF_CLASSES,NBOF_CLASSES)\n",
    "issame_train_in = np.ones(len(labels_train))\n",
    "issame_train_out = np.zeros((len(labels_train),2))\n",
    "issame_train_out[:,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input shapes: \n",
      "(4734, 100, 100, 3)\n",
      "(4734,)\n",
      "(4734,)\n",
      "Train output shape: \n",
      "(4734,)\n",
      "(4734, 2)\n",
      "Valid input shape: \n",
      "(556, 100, 100, 3)\n",
      "(556,)\n",
      "(556,)\n",
      "Valid output shape: \n",
      "(556,)\n",
      "(556, 2)\n"
     ]
    }
   ],
   "source": [
    "# Verify shapes\n",
    "# Train inputs\n",
    "print(\"Train input shapes: \")\n",
    "print(images_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(issame_train_in.shape)\n",
    "\n",
    "print(\"Train output shape: \")\n",
    "print(labels_train.shape)\n",
    "print(issame_train_out.shape)\n",
    "\n",
    "print(\"Valid input shape: \")\n",
    "print(images_valid.shape)\n",
    "print(labels_valid.shape)\n",
    "print(issame_in.shape)\n",
    "\n",
    "print(\"Valid output shape: \")\n",
    "print(labels_valid.shape)\n",
    "print(issame_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "- Define the ArcFace layer\n",
    "- Define the dummy model first\n",
    "- Compile it with the softmax loss and and Adam optimizer\n",
    "- Then use transfer learning with a more complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Arcface layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "mask = tf.one_hot(tf.constant([1,2,2,3]),4)\n",
    "with tf.Session() as sess:\n",
    "    mask_ = sess.run(mask)\n",
    "    print(mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My custom layer for arcface\n",
    "# It takes two inputs: one for the embedding, one for the label\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "import math\n",
    "\n",
    "# Arcface should only be used for training\n",
    "class Arcface(Layer):\n",
    "\n",
    "    def __init__(self, out_num, s = 64., m = 0.5, **kwargs):\n",
    "        self.out_num = out_num\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        super(Arcface, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape, initializer='uniform'):\n",
    "        assert isinstance(input_shape, list)\n",
    "        \n",
    "        shape = tf.TensorShape((input_shape[0][-1],self.out_num))\n",
    "        print(shape)\n",
    "        \n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                                 shape=shape,\n",
    "                                                 initializer=initializer,\n",
    "                                                 dtype=tf.float32,\n",
    "                                                 trainable=True)\n",
    "        super(Arcface, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        assert isinstance(x, list)\n",
    "        embedding, labels = x\n",
    "        \n",
    "        cos_m = math.cos(self.m)\n",
    "        sin_m = math.sin(self.m)\n",
    "        mm = sin_m * self.m  # issue 1\n",
    "        threshold = math.cos(math.pi - self.m)\n",
    "        \n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keepdims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        \n",
    "        weights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n",
    "        weights = tf.div(self.kernel, weights_norm, name='norm_weights')\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "        \n",
    "        # this condition controls the theta+m should be in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = self.s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "        mask = tf.one_hot(labels, depth=self.out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "\n",
    "        output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_loss_output')\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        shape_emb, shape_lab = input_shape\n",
    "        shape_emb[-1] = self.out_num\n",
    "        return tf.TensorShape(shape_emb)\n",
    "    \n",
    "#         shape = tf.TensorShape(input_shape).as_list()\n",
    "#         shape[-1] = self.num_classes\n",
    "#         return tf.TensorShape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "import math\n",
    "\n",
    "# Arcface should only be used for training\n",
    "class Arcface(Layer):\n",
    "\n",
    "    def __init__(self, out_num, s = 64., m = 0.5, **kwargs):\n",
    "        self.out_num = out_num\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        super(Arcface, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape, initializer='uniform'):\n",
    "        assert isinstance(input_shape, list)\n",
    "        \n",
    "        shape = tf.TensorShape((input_shape[0][-1],self.out_num))\n",
    "        print(shape)\n",
    "        \n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                                 shape=shape,\n",
    "                                                 initializer=initializer,\n",
    "                                                 dtype=tf.float32,\n",
    "                                                 trainable=True)\n",
    "        super(Arcface, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        assert isinstance(x, list)\n",
    "        emb, labels = x\n",
    "        labels_sq = tf.squeeze(labels)\n",
    "        labels_int = tf.cast(labels,tf.int32, name='labels_int')\n",
    "        print(labels_int.shape)\n",
    "        mask = tf.one_hot(labels_int, depth=self.out_num, name='one_hot_mask')\n",
    "        print(mask.shape)\n",
    "        def train_output():\n",
    "            cos_m = math.cos(self.m)\n",
    "            sin_m = math.sin(self.m)\n",
    "            mm = sin_m * self.m  # issue 1\n",
    "            threshold = math.cos(math.pi - self.m)\n",
    "\n",
    "            # inputs and weights norm\n",
    "            embedding_norm = tf.norm(emb, axis=1, keepdims=True)\n",
    "            embedding = tf.div(emb, embedding_norm, name='norm_embedding')\n",
    "\n",
    "            weights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n",
    "            weights = tf.div(self.kernel, weights_norm, name='norm_weights')\n",
    "            # cos(theta+m)\n",
    "            cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "            print(cos_t.shape)\n",
    "            cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "            sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "            sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "            cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "\n",
    "            # this condition controls the theta+m should be in range [0, pi]\n",
    "            #      0<=theta+m<=pi\n",
    "            #     -m<=theta<=pi-m\n",
    "            cond_v = cos_t - threshold\n",
    "            cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "            keep_val = self.s*(cos_t - mm)\n",
    "            cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "            \n",
    "            # mask = tf.squeeze(mask, 1)\n",
    "            inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "            s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "            mul1 = tf.multiply(s_cos_t, inv_mask)\n",
    "            print(mul1.shape)\n",
    "            mul2 = tf.multiply(cos_mt_temp, mask)\n",
    "            print(mul2.shape)\n",
    "            output = tf.add(mul1, mul2, name='arcface_loss_output')\n",
    "            print(output.shape)\n",
    "            print(cos_mt_temp.shape)\n",
    "            \n",
    "            return output\n",
    "        \n",
    "        def valid_output():\n",
    "            return mask\n",
    "        \n",
    "        return K.in_train_phase(train_output,valid_output,training=training)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        shape_emb, shape_lab = input_shape\n",
    "        shape_emb[-1] = self.out_num\n",
    "        return tf.TensorShape(shape_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, s = 64., m = 0.5, **kwargs):\n",
    "        self.out_num = output_dim\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "        \n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        shape = (input_shape[1].value, self.out_num)\n",
    "        print(shape)\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        #assert isinstance(x, list)\n",
    "        embedding = x\n",
    "        \n",
    "        cos_m = math.cos(self.m)\n",
    "        sin_m = math.sin(self.m)\n",
    "        mm = sin_m * self.m  # issue 1\n",
    "        threshold = math.cos(math.pi - self.m)\n",
    "        \n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keepdims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        \n",
    "        weights_norm = tf.norm(self.kernel, axis=0, keepdims=True)\n",
    "        weights = tf.div(self.kernel, weights_norm, name='norm_weights')\n",
    "        #print(self.weights)\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = self.s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "        \n",
    "        # this condition controls the theta+m should be in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = self.s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "        #mask = tf.one_hot(labels, depth=self.out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        #inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        \n",
    "        s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n",
    "        \n",
    "        return s_cos_t\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0].value, self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the validation layer:\n",
    "- The bigger the validation batch the better it is (no less than 64 pictures -> 32 pairs)\n",
    "- It computes the ROC curve\n",
    "- Finds the best threshold\n",
    "- Returns a list of 2D vectors [1,0] if the pair was the same dog, [0,1] if it was a different dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "0.6226596832275391\n",
      "[1. 1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# tests unitaires\n",
    "\n",
    "tf.reset_default_graph()\n",
    "emb_raw = tf.constant([[12.,2],[8,4],[3,8],[2,10],[50,10],[10,30]])\n",
    "\n",
    "actual_issame = tf.constant([1.,1,1,1,0,0])\n",
    "emb = tf.math.l2_normalize(emb_raw,0)\n",
    "\n",
    "# Normalizes\n",
    "#emb = tf.math.l2_normalize(emb_,0)\n",
    "\n",
    "# Separates the pairs\n",
    "emb1 = emb[0::2]\n",
    "emb2 = emb[1::2]\n",
    "\n",
    "# Computes distance between pairs\n",
    "diff = tf.squared_difference(emb1,emb2)\n",
    "dist = tf.reduce_sum(diff,1)\n",
    "\n",
    "dist = tf.reshape(tf.stack([dist,dist], axis=-1), [-1])\n",
    "print(dist.shape)\n",
    "best_threshold = 0\n",
    "#for t in np.arange(0,1,0.001):\n",
    "t = 0.01\n",
    "\n",
    "actual_issame_bool = tf.cast(actual_issame,dtype=tf.bool)\n",
    "\n",
    "def fn(t):\n",
    "    less = tf.less(dist,t)\n",
    "\n",
    "    acc = tf.logical_not(tf.logical_xor(less,actual_issame_bool))\n",
    "    acc = tf.cast(acc,tf.float32)\n",
    "    \n",
    "    out = tf.reshape(tf.reduce_sum(acc),[])\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "thresholds = tf.range(0,1,0.001)\n",
    "apply_t = tf.map_fn(fn, thresholds)\n",
    "best_t = tf.argmax(apply_t)\n",
    "\n",
    "best = thresholds[best_t]\n",
    "\n",
    "# Redo the manipulation with the best threshold\n",
    "less = tf.less(dist,best)\n",
    "less = tf.cast(less,tf.float32)\n",
    "#less = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], less)\n",
    "\n",
    "\n",
    "# # Creates different threshold in order to find the best one\n",
    "# np_threshold = np.vstack([np.arange(0,1,0.01)]*3).T\n",
    "\n",
    "# # Reshapes the distance\n",
    "# dist2 = tf.stack([dist]*len(np_threshold))\n",
    "\n",
    "# # Reshapes the true values\n",
    "# actual_issame = tf.constant([[True,True,False]]*len(np_threshold),dtype=bool)\n",
    "\n",
    "# threshold = tf.constant(np_threshold, dtype=tf.float32)\n",
    "\n",
    "# # Uses the created thresholds to compute the predictions\n",
    "# predict_issame = tf.less(dist2,threshold)\n",
    "\n",
    "# # Computes the accuracy\n",
    "# truth = tf.logical_not(tf.logical_xor(predict_issame, actual_issame))\n",
    "\n",
    "# r = tf.reduce_sum(tf.cast(truth,tf.float32),1)\n",
    "\n",
    "# # Finds the best accuracy with respect to the threshold\n",
    "# m = tf.argmax(r)\n",
    "\n",
    "# # best_threshold = threshold[m]\n",
    "# # accuracy = r[m]/3\n",
    "\n",
    "# # Ouputs the best output and reshapes the output in a softmax way\n",
    "# bool_output = predict_issame[m]\n",
    "# int_output = tf.cast(bool_output,tf.int32)\n",
    "# output = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], int_output)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    t1 = time.time()\n",
    "    dist_ = sess.run(less)\n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    print(dist_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14561080932617188\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# tests unitaires\n",
    "\n",
    "tf.reset_default_graph()\n",
    "emb_raw = tf.constant([[12.,2],[8,4],[3,8],[2,10],[50,10],[10,30]])\n",
    "emb_ = tf.math.l2_normalize(emb_raw,0)\n",
    "\n",
    "# Normalizes\n",
    "emb = tf.math.l2_normalize(emb_,0)\n",
    "\n",
    "# Separates the pairs\n",
    "emb1 = emb[0::2]\n",
    "emb2 = emb[1::2]\n",
    "\n",
    "# Computes distance between pairs\n",
    "diff = tf.squared_difference(emb1,emb2)\n",
    "dist = tf.reduce_sum(diff,1)\n",
    "\n",
    "\n",
    "\n",
    "# Creates different threshold in order to find the best one\n",
    "np_threshold = np.vstack([np.arange(0,1,0.01)]*3).T\n",
    "\n",
    "# Reshapes the distance\n",
    "dist2 = tf.stack([dist]*len(np_threshold))\n",
    "\n",
    "# Reshapes the true values\n",
    "actual_issame = tf.constant([[True,True,False]]*len(np_threshold),dtype=bool)\n",
    "\n",
    "threshold = tf.constant(np_threshold, dtype=tf.float32)\n",
    "\n",
    "# Uses the created thresholds to compute the predictions\n",
    "predict_issame = tf.less(dist2,threshold)\n",
    "\n",
    "# Computes the accuracy\n",
    "truth = tf.logical_not(tf.logical_xor(predict_issame, actual_issame))\n",
    "\n",
    "r = tf.reduce_sum(tf.cast(truth,tf.float32),1)\n",
    "\n",
    "# Finds the best accuracy with respect to the threshold\n",
    "m = tf.argmax(r)\n",
    "\n",
    "# best_threshold = threshold[m]\n",
    "# accuracy = r[m]/3\n",
    "\n",
    "# Ouputs the best output and reshapes the output in a softmax way\n",
    "bool_output = predict_issame[m]\n",
    "int_output = tf.cast(bool_output,tf.int32)\n",
    "output = tf.map_fn(lambda x : (1-x) * [0,1] + x * [1,0], int_output)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    t1 = time.time()\n",
    "    act,pred,a_ = sess.run([actual_issame,truth,output])\n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    print(a_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Should only be used for validating\n",
    "class Validation(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Validation, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        self.emb_shape = input_shape[0]\n",
    "        super(Validation, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        \"\"\"\n",
    "        Inputs: a tuple containing the embeddings and the issame list\n",
    "        - embeddings: shape=(batch_size, embedding_size), type=float\n",
    "        - issame: shape=(batch_size), type=bool\n",
    "        \n",
    "        Outputs: a tensor of shape=(batch_size,2), the ouput is either [1,0] (is same) or [0,1] (is different)\n",
    "        \"\"\"\n",
    "        assert isinstance(x, list)\n",
    "        \n",
    "        embeddings, iss = x\n",
    "        \n",
    "        \n",
    "        \n",
    "        def train_output():\n",
    "            return iss\n",
    "        \n",
    "        def valid_output():\n",
    "            issame = tf.squeeze(iss)\n",
    "            #self.emb_shape = embeddings.shape\n",
    "            emb = tf.math.l2_normalize(embeddings,0)\n",
    "            # emb contains a list of pictures\n",
    "            # pictures with an even index are first pictures of the pairs\n",
    "            # pictures with an odd index are second pictures of the pairs\n",
    "            emb1 = embeddings[0::2]\n",
    "            emb2 = embeddings[1::2]\n",
    "            #emb1, emb2 = tf.split(embeddings, [32,32],0)\n",
    "            \n",
    "          # Compute the distance for each pair of vector\n",
    "            dist = tf.reduce_sum(tf.squared_difference(emb1,emb2),1)\n",
    "            dist = tf.reshape(tf.stack([dist,dist], axis=-1), [-1])\n",
    "            actual_issame_bool = tf.cast(issame,dtype=tf.bool)\n",
    "\n",
    "            def fn(t):\n",
    "                less = tf.less(dist,t)\n",
    "                acc = tf.logical_not(tf.logical_xor(less,actual_issame_bool))\n",
    "                acc = tf.cast(acc,tf.float32)\n",
    "                out = tf.reshape(tf.reduce_sum(acc),[])\n",
    "                return out\n",
    "\n",
    "\n",
    "            thresholds = tf.range(0,1,0.001)\n",
    "            apply_t = tf.map_fn(fn, thresholds)\n",
    "            best_t = tf.argmax(apply_t)\n",
    "\n",
    "            best = thresholds[best_t]\n",
    "\n",
    "          # Redo the manipulation with the best threshold\n",
    "            less = tf.less(dist,0.01)\n",
    "            less = tf.cast(less,tf.float32)\n",
    "            less = tf.expand_dims(less,1) # <- bug fixed\n",
    "            return less\n",
    "\n",
    "            \n",
    "        return K.in_train_phase(train_output,valid_output,training=training)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        emb_shape, _ = input_shape\n",
    "        return (emb_shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Dummy layers to try the testing/training phases\n",
    "class test(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(test, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(test, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        def train_output():\n",
    "            ret = tf.multiply(x,0.)\n",
    "            ret = tf.add(ret,1.)\n",
    "            #ret.set_shape(x.get_shape())\n",
    "            return ret\n",
    "        \n",
    "        def valid_output():\n",
    "            ret = tf.zeros_like(x)\n",
    "            return ret\n",
    "            \n",
    "        return K.in_train_phase(train_output,valid_output,training=training)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Dummy layers to try the testing/training phases\n",
    "class test(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(test, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(test, self).build(input_shape)\n",
    "\n",
    "    def call(self, y, training=None):\n",
    "        \n",
    "        x,iss = y\n",
    "        def train_output():\n",
    "            #ret = tf.multiply(x,0.)\n",
    "            #ret = tf.add(ret,1.)\n",
    "            #ret.set_shape(x.get_shape())\n",
    "            ret = iss\n",
    "            #ret.set_shape((iss.get_shape()[0],2))\n",
    "            return ret\n",
    "        \n",
    "        def valid_output():\n",
    "            ret = tf.zeros_like(iss)\n",
    "            return ret\n",
    "            \n",
    "        return K.in_train_phase(train_output,valid_output,training=training)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummiest(tf.keras.Model):\n",
    "    def __init__(self, emb_size = 32):\n",
    "        \"\"\"\n",
    "        -emb_size: size of the embedding\n",
    "        -out_num: number of identities in the \n",
    "        \"\"\"\n",
    "        super(EvenMoreDummy, self).__init__(name='even_more_dummy')\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10,(3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20,(3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(40,(3, 3))\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.layers.Dense(emb_size)\n",
    "        self.f = tf.layers.Dense(1301, name='out')\n",
    "    \n",
    "    def call(self, images, training=None):\n",
    "        \n",
    "        x = self.conv1(images)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        emb = tf.math.l2_normalize(x)\n",
    "        \n",
    "        return self.f(emb)\n",
    "\n",
    "model = Dummiest(32)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tests unitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "class EvenMoreDummy(tf.keras.Model):\n",
    "    def __init__(self, emb_size = 32):\n",
    "        \"\"\"\n",
    "        -emb_size: size of the embedding\n",
    "        -out_num: number of identities in the \n",
    "        \"\"\"\n",
    "        super(EvenMoreDummy, self).__init__(name='even_more_dummy')\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10,(3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20,(3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(40,(3, 3))\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.layers.Dense(emb_size)\n",
    "        self.drop = tf.keras.layers.Dropout(0.5)\n",
    "        self.f = tf.layers.Dense(1301, name='out')\n",
    "        self.test = test()\n",
    "    \n",
    "    def call(self, images, training=None):\n",
    "        \n",
    "        x = self.conv1(images)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.drop(x)\n",
    "        emb = tf.math.l2_normalize(x)\n",
    "        emb = self.f(emb)\n",
    "        emb = self.test(emb)\n",
    "\n",
    "        return emb\n",
    "\n",
    "model = EvenMoreDummy(32)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1301)\n",
      "(?, 1)\n",
      "(?, 1, 1301)\n",
      "(?, 1301)\n",
      "(?, ?, 1301)\n",
      "(?, ?, 1301)\n",
      "(?, ?, 1301)\n",
      "(?, 1301)\n"
     ]
    }
   ],
   "source": [
    "# Try to use the functional API\n",
    "tf.reset_default_graph()\n",
    "def net(inputs_shapes, emb_size=32):\n",
    "    images_shape, labels_shape, issame_shape = inputs_shapes\n",
    "    input_image = tf.keras.Input(images_shape,name='image_input')\n",
    "    x = tf.keras.layers.Conv2D(10,(3, 3))(input_image)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(20,(3, 3))(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(40,(3, 3))(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    emb = tf.keras.layers.Dense(emb_size, activity_regularizer='l2')(x)\n",
    "    #out = tf.keras.layers.Dense(1301, name='arcface')(emb)\n",
    "    \n",
    "    input_labels = tf.keras.Input(labels_shape,name='input_labels')\n",
    "    out = Arcface(1301, name='arcface')([emb,input_labels])\n",
    "                                         \n",
    "    input_issame = tf.keras.Input(issame_shape,name='issame_input')\n",
    "    valid = Validation(name='validation')([emb,input_issame])\n",
    "    \n",
    "    return tf.keras.Model(inputs=[input_image,input_labels,input_issame], outputs=[out,valid])\n",
    "\n",
    "w, h, c = SIZE\n",
    "inputs_shapes = [(w, h, c,),(1,),(1,)]\n",
    "model = net(inputs_shapes)\n",
    "model.compile(tf.train.AdamOptimizer(),loss={'arcface':'mse','validation':'binary_crossentropy'},metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_out = tf.keras.utils.to_categorical(labels_train,NBOF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4734,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train = np.ones(labels_train.shape)\n",
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_valid_out = tf.keras.utils.to_categorical(labels_valid-NBOF_CLASSES,NBOF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1300, 1300, 1300, 1301, 1301, 1301, 1301, 1301, 1302, 1302, 1302,\n",
       "       1302, 1302, 1302, 1302, 1303, 1303, 1303, 1303, 1303, 1303, 1304,\n",
       "       1304, 1304, 1304, 1305, 1305, 1305, 1306, 1306, 1306, 1307, 1307,\n",
       "       1308, 1308, 1309, 1309, 1309, 1310, 1310, 1310, 1311, 1311, 1311,\n",
       "       1312, 1312, 1313, 1313, 1314, 1314, 1314, 1315, 1315, 1315, 1315,\n",
       "       1315, 1315, 1315, 1315, 1316, 1316, 1316, 1317, 1317, 1317, 1317,\n",
       "       1318, 1318, 1318, 1318, 1318, 1319, 1319, 1319, 1319, 1319, 1319,\n",
       "       1319, 1320, 1320, 1321, 1321, 1321, 1322, 1322, 1322, 1322, 1323,\n",
       "       1323, 1323, 1323, 1323, 1323, 1324, 1324, 1324, 1324, 1325, 1325,\n",
       "       1325, 1326, 1326, 1327, 1327, 1328, 1328, 1329, 1329, 1330, 1330,\n",
       "       1330, 1330, 1330, 1331, 1331, 1331, 1332, 1332, 1332, 1332, 1333,\n",
       "       1333, 1333, 1334, 1334, 1334, 1335, 1335, 1335, 1336, 1336, 1336,\n",
       "       1336, 1336, 1336, 1336, 1337, 1337, 1338, 1338, 1339, 1339, 1340,\n",
       "       1340, 1340, 1341, 1341, 1342, 1342, 1342, 1343, 1343, 1344, 1344,\n",
       "       1344, 1345, 1345, 1346, 1346, 1347, 1347, 1348, 1348, 1348, 1349,\n",
       "       1349, 1350, 1350, 1350, 1350, 1351, 1351, 1351, 1351, 1351, 1352,\n",
       "       1352, 1352, 1352, 1352, 1353, 1353, 1353, 1353, 1354, 1354, 1354,\n",
       "       1354, 1355, 1355, 1355, 1355, 1355, 1355, 1356, 1356, 1357, 1357,\n",
       "       1357, 1358, 1358, 1358, 1358, 1359, 1359, 1359, 1359, 1359, 1359,\n",
       "       1360, 1360, 1360, 1361, 1361, 1362, 1362, 1363, 1363, 1363, 1364,\n",
       "       1364, 1365, 1365, 1366, 1366, 1366, 1366, 1367, 1367, 1368, 1368,\n",
       "       1368, 1369, 1369, 1370, 1370, 1370, 1371, 1371, 1372, 1372, 1372,\n",
       "       1372, 1372, 1372, 1372, 1372, 1372, 1372, 1373, 1373, 1373, 1373,\n",
       "       1373, 1374, 1374, 1374, 1374, 1374, 1374, 1374, 1375, 1375, 1376,\n",
       "       1376, 1376, 1377, 1377, 1378, 1378, 1378, 1378, 1378, 1378, 1379,\n",
       "       1379, 1379, 1380, 1380, 1380, 1381, 1381, 1381, 1382, 1382, 1383,\n",
       "       1383, 1384, 1384, 1385, 1385, 1386, 1386, 1387, 1387, 1388, 1388,\n",
       "       1389, 1389, 1390, 1390, 1390, 1390, 1391, 1391, 1391, 1391, 1392,\n",
       "       1392, 1392, 1393, 1393, 1394, 1394, 1394, 1395, 1395, 1395, 1396,\n",
       "       1396, 1396, 1396, 1397, 1397, 1398, 1398, 1399, 1399, 1399, 1400,\n",
       "       1400, 1401, 1401, 1401, 1402, 1402, 1402, 1403, 1403, 1403, 1403,\n",
       "       1403, 1404, 1404, 1404, 1404, 1404, 1405, 1405, 1405, 1405, 1405,\n",
       "       1405, 1406, 1406, 1406, 1407, 1407, 1408, 1408, 1409, 1409, 1410,\n",
       "       1410, 1411, 1411, 1412, 1412, 1412, 1412, 1413, 1413, 1413, 1414,\n",
       "       1414, 1415, 1415, 1415, 1416, 1416, 1416, 1417, 1417, 1417, 1418,\n",
       "       1418, 1418, 1418, 1419, 1419, 1420, 1420, 1420, 1421, 1421, 1421,\n",
       "       1422, 1422, 1422, 1423, 1423, 1424, 1424, 1425, 1425, 1426, 1426,\n",
       "       1427, 1427, 1428, 1428, 1428, 1429, 1429, 1430, 1430, 1430, 1430,\n",
       "       1430, 1431, 1431, 1431, 1431, 1432, 1432, 1433, 1433, 1433, 1433,\n",
       "       1433, 1434, 1434, 1434, 1435, 1435, 1436, 1436, 1437, 1437, 1438,\n",
       "       1438, 1439, 1439, 1439, 1439, 1439, 1439, 1440, 1440, 1440, 1440,\n",
       "       1440, 1440, 1440, 1441, 1441, 1442, 1442, 1442, 1443, 1443, 1443,\n",
       "       1443, 1443, 1444, 1444, 1445, 1445, 1446, 1446, 1446, 1447, 1447,\n",
       "       1447, 1448, 1448, 1448, 1448, 1448, 1449, 1449, 1449, 1449, 1450,\n",
       "       1450, 1450, 1451, 1451, 1451, 1451, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452, 1452,\n",
       "       1452, 1452, 1452, 1452, 1452, 1453])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_valid = np.zeros(labels_valid.shape)\n",
    "labels_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected arcface to have 3 dimensions, but got array with shape (4734, 1301)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-853a78793acf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimages_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0missame_in\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabels_valid_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0missame_in\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m#validation_data = ([images_valid,issame_in], labels_valid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#validation_data=([images_valid,labels_valid,issame_in],[labels_valid,issame_out])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps_per_epoch'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1536\u001b[1;33m         validation_split=validation_split)\n\u001b[0m\u001b[0;32m   1537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1538\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[1;32m--> 992\u001b[1;33m                                                      class_weight, batch_size)\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   1152\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m           exception_prefix='target')\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m       \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    321\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected arcface to have 3 dimensions, but got array with shape (4734, 1301)"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    #[images_train,issame_train_in],\n",
    "    [images_train,labels_train,issame_train_in],\n",
    "    #[labels_train,issame_train_out],\n",
    "    #[labels_train,issame_train_out],\n",
    "    [labels_train_out,issame_train_in],\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_data = ([images_valid,labels_valid,issame_in], [labels_valid_out,issame_in])\n",
    "    #validation_data = ([images_valid,issame_in], labels_valid)\n",
    "    #validation_data=([images_valid,labels_valid,issame_in],[labels_valid,issame_out])\n",
    "    #callbacks=[tf.keras.callbacks.TensorBoard(log_dir='../output/logs/')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        (None, 100, 100, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 98, 98, 10)   280         image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 49, 49, 10)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 47, 47, 20)   1820        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 23, 23, 20)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 21, 21, 40)   7240        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 40)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 40)           0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           1312        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "input_labels (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "issame_input (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "arcface (Arcface)               (None, 1301)         41632       dense[0][0]                      \n",
      "                                                                 input_labels[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "validation (Validation)         (None, 1)            0           dense[0][0]                      \n",
      "                                                                 issame_input[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 52,284\n",
      "Trainable params: 52,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on the training/validation dataset to stop the worst examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(images_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6868594, 0.7891156]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict([images_test[0:1],labels_test[0:1],issame_in[0:1]])\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate it on the test dataset: one shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

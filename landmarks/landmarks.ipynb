{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models\n",
    "\n",
    "PATH = '../data/landmarks/'\n",
    "\n",
    "IMAGE_SIZE = (128,128,3)\n",
    "\n",
    "# Limite size of input for testing\n",
    "TEST_LIMIT = 1000\n",
    "\n",
    "SPLIT = 0.8\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "STEPS_PER_EPOCH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658, 7, 2)\n",
      "(658,)\n",
      "(658,)\n",
      "Loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/658 [00:00<?, ?it/s]c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 658/658 [01:44<00:00,  6.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the raw images\n",
    "resized_path = PATH + 'resized/'\n",
    "filenames = os.listdir(resized_path)\n",
    "\n",
    "## Sort the filenames in the proper order\n",
    "filename_int = np.sort([int(s[:-4]) for s in filenames])\n",
    "\n",
    "filenames = np.array([resized_path + str(i) + '.jpg' for i in filename_int])\n",
    "\n",
    "# Retrieve the masks\n",
    "masks_path = PATH + 'resized_masks/'\n",
    "f_masks = os.listdir(masks_path)\n",
    "\n",
    "## Sort the filenames in the proper order\n",
    "f_masks_int = np.sort([int(s[:-4]) for s in f_masks])\n",
    "\n",
    "f_masks = np.array([resized_path + str(i) + '.jpg' for i in f_masks_int])\n",
    "\n",
    "# Retrieve the landmarks\n",
    "labels = np.load(PATH + 'resized_labels.npy')\n",
    "\n",
    "# Reshape the outputs\n",
    "print(labels.shape)\n",
    "print(f_masks.shape)\n",
    "print(filenames.shape)\n",
    "assert len(f_masks)==len(labels)\n",
    "assert len(filenames)==len(labels)\n",
    "\n",
    "if TEST_LIMIT>len(labels):\n",
    "    TEST_LIMIT = len(labels)\n",
    "\n",
    "\n",
    "w,h,c = IMAGE_SIZE\n",
    "images = np.empty((0,w,h,c))\n",
    "\n",
    "masks = np.empty((0,w,h,1))\n",
    "\n",
    "print(\"Loading images...\")\n",
    "labels = labels[:TEST_LIMIT]\n",
    "labels = np.reshape(labels,(TEST_LIMIT,14))\n",
    "labels = labels[:,:10]\n",
    "\n",
    "for i in tqdm(range(TEST_LIMIT)):\n",
    "    image = sk.io.imread(filenames[i])\n",
    "    image_resized = sk.transform.resize(image, IMAGE_SIZE)\n",
    "    images = np.vstack((images,np.expand_dims(image_resized,0)))\n",
    "\n",
    "    mask = sk.io.imread(f_masks[i])\n",
    "\n",
    "    mask_resized = sk.transform.resize(mask, (w,h,1))\n",
    "    masks = np.vstack((masks,np.expand_dims(mask_resized,0)))\n",
    "\n",
    "\n",
    "\n",
    "train_split = int(SPLIT*len(labels))\n",
    "\n",
    "images_train = images[:train_split]\n",
    "images_valid = images[train_split:]\n",
    "\n",
    "masks_train = masks[:train_split]\n",
    "masks_valid = masks[train_split:]\n",
    "\n",
    "labels_train = labels[:train_split]\n",
    "labels_valid = labels[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TriNet(ratio=4, input_shape=(128,128,3)):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "     -ratio: ratio of channel reduction in SE module\n",
    "     -imput_shape: input image shape\n",
    "    \"\"\"\n",
    "    \n",
    "    def CBA_layer(x, filters, size=3, depth=2):\n",
    "        \n",
    "        for _ in range(depth):\n",
    "            x = tf.keras.layers.Conv2D(filters, (size, size), padding='same') (x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def Res_layer(x, num_split, filters):\n",
    "        '''\n",
    "        ResNet-like layer\n",
    "        '''\n",
    "        \n",
    "        # Spliting the branches and changing the size of the convolution\n",
    "        splitted_branches = list()\n",
    "        \n",
    "        for i in range(num_split):\n",
    "            if i+1 < 6:\n",
    "                size = i+1 \n",
    "            else:\n",
    "                size = 3\n",
    "            branch = CBA_layer(x, filters, size)\n",
    "            splitted_branches.append(branch)\n",
    "        \n",
    "        x = tf.keras.layers.concatenate(splitted_branches)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same') (x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def SE_layer(x):\n",
    "        '''\n",
    "        SENet-like layer\n",
    "        '''\n",
    "        out_dim = int(np.shape(x)[-1])\n",
    "        squeeze = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        excitation = tf.keras.layers.Dense(units=out_dim // ratio)(squeeze)\n",
    "        excitation = tf.keras.layers.Activation('relu')(excitation)\n",
    "        excitation = tf.keras.layers.Dense(units=out_dim)(excitation)\n",
    "        excitation = tf.keras.layers.Activation('sigmoid')(excitation)\n",
    "        excitation = tf.keras.layers.Reshape((1,1,out_dim))(excitation)\n",
    "        \n",
    "        scale = tf.keras.layers.multiply([x,excitation])\n",
    "        \n",
    "        return scale\n",
    "    \n",
    "    def RSE_layer(x, num_split, filters):\n",
    "        r = Res_layer(x, num_split, filters)\n",
    "        s = SE_layer(r)\n",
    "        c = tf.keras.layers.concatenate([x,s])\n",
    "        return tf.keras.layers.Activation('relu')(c)\n",
    "    \n",
    "\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "\n",
    "    s = tf.keras.layers.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    #Down 1\n",
    "    r1 = RSE_layer(s, 2, 8)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r1)\n",
    "    \n",
    "    #Down 2\n",
    "    r2 = RSE_layer(x, 4, 16)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r2)\n",
    "    \n",
    "    #Down 3\n",
    "    r3 = RSE_layer(x, 4, 32)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r3)\n",
    "    \n",
    "    #Down 4\n",
    "    r4 = RSE_layer(x, 6, 64)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r4)\n",
    "    \n",
    "    #Down 5\n",
    "    r5 = RSE_layer(x, 6, 128)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r5)\n",
    "    \n",
    "    #Middle\n",
    "    x = RSE_layer(x, 4, 256)\n",
    "\n",
    "    # First branch: landmarks detection\n",
    "    y = CBA_layer(x, 512)\n",
    "    y = tf.keras.layers.GlobalAveragePooling2D()(y)\n",
    "    y = tf.keras.layers.Flatten()(y)\n",
    "    y = tf.keras.layers.Dense(10)(y)\n",
    "    landmarks_output = tf.keras.layers.Lambda(lambda x: x * 255, name='landmarks_output')(y)\n",
    "    \n",
    "    # Second branch: mask generation\n",
    "    #Up 1\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r5])\n",
    "    x = RSE_layer(x, 6, 128)\n",
    "    \n",
    "    #Up 2\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r4])\n",
    "    x = RSE_layer(x, 6, 64)\n",
    "    \n",
    "    #Up 3\n",
    "    x = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r3])\n",
    "    x = RSE_layer(x, 4, 32)\n",
    "    \n",
    "    #Up 4\n",
    "    x = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r2])\n",
    "    x = RSE_layer(x, 4, 16)\n",
    "    \n",
    "    #Up 5\n",
    "    x = tf.keras.layers.Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r1])\n",
    "    x = RSE_layer(x, 2, 8)\n",
    "    \n",
    "    mask_output = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', name='mask_output') (x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, [landmarks_output, mask_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 128, 128, 3)  0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 128, 128, 8)  32          lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 128, 128, 8)  104         lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_567 (BatchN (None, 128, 128, 8)  32          conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_569 (BatchN (None, 128, 128, 8)  32          conv2d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_661 (Activation)     (None, 128, 128, 8)  0           batch_normalization_567[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_663 (Activation)     (None, 128, 128, 8)  0           batch_normalization_569[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 128, 128, 8)  72          activation_661[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 128, 128, 8)  264         activation_663[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_568 (BatchN (None, 128, 128, 8)  32          conv2d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_570 (BatchN (None, 128, 128, 8)  32          conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_662 (Activation)     (None, 128, 128, 8)  0           batch_normalization_568[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_664 (Activation)     (None, 128, 128, 8)  0           batch_normalization_570[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 128, 128, 16) 0           activation_662[0][0]             \n",
      "                                                                 activation_664[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 128, 128, 8)  1160        concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_571 (BatchN (None, 128, 128, 8)  32          conv2d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_51 (Gl (None, 8)            0           batch_normalization_571[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 2)            18          global_average_pooling2d_51[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_665 (Activation)     (None, 2)            0           dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 8)            24          activation_665[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_666 (Activation)     (None, 8)            0           dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_47 (Reshape)            (None, 1, 1, 8)      0           activation_666[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_47 (Multiply)          (None, 128, 128, 8)  0           batch_normalization_571[0][0]    \n",
      "                                                                 reshape_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 128, 128, 11) 0           lambda_5[0][0]                   \n",
      "                                                                 multiply_47[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_667 (Activation)     (None, 128, 128, 11) 0           concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 64, 64, 11)   0           activation_667[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 64, 64, 16)   192         max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 64, 64, 16)   720         max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 64, 64, 16)   1600        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 64, 64, 16)   2832        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_572 (BatchN (None, 64, 64, 16)   64          conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_574 (BatchN (None, 64, 64, 16)   64          conv2d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_576 (BatchN (None, 64, 64, 16)   64          conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_578 (BatchN (None, 64, 64, 16)   64          conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_668 (Activation)     (None, 64, 64, 16)   0           batch_normalization_572[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_670 (Activation)     (None, 64, 64, 16)   0           batch_normalization_574[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_672 (Activation)     (None, 64, 64, 16)   0           batch_normalization_576[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_674 (Activation)     (None, 64, 64, 16)   0           batch_normalization_578[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 64, 64, 16)   272         activation_668[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 64, 64, 16)   1040        activation_670[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 64, 64, 16)   2320        activation_672[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 64, 64, 16)   4112        activation_674[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_573 (BatchN (None, 64, 64, 16)   64          conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_575 (BatchN (None, 64, 64, 16)   64          conv2d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_577 (BatchN (None, 64, 64, 16)   64          conv2d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_579 (BatchN (None, 64, 64, 16)   64          conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_669 (Activation)     (None, 64, 64, 16)   0           batch_normalization_573[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_671 (Activation)     (None, 64, 64, 16)   0           batch_normalization_575[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_673 (Activation)     (None, 64, 64, 16)   0           batch_normalization_577[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_675 (Activation)     (None, 64, 64, 16)   0           batch_normalization_579[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 64, 64, 64)   0           activation_669[0][0]             \n",
      "                                                                 activation_671[0][0]             \n",
      "                                                                 activation_673[0][0]             \n",
      "                                                                 activation_675[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 64, 64, 16)   9232        concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_580 (BatchN (None, 64, 64, 16)   64          conv2d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_52 (Gl (None, 16)           0           batch_normalization_580[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 4)            68          global_average_pooling2d_52[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_676 (Activation)     (None, 4)            0           dense_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 16)           80          activation_676[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_677 (Activation)     (None, 16)           0           dense_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_48 (Reshape)            (None, 1, 1, 16)     0           activation_677[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_48 (Multiply)          (None, 64, 64, 16)   0           batch_normalization_580[0][0]    \n",
      "                                                                 reshape_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 64, 64, 27)   0           max_pooling2d_20[0][0]           \n",
      "                                                                 multiply_48[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_678 (Activation)     (None, 64, 64, 27)   0           concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 32, 32, 27)   0           activation_678[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 32, 32, 32)   896         max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 32, 32, 32)   3488        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 32, 32, 32)   7808        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 32, 32, 32)   13856       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_581 (BatchN (None, 32, 32, 32)   128         conv2d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_583 (BatchN (None, 32, 32, 32)   128         conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_585 (BatchN (None, 32, 32, 32)   128         conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchN (None, 32, 32, 32)   128         conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_679 (Activation)     (None, 32, 32, 32)   0           batch_normalization_581[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_681 (Activation)     (None, 32, 32, 32)   0           batch_normalization_583[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_683 (Activation)     (None, 32, 32, 32)   0           batch_normalization_585[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_685 (Activation)     (None, 32, 32, 32)   0           batch_normalization_587[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 32, 32, 32)   1056        activation_679[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 32, 32, 32)   4128        activation_681[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 32, 32, 32)   9248        activation_683[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 32, 32, 32)   16416       activation_685[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_582 (BatchN (None, 32, 32, 32)   128         conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_584 (BatchN (None, 32, 32, 32)   128         conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchN (None, 32, 32, 32)   128         conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchN (None, 32, 32, 32)   128         conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_680 (Activation)     (None, 32, 32, 32)   0           batch_normalization_582[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_682 (Activation)     (None, 32, 32, 32)   0           batch_normalization_584[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_684 (Activation)     (None, 32, 32, 32)   0           batch_normalization_586[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_686 (Activation)     (None, 32, 32, 32)   0           batch_normalization_588[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 32, 32, 128)  0           activation_680[0][0]             \n",
      "                                                                 activation_682[0][0]             \n",
      "                                                                 activation_684[0][0]             \n",
      "                                                                 activation_686[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 32, 32, 32)   36896       concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchN (None, 32, 32, 32)   128         conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_53 (Gl (None, 32)           0           batch_normalization_589[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 8)            264         global_average_pooling2d_53[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_687 (Activation)     (None, 8)            0           dense_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 32)           288         activation_687[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_688 (Activation)     (None, 32)           0           dense_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_49 (Reshape)            (None, 1, 1, 32)     0           activation_688[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_49 (Multiply)          (None, 32, 32, 32)   0           batch_normalization_589[0][0]    \n",
      "                                                                 reshape_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 32, 32, 59)   0           max_pooling2d_21[0][0]           \n",
      "                                                                 multiply_49[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_689 (Activation)     (None, 32, 32, 59)   0           concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 16, 16, 59)   0           activation_689[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 16, 16, 64)   3840        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)             (None, 16, 16, 64)   15168       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)             (None, 16, 16, 64)   34048       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 16, 16, 64)   60480       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 16, 16, 64)   94464       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 16, 16, 64)   34048       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchN (None, 16, 16, 64)   256         conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_592 (BatchN (None, 16, 16, 64)   256         conv2d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_594 (BatchN (None, 16, 16, 64)   256         conv2d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchN (None, 16, 16, 64)   256         conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchN (None, 16, 16, 64)   256         conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchN (None, 16, 16, 64)   256         conv2d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_690 (Activation)     (None, 16, 16, 64)   0           batch_normalization_590[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_692 (Activation)     (None, 16, 16, 64)   0           batch_normalization_592[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_694 (Activation)     (None, 16, 16, 64)   0           batch_normalization_594[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_696 (Activation)     (None, 16, 16, 64)   0           batch_normalization_596[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_698 (Activation)     (None, 16, 16, 64)   0           batch_normalization_598[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_700 (Activation)     (None, 16, 16, 64)   0           batch_normalization_600[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)             (None, 16, 16, 64)   4160        activation_690[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)             (None, 16, 16, 64)   16448       activation_692[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 16, 16, 64)   36928       activation_694[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 16, 16, 64)   65600       activation_696[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 16, 16, 64)   102464      activation_698[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 16, 16, 64)   36928       activation_700[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_591 (BatchN (None, 16, 16, 64)   256         conv2d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_593 (BatchN (None, 16, 16, 64)   256         conv2d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_595 (BatchN (None, 16, 16, 64)   256         conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchN (None, 16, 16, 64)   256         conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchN (None, 16, 16, 64)   256         conv2d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchN (None, 16, 16, 64)   256         conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_691 (Activation)     (None, 16, 16, 64)   0           batch_normalization_591[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_693 (Activation)     (None, 16, 16, 64)   0           batch_normalization_593[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_695 (Activation)     (None, 16, 16, 64)   0           batch_normalization_595[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_697 (Activation)     (None, 16, 16, 64)   0           batch_normalization_597[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_699 (Activation)     (None, 16, 16, 64)   0           batch_normalization_599[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_701 (Activation)     (None, 16, 16, 64)   0           batch_normalization_601[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 16, 16, 384)  0           activation_691[0][0]             \n",
      "                                                                 activation_693[0][0]             \n",
      "                                                                 activation_695[0][0]             \n",
      "                                                                 activation_697[0][0]             \n",
      "                                                                 activation_699[0][0]             \n",
      "                                                                 activation_701[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 16, 16, 64)   221248      concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchN (None, 16, 16, 64)   256         conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_54 (Gl (None, 64)           0           batch_normalization_602[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 16)           1040        global_average_pooling2d_54[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_702 (Activation)     (None, 16)           0           dense_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 64)           1088        activation_702[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_703 (Activation)     (None, 64)           0           dense_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_50 (Reshape)            (None, 1, 1, 64)     0           activation_703[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 16, 16, 64)   0           batch_normalization_602[0][0]    \n",
      "                                                                 reshape_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 16, 16, 123)  0           max_pooling2d_22[0][0]           \n",
      "                                                                 multiply_50[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_704 (Activation)     (None, 16, 16, 123)  0           concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 8, 8, 123)    0           activation_704[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 8, 8, 128)    15872       max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)             (None, 8, 8, 128)    63104       max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)             (None, 8, 8, 128)    141824      max_pooling2d_23[0][0]           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)             (None, 8, 8, 128)    252032      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)             (None, 8, 8, 128)    393728      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)             (None, 8, 8, 128)    141824      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchN (None, 8, 8, 128)    512         conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchN (None, 8, 8, 128)    512         conv2d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchN (None, 8, 8, 128)    512         conv2d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 8, 8, 128)    512         conv2d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 8, 8, 128)    512         conv2d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 8, 8, 128)    512         conv2d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_705 (Activation)     (None, 8, 8, 128)    0           batch_normalization_603[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_707 (Activation)     (None, 8, 8, 128)    0           batch_normalization_605[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_709 (Activation)     (None, 8, 8, 128)    0           batch_normalization_607[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_711 (Activation)     (None, 8, 8, 128)    0           batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_713 (Activation)     (None, 8, 8, 128)    0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_715 (Activation)     (None, 8, 8, 128)    0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)             (None, 8, 8, 128)    16512       activation_705[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)             (None, 8, 8, 128)    65664       activation_707[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 8, 8, 128)    147584      activation_709[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)             (None, 8, 8, 128)    262272      activation_711[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)             (None, 8, 8, 128)    409728      activation_713[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)             (None, 8, 8, 128)    147584      activation_715[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchN (None, 8, 8, 128)    512         conv2d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchN (None, 8, 8, 128)    512         conv2d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchN (None, 8, 8, 128)    512         conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 8, 8, 128)    512         conv2d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 8, 8, 128)    512         conv2d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 8, 8, 128)    512         conv2d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_706 (Activation)     (None, 8, 8, 128)    0           batch_normalization_604[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_708 (Activation)     (None, 8, 8, 128)    0           batch_normalization_606[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_710 (Activation)     (None, 8, 8, 128)    0           batch_normalization_608[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_712 (Activation)     (None, 8, 8, 128)    0           batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_714 (Activation)     (None, 8, 8, 128)    0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_716 (Activation)     (None, 8, 8, 128)    0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 8, 8, 768)    0           activation_706[0][0]             \n",
      "                                                                 activation_708[0][0]             \n",
      "                                                                 activation_710[0][0]             \n",
      "                                                                 activation_712[0][0]             \n",
      "                                                                 activation_714[0][0]             \n",
      "                                                                 activation_716[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)             (None, 8, 8, 128)    884864      concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 8, 8, 128)    512         conv2d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_55 (Gl (None, 128)          0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 32)           4128        global_average_pooling2d_55[0][0]\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_717 (Activation)     (None, 32)           0           dense_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 128)          4224        activation_717[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_718 (Activation)     (None, 128)          0           dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_51 (Reshape)            (None, 1, 1, 128)    0           activation_718[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 8, 8, 128)    0           batch_normalization_615[0][0]    \n",
      "                                                                 reshape_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 8, 8, 251)    0           max_pooling2d_23[0][0]           \n",
      "                                                                 multiply_51[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_719 (Activation)     (None, 8, 8, 251)    0           concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 4, 4, 251)    0           activation_719[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)             (None, 4, 4, 256)    64512       max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)             (None, 4, 4, 256)    257280      max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)             (None, 4, 4, 256)    578560      max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 4, 4, 256)    1028352     max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 4, 4, 256)    1024        conv2d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchN (None, 4, 4, 256)    1024        conv2d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchN (None, 4, 4, 256)    1024        conv2d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchN (None, 4, 4, 256)    1024        conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_720 (Activation)     (None, 4, 4, 256)    0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_722 (Activation)     (None, 4, 4, 256)    0           batch_normalization_618[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_724 (Activation)     (None, 4, 4, 256)    0           batch_normalization_620[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_726 (Activation)     (None, 4, 4, 256)    0           batch_normalization_622[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)             (None, 4, 4, 256)    65792       activation_720[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)             (None, 4, 4, 256)    262400      activation_722[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)             (None, 4, 4, 256)    590080      activation_724[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)             (None, 4, 4, 256)    1048832     activation_726[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchN (None, 4, 4, 256)    1024        conv2d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchN (None, 4, 4, 256)    1024        conv2d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchN (None, 4, 4, 256)    1024        conv2d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchN (None, 4, 4, 256)    1024        conv2d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_721 (Activation)     (None, 4, 4, 256)    0           batch_normalization_617[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_723 (Activation)     (None, 4, 4, 256)    0           batch_normalization_619[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_725 (Activation)     (None, 4, 4, 256)    0           batch_normalization_621[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_727 (Activation)     (None, 4, 4, 256)    0           batch_normalization_623[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 4, 4, 1024)   0           activation_721[0][0]             \n",
      "                                                                 activation_723[0][0]             \n",
      "                                                                 activation_725[0][0]             \n",
      "                                                                 activation_727[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 4, 4, 256)    2359552     concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchN (None, 4, 4, 256)    1024        conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_56 (Gl (None, 256)          0           batch_normalization_624[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 64)           16448       global_average_pooling2d_56[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_728 (Activation)     (None, 64)           0           dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 256)          16640       activation_728[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "activation_729 (Activation)     (None, 256)          0           dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_52 (Reshape)            (None, 1, 1, 256)    0           activation_729[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 4, 4, 256)    0           batch_normalization_624[0][0]    \n",
      "                                                                 reshape_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 4, 4, 507)    0           max_pooling2d_24[0][0]           \n",
      "                                                                 multiply_52[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_730 (Activation)     (None, 4, 4, 507)    0           concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTran (None, 8, 8, 128)    259712      activation_730[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 8, 8, 379)    0           conv2d_transpose_20[0][0]        \n",
      "                                                                 activation_719[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 8, 8, 128)    48640       concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 8, 8, 128)    194176      concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 8, 8, 128)    436736      concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 8, 8, 128)    776320      concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 8, 8, 128)    1212928     concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 8, 8, 128)    436736      concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchN (None, 8, 8, 128)    512         conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchN (None, 8, 8, 128)    512         conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchN (None, 8, 8, 128)    512         conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchN (None, 8, 8, 128)    512         conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_635 (BatchN (None, 8, 8, 128)    512         conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_637 (BatchN (None, 8, 8, 128)    512         conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_733 (Activation)     (None, 8, 8, 128)    0           batch_normalization_627[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_735 (Activation)     (None, 8, 8, 128)    0           batch_normalization_629[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_737 (Activation)     (None, 8, 8, 128)    0           batch_normalization_631[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_739 (Activation)     (None, 8, 8, 128)    0           batch_normalization_633[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_741 (Activation)     (None, 8, 8, 128)    0           batch_normalization_635[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_743 (Activation)     (None, 8, 8, 128)    0           batch_normalization_637[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 8, 8, 128)    16512       activation_733[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 8, 8, 128)    65664       activation_735[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 8, 8, 128)    147584      activation_737[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 8, 8, 128)    262272      activation_739[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 8, 8, 128)    409728      activation_741[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 8, 8, 128)    147584      activation_743[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchN (None, 8, 8, 128)    512         conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchN (None, 8, 8, 128)    512         conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchN (None, 8, 8, 128)    512         conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_634 (BatchN (None, 8, 8, 128)    512         conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_636 (BatchN (None, 8, 8, 128)    512         conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_638 (BatchN (None, 8, 8, 128)    512         conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_734 (Activation)     (None, 8, 8, 128)    0           batch_normalization_628[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_736 (Activation)     (None, 8, 8, 128)    0           batch_normalization_630[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_738 (Activation)     (None, 8, 8, 128)    0           batch_normalization_632[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_740 (Activation)     (None, 8, 8, 128)    0           batch_normalization_634[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_742 (Activation)     (None, 8, 8, 128)    0           batch_normalization_636[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_744 (Activation)     (None, 8, 8, 128)    0           batch_normalization_638[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 8, 8, 768)    0           activation_734[0][0]             \n",
      "                                                                 activation_736[0][0]             \n",
      "                                                                 activation_738[0][0]             \n",
      "                                                                 activation_740[0][0]             \n",
      "                                                                 activation_742[0][0]             \n",
      "                                                                 activation_744[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 8, 8, 128)    884864      concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_639 (BatchN (None, 8, 8, 128)    512         conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_58 (Gl (None, 128)          0           batch_normalization_639[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 32)           4128        global_average_pooling2d_58[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_745 (Activation)     (None, 32)           0           dense_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 128)          4224        activation_745[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_746 (Activation)     (None, 128)          0           dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_53 (Reshape)            (None, 1, 1, 128)    0           activation_746[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 8, 8, 128)    0           batch_normalization_639[0][0]    \n",
      "                                                                 reshape_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 8, 8, 507)    0           concatenate_126[0][0]            \n",
      "                                                                 multiply_53[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_747 (Activation)     (None, 8, 8, 507)    0           concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTran (None, 16, 16, 64)   129856      activation_747[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 16, 16, 187)  0           conv2d_transpose_21[0][0]        \n",
      "                                                                 activation_704[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 16, 16, 64)   12032       concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 16, 16, 64)   47936       concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 16, 16, 64)   107776      concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 16, 16, 64)   191552      concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 16, 16, 64)   299264      concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 16, 16, 64)   107776      concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_640 (BatchN (None, 16, 16, 64)   256         conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_642 (BatchN (None, 16, 16, 64)   256         conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_644 (BatchN (None, 16, 16, 64)   256         conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchN (None, 16, 16, 64)   256         conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchN (None, 16, 16, 64)   256         conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchN (None, 16, 16, 64)   256         conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_748 (Activation)     (None, 16, 16, 64)   0           batch_normalization_640[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_750 (Activation)     (None, 16, 16, 64)   0           batch_normalization_642[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_752 (Activation)     (None, 16, 16, 64)   0           batch_normalization_644[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_754 (Activation)     (None, 16, 16, 64)   0           batch_normalization_646[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_756 (Activation)     (None, 16, 16, 64)   0           batch_normalization_648[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_758 (Activation)     (None, 16, 16, 64)   0           batch_normalization_650[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 16, 16, 64)   4160        activation_748[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_644 (Conv2D)             (None, 16, 16, 64)   16448       activation_750[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 16, 16, 64)   36928       activation_752[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 16, 16, 64)   65600       activation_754[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 16, 16, 64)   102464      activation_756[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 16, 16, 64)   36928       activation_758[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_641 (BatchN (None, 16, 16, 64)   256         conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_643 (BatchN (None, 16, 16, 64)   256         conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_645 (BatchN (None, 16, 16, 64)   256         conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchN (None, 16, 16, 64)   256         conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchN (None, 16, 16, 64)   256         conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchN (None, 16, 16, 64)   256         conv2d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_749 (Activation)     (None, 16, 16, 64)   0           batch_normalization_641[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_751 (Activation)     (None, 16, 16, 64)   0           batch_normalization_643[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_753 (Activation)     (None, 16, 16, 64)   0           batch_normalization_645[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_755 (Activation)     (None, 16, 16, 64)   0           batch_normalization_647[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_757 (Activation)     (None, 16, 16, 64)   0           batch_normalization_649[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_759 (Activation)     (None, 16, 16, 64)   0           batch_normalization_651[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 16, 16, 384)  0           activation_749[0][0]             \n",
      "                                                                 activation_751[0][0]             \n",
      "                                                                 activation_753[0][0]             \n",
      "                                                                 activation_755[0][0]             \n",
      "                                                                 activation_757[0][0]             \n",
      "                                                                 activation_759[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 16, 16, 64)   221248      concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchN (None, 16, 16, 64)   256         conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_59 (Gl (None, 64)           0           batch_normalization_652[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 16)           1040        global_average_pooling2d_59[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_760 (Activation)     (None, 16)           0           dense_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 64)           1088        activation_760[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_761 (Activation)     (None, 64)           0           dense_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_54 (Reshape)            (None, 1, 1, 64)     0           activation_761[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 16, 16, 64)   0           batch_normalization_652[0][0]    \n",
      "                                                                 reshape_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 16, 16, 251)  0           concatenate_129[0][0]            \n",
      "                                                                 multiply_54[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_762 (Activation)     (None, 16, 16, 251)  0           concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 32, 32, 32)   32160       activation_762[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 32, 32, 91)   0           conv2d_transpose_22[0][0]        \n",
      "                                                                 activation_689[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)             (None, 32, 32, 32)   2944        concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)             (None, 32, 32, 32)   11680       concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_658 (Conv2D)             (None, 32, 32, 32)   26240       concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_660 (Conv2D)             (None, 32, 32, 32)   46624       concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchN (None, 32, 32, 32)   128         conv2d_654[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_655 (BatchN (None, 32, 32, 32)   128         conv2d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_657 (BatchN (None, 32, 32, 32)   128         conv2d_658[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_659 (BatchN (None, 32, 32, 32)   128         conv2d_660[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_763 (Activation)     (None, 32, 32, 32)   0           batch_normalization_653[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_765 (Activation)     (None, 32, 32, 32)   0           batch_normalization_655[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_767 (Activation)     (None, 32, 32, 32)   0           batch_normalization_657[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_769 (Activation)     (None, 32, 32, 32)   0           batch_normalization_659[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)             (None, 32, 32, 32)   1056        activation_763[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)             (None, 32, 32, 32)   4128        activation_765[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_659 (Conv2D)             (None, 32, 32, 32)   9248        activation_767[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_661 (Conv2D)             (None, 32, 32, 32)   16416       activation_769[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_654 (BatchN (None, 32, 32, 32)   128         conv2d_655[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_656 (BatchN (None, 32, 32, 32)   128         conv2d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_658 (BatchN (None, 32, 32, 32)   128         conv2d_659[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_660 (BatchN (None, 32, 32, 32)   128         conv2d_661[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_764 (Activation)     (None, 32, 32, 32)   0           batch_normalization_654[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_766 (Activation)     (None, 32, 32, 32)   0           batch_normalization_656[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_768 (Activation)     (None, 32, 32, 32)   0           batch_normalization_658[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_770 (Activation)     (None, 32, 32, 32)   0           batch_normalization_660[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 32, 32, 128)  0           activation_764[0][0]             \n",
      "                                                                 activation_766[0][0]             \n",
      "                                                                 activation_768[0][0]             \n",
      "                                                                 activation_770[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_662 (Conv2D)             (None, 32, 32, 32)   36896       concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_661 (BatchN (None, 32, 32, 32)   128         conv2d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_60 (Gl (None, 32)           0           batch_normalization_661[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 8)            264         global_average_pooling2d_60[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_771 (Activation)     (None, 8)            0           dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 32)           288         activation_771[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_772 (Activation)     (None, 32)           0           dense_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_55 (Reshape)            (None, 1, 1, 32)     0           activation_772[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_55 (Multiply)          (None, 32, 32, 32)   0           batch_normalization_661[0][0]    \n",
      "                                                                 reshape_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 32, 32, 123)  0           concatenate_132[0][0]            \n",
      "                                                                 multiply_55[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_773 (Activation)     (None, 32, 32, 123)  0           concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DTran (None, 64, 64, 16)   7888        activation_773[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 64, 64, 43)   0           conv2d_transpose_23[0][0]        \n",
      "                                                                 activation_678[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_663 (Conv2D)             (None, 64, 64, 16)   704         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_665 (Conv2D)             (None, 64, 64, 16)   2768        concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_667 (Conv2D)             (None, 64, 64, 16)   6208        concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_669 (Conv2D)             (None, 64, 64, 16)   11024       concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_662 (BatchN (None, 64, 64, 16)   64          conv2d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_664 (BatchN (None, 64, 64, 16)   64          conv2d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_666 (BatchN (None, 64, 64, 16)   64          conv2d_667[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_668 (BatchN (None, 64, 64, 16)   64          conv2d_669[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_774 (Activation)     (None, 64, 64, 16)   0           batch_normalization_662[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_776 (Activation)     (None, 64, 64, 16)   0           batch_normalization_664[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_778 (Activation)     (None, 64, 64, 16)   0           batch_normalization_666[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_780 (Activation)     (None, 64, 64, 16)   0           batch_normalization_668[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_664 (Conv2D)             (None, 64, 64, 16)   272         activation_774[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_666 (Conv2D)             (None, 64, 64, 16)   1040        activation_776[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_668 (Conv2D)             (None, 64, 64, 16)   2320        activation_778[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_670 (Conv2D)             (None, 64, 64, 16)   4112        activation_780[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_663 (BatchN (None, 64, 64, 16)   64          conv2d_664[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_665 (BatchN (None, 64, 64, 16)   64          conv2d_666[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_667 (BatchN (None, 64, 64, 16)   64          conv2d_668[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_669 (BatchN (None, 64, 64, 16)   64          conv2d_670[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_775 (Activation)     (None, 64, 64, 16)   0           batch_normalization_663[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_777 (Activation)     (None, 64, 64, 16)   0           batch_normalization_665[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_779 (Activation)     (None, 64, 64, 16)   0           batch_normalization_667[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_781 (Activation)     (None, 64, 64, 16)   0           batch_normalization_669[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 64, 64, 64)   0           activation_775[0][0]             \n",
      "                                                                 activation_777[0][0]             \n",
      "                                                                 activation_779[0][0]             \n",
      "                                                                 activation_781[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_671 (Conv2D)             (None, 64, 64, 16)   9232        concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_670 (BatchN (None, 64, 64, 16)   64          conv2d_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_61 (Gl (None, 16)           0           batch_normalization_670[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 4)            68          global_average_pooling2d_61[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_782 (Activation)     (None, 4)            0           dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 16)           80          activation_782[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_783 (Activation)     (None, 16)           0           dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_56 (Reshape)            (None, 1, 1, 16)     0           activation_783[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_56 (Multiply)          (None, 64, 64, 16)   0           batch_normalization_670[0][0]    \n",
      "                                                                 reshape_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 64, 64, 59)   0           concatenate_135[0][0]            \n",
      "                                                                 multiply_56[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_784 (Activation)     (None, 64, 64, 59)   0           concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DTran (None, 128, 128, 8)  1896        activation_784[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 128, 128, 19) 0           conv2d_transpose_24[0][0]        \n",
      "                                                                 activation_667[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_672 (Conv2D)             (None, 128, 128, 8)  160         concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_674 (Conv2D)             (None, 128, 128, 8)  616         concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_671 (BatchN (None, 128, 128, 8)  32          conv2d_672[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_673 (BatchN (None, 128, 128, 8)  32          conv2d_674[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_785 (Activation)     (None, 128, 128, 8)  0           batch_normalization_671[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_787 (Activation)     (None, 128, 128, 8)  0           batch_normalization_673[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_673 (Conv2D)             (None, 128, 128, 8)  72          activation_785[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_675 (Conv2D)             (None, 128, 128, 8)  264         activation_787[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_672 (BatchN (None, 128, 128, 8)  32          conv2d_673[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_674 (BatchN (None, 128, 128, 8)  32          conv2d_675[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_786 (Activation)     (None, 128, 128, 8)  0           batch_normalization_672[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_788 (Activation)     (None, 128, 128, 8)  0           batch_normalization_674[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 128, 128, 16) 0           activation_786[0][0]             \n",
      "                                                                 activation_788[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_676 (Conv2D)             (None, 128, 128, 8)  1160        concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_675 (BatchN (None, 128, 128, 8)  32          conv2d_676[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)             (None, 4, 4, 512)    2336768     activation_730[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_62 (Gl (None, 8)            0           batch_normalization_675[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchN (None, 4, 4, 512)    2048        conv2d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 2)            18          global_average_pooling2d_62[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_731 (Activation)     (None, 4, 4, 512)    0           batch_normalization_625[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_789 (Activation)     (None, 2)            0           dense_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 4, 4, 512)    2359808     activation_731[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 8)            24          activation_789[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchN (None, 4, 4, 512)    2048        conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_790 (Activation)     (None, 8)            0           dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_732 (Activation)     (None, 4, 4, 512)    0           batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_57 (Reshape)            (None, 1, 1, 8)      0           activation_790[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_57 (Gl (None, 512)          0           activation_732[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_57 (Multiply)          (None, 128, 128, 8)  0           batch_normalization_675[0][0]    \n",
      "                                                                 reshape_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 512)          0           global_average_pooling2d_57[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 128, 128, 27) 0           concatenate_138[0][0]            \n",
      "                                                                 multiply_57[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 10)           5130        flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_791 (Activation)     (None, 128, 128, 27) 0           concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "landmarks_output (Lambda)       (None, 10)           0           dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mask_output (Conv2D)            (None, 128, 128, 1)  28          activation_791[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,752,394\n",
      "Trainable params: 21,733,866\n",
      "Non-trainable params: 18,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# layers = [10, 16, 32, 64, 128]\n",
    "# model = models.MultiTaskResNet(layers, 14, IMAGE_SIZE)\n",
    "model = TriNet()\n",
    "print(model.summary())\n",
    "\n",
    "losses = {\n",
    "    \"mask_output\": \"binary_crossentropy\",\n",
    "    \"landmarks_output\": \"mse\"\n",
    "}\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss=losses,\n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 526 samples, validate on 132 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node concatenate_60/concat}} = ConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_354/Relu, activation_356/Relu, activation_358/Relu, activation_360/Relu, loss_1/landmarks_output_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/axis)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_1/acc_1/Mean_1/_8473}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_36243_metrics_1/acc_1/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8591df237be9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"mask_output\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmasks_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"landmarks_output\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabels_valid\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node concatenate_60/concat}} = ConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_354/Relu, activation_356/Relu, activation_358/Relu, activation_360/Relu, loss_1/landmarks_output_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/axis)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_1/acc_1/Mean_1/_8473}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_36243_metrics_1/acc_1/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint(\n",
    "#         '../weights/landmarks/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "#         save_best_only=True,\n",
    "#         save_weights_only=True\n",
    "#         ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='../output/logs')\n",
    "    ]\n",
    "\n",
    "model.fit(\n",
    "    images_train,\n",
    "    {\"mask_output\": masks_train, \"landmarks_output\": labels_train},\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(images_valid, {\"mask_output\": masks_valid, \"landmarks_output\": labels_valid})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x292a6c438d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filenames = os.listdir(PATH+'resized/')\n",
    "\n",
    "test_images = np.array([sk.io.imread(PATH+'resized/' + filenames[i]) for i in range(2)])\n",
    "\n",
    "test_images = np.array([sk.transform.resize(image, IMAGE_SIZE) for image in test_images])\n",
    "\n",
    "masks_o, landmarks = model.predict(test_images)\n",
    "masks = (masks_o > 0.8).astype(np.uint8)\n",
    "\n",
    "print(masks[0].shape)\n",
    "for i in range(2):\n",
    "    mask = np.squeeze(masks[i]).astype(np.float32)\n",
    "    plt.imshow(np.dstack((mask,mask,mask)))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models\n",
    "\n",
    "PATH = '../data/landmarks/'\n",
    "\n",
    "IMAGE_SIZE = (128,128,3)\n",
    "\n",
    "# Limite size of input for testing\n",
    "TEST_LIMIT = 1000\n",
    "\n",
    "SPLIT = 0.8\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "STEPS_PER_EPOCH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658, 7, 2)\n",
      "(658,)\n",
      "(658,)\n",
      "Loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/658 [00:00<?, ?it/s]c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 658/658 [01:24<00:00,  7.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the raw images\n",
    "resized_path = PATH + 'resized/'\n",
    "filenames = os.listdir(resized_path)\n",
    "\n",
    "## Sort the filenames in the proper order\n",
    "filename_int = np.sort([int(s[:-4]) for s in filenames])\n",
    "\n",
    "filenames = np.array([resized_path + str(i) + '.jpg' for i in filename_int])\n",
    "\n",
    "# Retrieve the masks\n",
    "masks_path = PATH + 'resized_masks/'\n",
    "f_masks = os.listdir(masks_path)\n",
    "\n",
    "## Sort the filenames in the proper order\n",
    "f_masks_int = np.sort([int(s[:-4]) for s in f_masks])\n",
    "\n",
    "f_masks = np.array([resized_path + str(i) + '.jpg' for i in f_masks_int])\n",
    "\n",
    "# Retrieve the landmarks\n",
    "labels = np.load(PATH + 'resized_labels.npy')\n",
    "\n",
    "# Reshape the outputs\n",
    "print(labels.shape)\n",
    "print(f_masks.shape)\n",
    "print(filenames.shape)\n",
    "assert len(f_masks)==len(labels)\n",
    "assert len(filenames)==len(labels)\n",
    "\n",
    "if TEST_LIMIT>len(labels):\n",
    "    TEST_LIMIT = len(labels)\n",
    "\n",
    "\n",
    "w,h,c = IMAGE_SIZE\n",
    "images = np.empty((0,w,h,c))\n",
    "\n",
    "masks = np.empty((0,w//4,h//4,1))\n",
    "\n",
    "print(\"Loading images...\")\n",
    "labels = labels[:TEST_LIMIT]\n",
    "labels = np.reshape(labels,(TEST_LIMIT,14))\n",
    "labels = labels[:,:10]\n",
    "\n",
    "for i in tqdm(range(TEST_LIMIT)):\n",
    "    image = sk.io.imread(filenames[i])\n",
    "    image_resized = sk.transform.resize(image, IMAGE_SIZE)\n",
    "    images = np.vstack((images,np.expand_dims(image_resized,0)))\n",
    "\n",
    "    mask = sk.io.imread(f_masks[i])\n",
    "\n",
    "    mask_resized = sk.transform.resize(mask, (w//4,h//4,1))\n",
    "    masks = np.vstack((masks,np.expand_dims(mask_resized,0)))\n",
    "\n",
    "\n",
    "\n",
    "train_split = int(SPLIT*len(labels))\n",
    "\n",
    "images_train = images[:train_split]\n",
    "images_valid = images[train_split:]\n",
    "\n",
    "masks_train = masks[:train_split]\n",
    "masks_valid = masks[train_split:]\n",
    "\n",
    "labels_train = labels[:train_split]\n",
    "labels_valid = labels[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 10) 280         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 10) 910         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 10) 40          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 128, 13) 0           max_pooling2d[0][0]              \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 1888        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 16)   2320        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 13)   0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 29)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   8384        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 32)   9248        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 29)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 61)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 64)   35200       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 61)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 125)  0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 125)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 125)          0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mask_output (Conv2D)            (None, 32, 32, 1)    550         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "landmarks_output (Dense)        (None, 10)           1260        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 97,456\n",
      "Trainable params: 97,212\n",
      "Non-trainable params: 244\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "layers = [10, 16, 32, 64]\n",
    "model = models.MultiTaskResNet(layers, 14, IMAGE_SIZE)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "losses = {\n",
    "    \"mask_output\": \"binary_crossentropy\",\n",
    "    \"landmarks_output\": \"mse\"\n",
    "}\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss=losses,\n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 526 samples, validate on 132 samples\n",
      "Epoch 1/20\n",
      "526/526 [==============================] - ETA: 1:29 - loss: 54260.7148 - mask_output_loss: 29.4986 - landmarks_output_loss: 54231.2148 - mask_output_acc: 0.0078 - landmarks_output_acc: 0.18 - ETA: 42s - loss: 56966.7695 - mask_output_loss: 26.0210 - landmarks_output_loss: 56940.7480 - mask_output_acc: 0.0042 - landmarks_output_acc: 0.1562 - ETA: 27s - loss: 57091.4049 - mask_output_loss: 24.5258 - landmarks_output_loss: 57066.8789 - mask_output_acc: 0.0045 - landmarks_output_acc: 0.125 - ETA: 19s - loss: 55128.1289 - mask_output_loss: 23.7596 - landmarks_output_loss: 55104.3691 - mask_output_acc: 0.0051 - landmarks_output_acc: 0.109 - ETA: 14s - loss: 55673.7977 - mask_output_loss: 23.2820 - landmarks_output_loss: 55650.5156 - mask_output_acc: 0.0060 - landmarks_output_acc: 0.093 - ETA: 11s - loss: 56235.6035 - mask_output_loss: 22.9252 - landmarks_output_loss: 56212.6784 - mask_output_acc: 0.0060 - landmarks_output_acc: 0.078 - ETA: 8s - loss: 56971.1535 - mask_output_loss: 22.6350 - landmarks_output_loss: 56948.5184 - mask_output_acc: 0.0063 - landmarks_output_acc: 0.071 - ETA: 7s - loss: 57816.9087 - mask_output_loss: 22.2529 - landmarks_output_loss: 57794.6558 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.06 - ETA: 5s - loss: 57706.7283 - mask_output_loss: 22.0308 - landmarks_output_loss: 57684.6975 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.06 - ETA: 4s - loss: 57769.7215 - mask_output_loss: 21.7938 - landmarks_output_loss: 57747.9277 - mask_output_acc: 0.0080 - landmarks_output_acc: 0.06 - ETA: 3s - loss: 57925.1776 - mask_output_loss: 21.6978 - landmarks_output_loss: 57903.4798 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.06 - ETA: 2s - loss: 58217.6224 - mask_output_loss: 21.5657 - landmarks_output_loss: 58196.0566 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.07 - ETA: 1s - loss: 57983.1725 - mask_output_loss: 21.5588 - landmarks_output_loss: 57961.6136 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.08 - ETA: 1s - loss: 58118.4489 - mask_output_loss: 21.4961 - landmarks_output_loss: 58096.9526 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.10 - ETA: 0s - loss: 58100.4828 - mask_output_loss: 21.4179 - landmarks_output_loss: 58079.0646 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.11 - ETA: 0s - loss: 58236.5823 - mask_output_loss: 21.3638 - landmarks_output_loss: 58215.2183 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.12 - 9s 17ms/step - loss: 58141.4566 - mask_output_loss: 21.0286 - landmarks_output_loss: 58120.4278 - mask_output_acc: 0.0086 - landmarks_output_acc: 0.1312 - val_loss: 64518.7687 - val_mask_output_loss: 21.6852 - val_landmarks_output_loss: 64497.0838 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 54669.1758 - mask_output_loss: 19.4716 - landmarks_output_loss: 54649.7031 - mask_output_acc: 0.0064 - landmarks_output_acc: 0.15 - ETA: 2s - loss: 59615.0488 - mask_output_loss: 19.8877 - landmarks_output_loss: 59595.1602 - mask_output_acc: 0.0037 - landmarks_output_acc: 0.15 - ETA: 1s - loss: 59436.7044 - mask_output_loss: 19.6105 - landmarks_output_loss: 59417.0938 - mask_output_acc: 0.0045 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 59623.1035 - mask_output_loss: 19.4943 - landmarks_output_loss: 59603.6094 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 59599.7977 - mask_output_loss: 19.3461 - landmarks_output_loss: 59580.4516 - mask_output_acc: 0.0110 - landmarks_output_acc: 0.20 - ETA: 1s - loss: 60118.6986 - mask_output_loss: 19.3793 - landmarks_output_loss: 60099.3190 - mask_output_acc: 0.0107 - landmarks_output_acc: 0.20 - ETA: 1s - loss: 60348.6585 - mask_output_loss: 19.3188 - landmarks_output_loss: 60329.3393 - mask_output_acc: 0.0103 - landmarks_output_acc: 0.20 - ETA: 1s - loss: 59933.8135 - mask_output_loss: 19.3044 - landmarks_output_loss: 59914.5088 - mask_output_acc: 0.0106 - landmarks_output_acc: 0.20 - ETA: 1s - loss: 59259.8125 - mask_output_loss: 19.3007 - landmarks_output_loss: 59240.5113 - mask_output_acc: 0.0100 - landmarks_output_acc: 0.19 - ETA: 0s - loss: 58693.7797 - mask_output_loss: 19.2993 - landmarks_output_loss: 58674.4801 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.19 - ETA: 0s - loss: 58104.9837 - mask_output_loss: 19.3412 - landmarks_output_loss: 58085.6424 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.19 - ETA: 0s - loss: 58734.5475 - mask_output_loss: 19.3470 - landmarks_output_loss: 58715.2002 - mask_output_acc: 0.0090 - landmarks_output_acc: 0.19 - ETA: 0s - loss: 58386.0814 - mask_output_loss: 19.3974 - landmarks_output_loss: 58366.6836 - mask_output_acc: 0.0087 - landmarks_output_acc: 0.20 - ETA: 0s - loss: 58348.4891 - mask_output_loss: 19.4088 - landmarks_output_loss: 58329.0798 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.20 - ETA: 0s - loss: 58030.2044 - mask_output_loss: 19.4046 - landmarks_output_loss: 58010.7995 - mask_output_acc: 0.0080 - landmarks_output_acc: 0.21 - ETA: 0s - loss: 58035.5845 - mask_output_loss: 19.3805 - landmarks_output_loss: 58016.2036 - mask_output_acc: 0.0083 - landmarks_output_acc: 0.22 - 3s 5ms/step - loss: 57857.0743 - mask_output_loss: 19.0915 - landmarks_output_loss: 57837.9824 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2243 - val_loss: 64535.8400 - val_mask_output_loss: 21.8358 - val_landmarks_output_loss: 64514.0041 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 63008.1094 - mask_output_loss: 18.9152 - landmarks_output_loss: 62989.1953 - mask_output_acc: 0.0054 - landmarks_output_acc: 0.28 - ETA: 2s - loss: 61623.5898 - mask_output_loss: 19.0335 - landmarks_output_loss: 61604.5566 - mask_output_acc: 0.0041 - landmarks_output_acc: 0.32 - ETA: 1s - loss: 57383.4141 - mask_output_loss: 18.8195 - landmarks_output_loss: 57364.5951 - mask_output_acc: 0.0039 - landmarks_output_acc: 0.29 - ETA: 1s - loss: 57270.1445 - mask_output_loss: 18.8690 - landmarks_output_loss: 57251.2764 - mask_output_acc: 0.0037 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 59010.2250 - mask_output_loss: 18.8703 - landmarks_output_loss: 58991.3555 - mask_output_acc: 0.0043 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 59588.7624 - mask_output_loss: 18.8129 - landmarks_output_loss: 59569.9499 - mask_output_acc: 0.0076 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 58884.0921 - mask_output_loss: 18.8618 - landmarks_output_loss: 58865.2305 - mask_output_acc: 0.0071 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 58091.5532 - mask_output_loss: 18.8281 - landmarks_output_loss: 58072.7251 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 57731.3438 - mask_output_loss: 18.8849 - landmarks_output_loss: 57712.4588 - mask_output_acc: 0.0093 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 57840.4035 - mask_output_loss: 18.8852 - landmarks_output_loss: 57821.5184 - mask_output_acc: 0.0087 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 58736.9492 - mask_output_loss: 18.8067 - landmarks_output_loss: 58718.1424 - mask_output_acc: 0.0097 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 58619.8070 - mask_output_loss: 18.7841 - landmarks_output_loss: 58601.0228 - mask_output_acc: 0.0090 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 58502.0535 - mask_output_loss: 18.7539 - landmarks_output_loss: 58483.2996 - mask_output_acc: 0.0096 - landmarks_output_acc: 0.21 - ETA: 0s - loss: 58068.4079 - mask_output_loss: 18.7543 - landmarks_output_loss: 58049.6537 - mask_output_acc: 0.0097 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 57937.7242 - mask_output_loss: 18.7713 - landmarks_output_loss: 57918.9529 - mask_output_acc: 0.0093 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 57450.0398 - mask_output_loss: 18.7705 - landmarks_output_loss: 57431.2693 - mask_output_acc: 0.0090 - landmarks_output_acc: 0.21 - 3s 5ms/step - loss: 57468.0867 - mask_output_loss: 18.4820 - landmarks_output_loss: 57449.6046 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2167 - val_loss: 65282.7881 - val_mask_output_loss: 20.6989 - val_landmarks_output_loss: 65262.0895 - val_mask_output_acc: 0.0048 - val_landmarks_output_acc: 0.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 58781.0312 - mask_output_loss: 18.4754 - landmarks_output_loss: 58762.5547 - mask_output_acc: 0.0020 - landmarks_output_acc: 0.15 - ETA: 2s - loss: 59155.7598 - mask_output_loss: 17.8064 - landmarks_output_loss: 59137.9531 - mask_output_acc: 0.0172 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 59057.3320 - mask_output_loss: 18.0331 - landmarks_output_loss: 59039.2982 - mask_output_acc: 0.0144 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 57477.6758 - mask_output_loss: 18.1753 - landmarks_output_loss: 57459.5000 - mask_output_acc: 0.0119 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 56244.6320 - mask_output_loss: 18.1541 - landmarks_output_loss: 56226.4773 - mask_output_acc: 0.0132 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 55088.1836 - mask_output_loss: 18.3035 - landmarks_output_loss: 55069.8796 - mask_output_acc: 0.0139 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 56088.1289 - mask_output_loss: 18.2624 - landmarks_output_loss: 56069.8661 - mask_output_acc: 0.0124 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 56279.1890 - mask_output_loss: 18.2543 - landmarks_output_loss: 56260.9346 - mask_output_acc: 0.0117 - landmarks_output_acc: 0.22 - ETA: 1s - loss: 56576.4926 - mask_output_loss: 18.3189 - landmarks_output_loss: 56558.1736 - mask_output_acc: 0.0112 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 55973.6449 - mask_output_loss: 18.2918 - landmarks_output_loss: 55955.3531 - mask_output_acc: 0.0106 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 56359.7788 - mask_output_loss: 18.3051 - landmarks_output_loss: 56341.4737 - mask_output_acc: 0.0098 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 56593.0345 - mask_output_loss: 18.3196 - landmarks_output_loss: 56574.7148 - mask_output_acc: 0.0093 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 56253.3092 - mask_output_loss: 18.3288 - landmarks_output_loss: 56234.9802 - mask_output_acc: 0.0093 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 56643.1440 - mask_output_loss: 18.3649 - landmarks_output_loss: 56624.7790 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 56537.3708 - mask_output_loss: 18.3708 - landmarks_output_loss: 56519.0000 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 56699.7188 - mask_output_loss: 18.3556 - landmarks_output_loss: 56681.3633 - mask_output_acc: 0.0090 - landmarks_output_acc: 0.23 - 3s 5ms/step - loss: 56955.8808 - mask_output_loss: 18.0693 - landmarks_output_loss: 56937.8116 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2376 - val_loss: 65421.5064 - val_mask_output_loss: 19.9509 - val_landmarks_output_loss: 65401.5571 - val_mask_output_acc: 0.0048 - val_landmarks_output_acc: 0.3409\n",
      "Epoch 5/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 57813.9336 - mask_output_loss: 18.4038 - landmarks_output_loss: 57795.5312 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.25 - ETA: 2s - loss: 55160.4688 - mask_output_loss: 18.1924 - landmarks_output_loss: 55142.2773 - mask_output_acc: 0.0073 - landmarks_output_acc: 0.29 - ETA: 2s - loss: 55468.0456 - mask_output_loss: 18.3758 - landmarks_output_loss: 55449.6706 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.22 - ETA: 1s - loss: 55530.4590 - mask_output_loss: 18.4823 - landmarks_output_loss: 55511.9775 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 54526.5789 - mask_output_loss: 18.4948 - landmarks_output_loss: 54508.0852 - mask_output_acc: 0.0073 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 54821.2650 - mask_output_loss: 18.2775 - landmarks_output_loss: 54802.9883 - mask_output_acc: 0.0083 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 55502.0686 - mask_output_loss: 18.1844 - landmarks_output_loss: 55483.8850 - mask_output_acc: 0.0086 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 54605.5229 - mask_output_loss: 18.2726 - landmarks_output_loss: 54587.2510 - mask_output_acc: 0.0078 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 54577.6454 - mask_output_loss: 18.3110 - landmarks_output_loss: 54559.3351 - mask_output_acc: 0.0073 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 54952.7117 - mask_output_loss: 18.3145 - landmarks_output_loss: 54934.3977 - mask_output_acc: 0.0070 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 55320.9624 - mask_output_loss: 18.3554 - landmarks_output_loss: 55302.6072 - mask_output_acc: 0.0066 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 55768.5625 - mask_output_loss: 18.3765 - landmarks_output_loss: 55750.1862 - mask_output_acc: 0.0064 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 56177.8353 - mask_output_loss: 18.3271 - landmarks_output_loss: 56159.5084 - mask_output_acc: 0.0068 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 56229.6512 - mask_output_loss: 18.3116 - landmarks_output_loss: 56211.3398 - mask_output_acc: 0.0079 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 55966.0966 - mask_output_loss: 18.2745 - landmarks_output_loss: 55947.8224 - mask_output_acc: 0.0080 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 56305.5637 - mask_output_loss: 18.2656 - landmarks_output_loss: 56287.2983 - mask_output_acc: 0.0076 - landmarks_output_acc: 0.23 - 3s 5ms/step - loss: 56375.2184 - mask_output_loss: 17.9858 - landmarks_output_loss: 56357.2328 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2357 - val_loss: 66310.9643 - val_mask_output_loss: 23.0195 - val_landmarks_output_loss: 66287.9451 - val_mask_output_acc: 0.0048 - val_landmarks_output_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 52592.2617 - mask_output_loss: 18.8935 - landmarks_output_loss: 52573.3672 - mask_output_acc: 0.0052 - landmarks_output_acc: 0.21 - ETA: 2s - loss: 58231.7129 - mask_output_loss: 18.2668 - landmarks_output_loss: 58213.4453 - mask_output_acc: 0.0052 - landmarks_output_acc: 0.28 - ETA: 1s - loss: 60753.3138 - mask_output_loss: 18.1821 - landmarks_output_loss: 60735.1302 - mask_output_acc: 0.0044 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 58374.2217 - mask_output_loss: 18.0063 - landmarks_output_loss: 58356.2139 - mask_output_acc: 0.0074 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 57710.1711 - mask_output_loss: 18.1262 - landmarks_output_loss: 57692.0437 - mask_output_acc: 0.0062 - landmarks_output_acc: 0.22 - ETA: 1s - loss: 57971.1257 - mask_output_loss: 18.1276 - landmarks_output_loss: 57952.9974 - mask_output_acc: 0.0055 - landmarks_output_acc: 0.22 - ETA: 1s - loss: 57397.9325 - mask_output_loss: 18.1237 - landmarks_output_loss: 57379.8080 - mask_output_acc: 0.0069 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 56870.4370 - mask_output_loss: 18.0702 - landmarks_output_loss: 56852.3662 - mask_output_acc: 0.0072 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 56593.5078 - mask_output_loss: 18.0777 - landmarks_output_loss: 56575.4297 - mask_output_acc: 0.0070 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 56307.7234 - mask_output_loss: 18.1462 - landmarks_output_loss: 56289.5770 - mask_output_acc: 0.0071 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 56531.0543 - mask_output_loss: 18.1614 - landmarks_output_loss: 56512.8928 - mask_output_acc: 0.0068 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 56161.7044 - mask_output_loss: 18.1378 - landmarks_output_loss: 56143.5664 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 56031.2999 - mask_output_loss: 18.1314 - landmarks_output_loss: 56013.1683 - mask_output_acc: 0.0081 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 56006.1490 - mask_output_loss: 18.1262 - landmarks_output_loss: 55988.0226 - mask_output_acc: 0.0083 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 55837.5349 - mask_output_loss: 18.1905 - landmarks_output_loss: 55819.3443 - mask_output_acc: 0.0081 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 55843.5098 - mask_output_loss: 18.1995 - landmarks_output_loss: 55825.3101 - mask_output_acc: 0.0079 - landmarks_output_acc: 0.22 - 3s 5ms/step - loss: 55724.9127 - mask_output_loss: 17.9175 - landmarks_output_loss: 55706.9950 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2319 - val_loss: 65432.5855 - val_mask_output_loss: 27.9314 - val_landmarks_output_loss: 65404.6544 - val_mask_output_acc: 0.0048 - val_landmarks_output_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 57475.9297 - mask_output_loss: 17.5856 - landmarks_output_loss: 57458.3438 - mask_output_acc: 0.0047 - landmarks_output_acc: 0.28 - ETA: 2s - loss: 56579.4180 - mask_output_loss: 17.6919 - landmarks_output_loss: 56561.7266 - mask_output_acc: 0.0052 - landmarks_output_acc: 0.28 - ETA: 2s - loss: 54166.2917 - mask_output_loss: 17.6913 - landmarks_output_loss: 54148.6003 - mask_output_acc: 0.0039 - landmarks_output_acc: 0.22 - ETA: 1s - loss: 54944.3525 - mask_output_loss: 17.8773 - landmarks_output_loss: 54926.4756 - mask_output_acc: 0.0033 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 54999.9898 - mask_output_loss: 17.8796 - landmarks_output_loss: 54982.1102 - mask_output_acc: 0.0069 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 54891.1185 - mask_output_loss: 17.9306 - landmarks_output_loss: 54873.1882 - mask_output_acc: 0.0078 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 55269.1691 - mask_output_loss: 18.0061 - landmarks_output_loss: 55251.1629 - mask_output_acc: 0.0070 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 55453.5552 - mask_output_loss: 18.0260 - landmarks_output_loss: 55435.5293 - mask_output_acc: 0.0076 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 55523.5768 - mask_output_loss: 18.0854 - landmarks_output_loss: 55505.4918 - mask_output_acc: 0.0093 - landmarks_output_acc: 0.21 - ETA: 0s - loss: 55839.7133 - mask_output_loss: 18.0732 - landmarks_output_loss: 55821.6402 - mask_output_acc: 0.0093 - landmarks_output_acc: 0.20 - ETA: 0s - loss: 55507.8810 - mask_output_loss: 18.0669 - landmarks_output_loss: 55489.8143 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.20 - ETA: 0s - loss: 55399.1198 - mask_output_loss: 18.0441 - landmarks_output_loss: 55381.0758 - mask_output_acc: 0.0085 - landmarks_output_acc: 0.20 - ETA: 0s - loss: 55199.1544 - mask_output_loss: 18.0520 - landmarks_output_loss: 55181.1025 - mask_output_acc: 0.0096 - landmarks_output_acc: 0.21 - ETA: 0s - loss: 55447.1576 - mask_output_loss: 18.0660 - landmarks_output_loss: 55429.0918 - mask_output_acc: 0.0094 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 55446.7719 - mask_output_loss: 18.1047 - landmarks_output_loss: 55428.6672 - mask_output_acc: 0.0092 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 55141.2498 - mask_output_loss: 18.1556 - landmarks_output_loss: 55123.0942 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.23 - 3s 5ms/step - loss: 54973.3903 - mask_output_loss: 17.8857 - landmarks_output_loss: 54955.5048 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2357 - val_loss: 67839.6361 - val_mask_output_loss: 27.0804 - val_landmarks_output_loss: 67812.5554 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.0606\n",
      "Epoch 8/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 60993.0430 - mask_output_loss: 18.8040 - landmarks_output_loss: 60974.2383 - mask_output_acc: 0.0019 - landmarks_output_acc: 0.25 - ETA: 2s - loss: 57627.7695 - mask_output_loss: 18.4182 - landmarks_output_loss: 57609.3516 - mask_output_acc: 0.0059 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 57422.0026 - mask_output_loss: 18.4917 - landmarks_output_loss: 57403.5104 - mask_output_acc: 0.0044 - landmarks_output_acc: 0.19 - ETA: 1s - loss: 57405.9727 - mask_output_loss: 18.4082 - landmarks_output_loss: 57387.5645 - mask_output_acc: 0.0038 - landmarks_output_acc: 0.20 - ETA: 1s - loss: 55406.7969 - mask_output_loss: 18.1732 - landmarks_output_loss: 55388.6234 - mask_output_acc: 0.0062 - landmarks_output_acc: 0.22 - ETA: 1s - loss: 55433.1641 - mask_output_loss: 18.2147 - landmarks_output_loss: 55414.9492 - mask_output_acc: 0.0065 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 54589.4542 - mask_output_loss: 18.1805 - landmarks_output_loss: 54571.2734 - mask_output_acc: 0.0078 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 54617.3682 - mask_output_loss: 18.1756 - landmarks_output_loss: 54599.1924 - mask_output_acc: 0.0075 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 54400.1107 - mask_output_loss: 18.1278 - landmarks_output_loss: 54381.9826 - mask_output_acc: 0.0075 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 54216.6598 - mask_output_loss: 18.1023 - landmarks_output_loss: 54198.5570 - mask_output_acc: 0.0083 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 54456.0249 - mask_output_loss: 18.0616 - landmarks_output_loss: 54437.9631 - mask_output_acc: 0.0082 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 54181.4375 - mask_output_loss: 18.0678 - landmarks_output_loss: 54163.3695 - mask_output_acc: 0.0081 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 53613.7572 - mask_output_loss: 18.0404 - landmarks_output_loss: 53595.7166 - mask_output_acc: 0.0078 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 53635.4930 - mask_output_loss: 18.0396 - landmarks_output_loss: 53617.4534 - mask_output_acc: 0.0086 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 53751.8185 - mask_output_loss: 18.0492 - landmarks_output_loss: 53733.7693 - mask_output_acc: 0.0094 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 53961.8923 - mask_output_loss: 18.0927 - landmarks_output_loss: 53943.7996 - mask_output_acc: 0.0090 - landmarks_output_acc: 0.25 - 3s 5ms/step - loss: 54127.2011 - mask_output_loss: 17.8198 - landmarks_output_loss: 54109.3812 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2529 - val_loss: 64278.6009 - val_mask_output_loss: 35.4851 - val_landmarks_output_loss: 64243.1154 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.0152\n",
      "Epoch 9/20\n",
      "526/526 [==============================] - ETA: 1s - loss: 54066.2773 - mask_output_loss: 17.4572 - landmarks_output_loss: 54048.8203 - mask_output_acc: 0.0068 - landmarks_output_acc: 0.25 - ETA: 2s - loss: 54856.0156 - mask_output_loss: 17.3651 - landmarks_output_loss: 54838.6504 - mask_output_acc: 0.0152 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 53367.2643 - mask_output_loss: 17.6681 - landmarks_output_loss: 53349.5964 - mask_output_acc: 0.0139 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 53435.3770 - mask_output_loss: 17.7537 - landmarks_output_loss: 53417.6230 - mask_output_acc: 0.0149 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 54034.3656 - mask_output_loss: 18.0315 - landmarks_output_loss: 54016.3344 - mask_output_acc: 0.0127 - landmarks_output_acc: 0.22 - ETA: 1s - loss: 52848.4453 - mask_output_loss: 18.0548 - landmarks_output_loss: 52830.3906 - mask_output_acc: 0.0156 - landmarks_output_acc: 0.20 - ETA: 1s - loss: 53019.1456 - mask_output_loss: 18.0356 - landmarks_output_loss: 53001.1099 - mask_output_acc: 0.0145 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 53008.0508 - mask_output_loss: 18.0835 - landmarks_output_loss: 52989.9673 - mask_output_acc: 0.0130 - landmarks_output_acc: 0.22 - ETA: 1s - loss: 52625.5508 - mask_output_loss: 18.1376 - landmarks_output_loss: 52607.4132 - mask_output_acc: 0.0126 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 53345.1266 - mask_output_loss: 18.1225 - landmarks_output_loss: 53327.0039 - mask_output_acc: 0.0115 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 53394.9975 - mask_output_loss: 18.1914 - landmarks_output_loss: 53376.8061 - mask_output_acc: 0.0112 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 53027.9635 - mask_output_loss: 18.1906 - landmarks_output_loss: 53009.7728 - mask_output_acc: 0.0104 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 52812.8711 - mask_output_loss: 18.1805 - landmarks_output_loss: 52794.6905 - mask_output_acc: 0.0100 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 52926.0285 - mask_output_loss: 18.1628 - landmarks_output_loss: 52907.8655 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 52980.9214 - mask_output_loss: 18.0962 - landmarks_output_loss: 52962.8250 - mask_output_acc: 0.0093 - landmarks_output_acc: 0.22 - ETA: 0s - loss: 53093.2600 - mask_output_loss: 18.0724 - landmarks_output_loss: 53075.1875 - mask_output_acc: 0.0090 - landmarks_output_acc: 0.22 - 3s 5ms/step - loss: 53195.9934 - mask_output_loss: 17.8129 - landmarks_output_loss: 53178.1804 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2319 - val_loss: 56628.2427 - val_mask_output_loss: 36.2249 - val_landmarks_output_loss: 56592.0165 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 56179.9102 - mask_output_loss: 16.9946 - landmarks_output_loss: 56162.9141 - mask_output_acc: 0.0072 - landmarks_output_acc: 0.21 - ETA: 2s - loss: 50632.7695 - mask_output_loss: 17.5392 - landmarks_output_loss: 50615.2305 - mask_output_acc: 0.0119 - landmarks_output_acc: 0.17 - ETA: 1s - loss: 50947.1302 - mask_output_loss: 17.3532 - landmarks_output_loss: 50929.7773 - mask_output_acc: 0.0154 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 50541.3242 - mask_output_loss: 17.5260 - landmarks_output_loss: 50523.7988 - mask_output_acc: 0.0126 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 51342.3523 - mask_output_loss: 17.5886 - landmarks_output_loss: 51324.7641 - mask_output_acc: 0.0120 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 51909.2435 - mask_output_loss: 17.6812 - landmarks_output_loss: 51891.5625 - mask_output_acc: 0.0103 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 52412.6735 - mask_output_loss: 17.6710 - landmarks_output_loss: 52395.0028 - mask_output_acc: 0.0093 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 52350.9897 - mask_output_loss: 17.6830 - landmarks_output_loss: 52333.3071 - mask_output_acc: 0.0092 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 52798.4787 - mask_output_loss: 17.7401 - landmarks_output_loss: 52780.7391 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 52389.5383 - mask_output_loss: 17.7483 - landmarks_output_loss: 52371.7906 - mask_output_acc: 0.0105 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 52692.9563 - mask_output_loss: 17.7574 - landmarks_output_loss: 52675.1996 - mask_output_acc: 0.0109 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 52049.1312 - mask_output_loss: 17.8562 - landmarks_output_loss: 52031.2757 - mask_output_acc: 0.0106 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 52184.9907 - mask_output_loss: 17.9010 - landmarks_output_loss: 52167.0904 - mask_output_acc: 0.0101 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 52033.9618 - mask_output_loss: 18.0010 - landmarks_output_loss: 52015.9615 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 51898.8372 - mask_output_loss: 18.0086 - landmarks_output_loss: 51880.8292 - mask_output_acc: 0.0094 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 52091.3130 - mask_output_loss: 18.0197 - landmarks_output_loss: 52073.2939 - mask_output_acc: 0.0090 - landmarks_output_acc: 0.25 - 3s 5ms/step - loss: 52132.8673 - mask_output_loss: 17.7555 - landmarks_output_loss: 52115.1124 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2529 - val_loss: 59623.6080 - val_mask_output_loss: 30.4624 - val_landmarks_output_loss: 59593.1457 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.4091\n",
      "Epoch 11/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 52285.5352 - mask_output_loss: 17.6406 - landmarks_output_loss: 52267.8945 - mask_output_acc: 0.0029 - landmarks_output_acc: 0.21 - ETA: 2s - loss: 52437.8262 - mask_output_loss: 17.9123 - landmarks_output_loss: 52419.9141 - mask_output_acc: 0.0050 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 53241.4727 - mask_output_loss: 18.0083 - landmarks_output_loss: 53223.4648 - mask_output_acc: 0.0045 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 51802.8359 - mask_output_loss: 18.0404 - landmarks_output_loss: 51784.7959 - mask_output_acc: 0.0054 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 51471.4258 - mask_output_loss: 18.1369 - landmarks_output_loss: 51453.2891 - mask_output_acc: 0.0055 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 51072.3118 - mask_output_loss: 18.1833 - landmarks_output_loss: 51054.1289 - mask_output_acc: 0.0053 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 51542.8047 - mask_output_loss: 18.2506 - landmarks_output_loss: 51524.5541 - mask_output_acc: 0.0050 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 51862.8682 - mask_output_loss: 18.1762 - landmarks_output_loss: 51844.6919 - mask_output_acc: 0.0063 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 51756.7795 - mask_output_loss: 18.1634 - landmarks_output_loss: 51738.6159 - mask_output_acc: 0.0064 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 51872.8371 - mask_output_loss: 18.0560 - landmarks_output_loss: 51854.7809 - mask_output_acc: 0.0101 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 51784.2358 - mask_output_loss: 17.9895 - landmarks_output_loss: 51766.2461 - mask_output_acc: 0.0102 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 51702.7393 - mask_output_loss: 18.0237 - landmarks_output_loss: 51684.7152 - mask_output_acc: 0.0098 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 51559.6995 - mask_output_loss: 18.0144 - landmarks_output_loss: 51541.6848 - mask_output_acc: 0.0094 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 51188.0432 - mask_output_loss: 18.0494 - landmarks_output_loss: 51169.9936 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 51275.8586 - mask_output_loss: 18.0886 - landmarks_output_loss: 51257.7698 - mask_output_acc: 0.0086 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 51131.7095 - mask_output_loss: 18.0999 - landmarks_output_loss: 51113.6094 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.25 - 3s 5ms/step - loss: 50991.7038 - mask_output_loss: 17.8250 - landmarks_output_loss: 50973.8787 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2529 - val_loss: 70953.3414 - val_mask_output_loss: 31.6088 - val_landmarks_output_loss: 70921.7320 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.3106\n",
      "Epoch 12/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 51988.9375 - mask_output_loss: 18.8234 - landmarks_output_loss: 51970.1133 - mask_output_acc: 0.0155 - landmarks_output_acc: 0.28 - ETA: 2s - loss: 50046.1465 - mask_output_loss: 18.3663 - landmarks_output_loss: 50027.7793 - mask_output_acc: 0.0129 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 50451.4701 - mask_output_loss: 18.2835 - landmarks_output_loss: 50433.1862 - mask_output_acc: 0.0105 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 50698.7070 - mask_output_loss: 18.2364 - landmarks_output_loss: 50680.4707 - mask_output_acc: 0.0106 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 49133.1813 - mask_output_loss: 18.3019 - landmarks_output_loss: 49114.8797 - mask_output_acc: 0.0087 - landmarks_output_acc: 0.20 - ETA: 1s - loss: 48460.9857 - mask_output_loss: 18.3191 - landmarks_output_loss: 48442.6667 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 48616.5982 - mask_output_loss: 18.2536 - landmarks_output_loss: 48598.3449 - mask_output_acc: 0.0080 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 48900.7935 - mask_output_loss: 18.3235 - landmarks_output_loss: 48882.4702 - mask_output_acc: 0.0076 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 49627.8216 - mask_output_loss: 18.2148 - landmarks_output_loss: 49609.6072 - mask_output_acc: 0.0073 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 49292.0508 - mask_output_loss: 18.1570 - landmarks_output_loss: 49273.8941 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.23 - ETA: 0s - loss: 49565.1278 - mask_output_loss: 18.1378 - landmarks_output_loss: 49546.9904 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.24 - ETA: 0s - loss: 49780.3001 - mask_output_loss: 18.0996 - landmarks_output_loss: 49762.2008 - mask_output_acc: 0.0100 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 49693.3603 - mask_output_loss: 18.0877 - landmarks_output_loss: 49675.2728 - mask_output_acc: 0.0100 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 49730.0117 - mask_output_loss: 18.1290 - landmarks_output_loss: 49711.8828 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 49666.0268 - mask_output_loss: 18.1003 - landmarks_output_loss: 49647.9266 - mask_output_acc: 0.0093 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 49490.0303 - mask_output_loss: 18.0739 - landmarks_output_loss: 49471.9565 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.26 - 3s 5ms/step - loss: 49734.9625 - mask_output_loss: 17.8031 - landmarks_output_loss: 49717.1595 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2662 - val_loss: 75926.5021 - val_mask_output_loss: 39.2617 - val_landmarks_output_loss: 75887.2412 - val_mask_output_acc: 0.0046 - val_landmarks_output_acc: 0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 54882.6953 - mask_output_loss: 17.6082 - landmarks_output_loss: 54865.0859 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.28 - ETA: 2s - loss: 48450.9785 - mask_output_loss: 17.9809 - landmarks_output_loss: 48432.9961 - mask_output_acc: 0.0081 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 50519.8203 - mask_output_loss: 17.9990 - landmarks_output_loss: 50501.8203 - mask_output_acc: 0.0081 - landmarks_output_acc: 0.27 - ETA: 1s - loss: 50151.5928 - mask_output_loss: 17.6606 - landmarks_output_loss: 50133.9316 - mask_output_acc: 0.0126 - landmarks_output_acc: 0.27 - ETA: 1s - loss: 49720.6813 - mask_output_loss: 17.8632 - landmarks_output_loss: 49702.8180 - mask_output_acc: 0.0117 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 50352.3268 - mask_output_loss: 17.8833 - landmarks_output_loss: 50334.4434 - mask_output_acc: 0.0125 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 50033.6166 - mask_output_loss: 17.8681 - landmarks_output_loss: 50015.7483 - mask_output_acc: 0.0113 - landmarks_output_acc: 0.27 - ETA: 1s - loss: 49790.6211 - mask_output_loss: 17.9297 - landmarks_output_loss: 49772.6914 - mask_output_acc: 0.0115 - landmarks_output_acc: 0.27 - ETA: 1s - loss: 49060.4145 - mask_output_loss: 18.0090 - landmarks_output_loss: 49042.4054 - mask_output_acc: 0.0106 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 48851.8406 - mask_output_loss: 17.9755 - landmarks_output_loss: 48833.8648 - mask_output_acc: 0.0101 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 48567.0618 - mask_output_loss: 17.9754 - landmarks_output_loss: 48549.0859 - mask_output_acc: 0.0096 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 48631.3613 - mask_output_loss: 17.9769 - landmarks_output_loss: 48613.3841 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 48578.5775 - mask_output_loss: 18.0129 - landmarks_output_loss: 48560.5643 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 48540.8703 - mask_output_loss: 18.0523 - landmarks_output_loss: 48522.8178 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 48548.4786 - mask_output_loss: 18.0537 - landmarks_output_loss: 48530.4247 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 48434.3142 - mask_output_loss: 18.0676 - landmarks_output_loss: 48416.2463 - mask_output_acc: 0.0090 - landmarks_output_acc: 0.25 - 3s 5ms/step - loss: 48457.3638 - mask_output_loss: 17.7903 - landmarks_output_loss: 48439.5731 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2586 - val_loss: 72272.3265 - val_mask_output_loss: 32.0330 - val_landmarks_output_loss: 72240.2926 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 49595.6602 - mask_output_loss: 18.8020 - landmarks_output_loss: 49576.8594 - mask_output_acc: 0.0020 - landmarks_output_acc: 0.18 - ETA: 2s - loss: 47898.2617 - mask_output_loss: 18.5865 - landmarks_output_loss: 47879.6758 - mask_output_acc: 0.0050 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 47580.6966 - mask_output_loss: 18.3060 - landmarks_output_loss: 47562.3906 - mask_output_acc: 0.0052 - landmarks_output_acc: 0.22 - ETA: 1s - loss: 47385.0322 - mask_output_loss: 18.1048 - landmarks_output_loss: 47366.9277 - mask_output_acc: 0.0044 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 47937.0820 - mask_output_loss: 18.0758 - landmarks_output_loss: 47919.0062 - mask_output_acc: 0.0074 - landmarks_output_acc: 0.28 - ETA: 1s - loss: 47599.2982 - mask_output_loss: 18.1989 - landmarks_output_loss: 47581.0990 - mask_output_acc: 0.0080 - landmarks_output_acc: 0.27 - ETA: 1s - loss: 47448.1663 - mask_output_loss: 18.2482 - landmarks_output_loss: 47429.9180 - mask_output_acc: 0.0072 - landmarks_output_acc: 0.28 - ETA: 1s - loss: 47828.9829 - mask_output_loss: 18.1649 - landmarks_output_loss: 47810.8179 - mask_output_acc: 0.0070 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 47693.3034 - mask_output_loss: 18.1907 - landmarks_output_loss: 47675.1124 - mask_output_acc: 0.0066 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 48134.0473 - mask_output_loss: 18.1796 - landmarks_output_loss: 48115.8676 - mask_output_acc: 0.0072 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 47997.9851 - mask_output_loss: 18.1949 - landmarks_output_loss: 47979.7901 - mask_output_acc: 0.0072 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 47732.4385 - mask_output_loss: 18.1796 - landmarks_output_loss: 47714.2588 - mask_output_acc: 0.0070 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 47524.1277 - mask_output_loss: 18.1737 - landmarks_output_loss: 47505.9540 - mask_output_acc: 0.0066 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 47529.4640 - mask_output_loss: 18.1282 - landmarks_output_loss: 47511.3359 - mask_output_acc: 0.0071 - landmarks_output_acc: 0.28 - ETA: 0s - loss: 46936.8930 - mask_output_loss: 18.0713 - landmarks_output_loss: 46918.8219 - mask_output_acc: 0.0081 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 47199.9883 - mask_output_loss: 18.0652 - landmarks_output_loss: 47181.9233 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.28 - 3s 5ms/step - loss: 47147.1223 - mask_output_loss: 17.7965 - landmarks_output_loss: 47129.3261 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2776 - val_loss: 74954.0708 - val_mask_output_loss: 49.9743 - val_landmarks_output_loss: 74904.0971 - val_mask_output_acc: 0.0046 - val_landmarks_output_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 48128.3477 - mask_output_loss: 18.6065 - landmarks_output_loss: 48109.7422 - mask_output_acc: 0.0028 - landmarks_output_acc: 0.21 - ETA: 2s - loss: 46092.1699 - mask_output_loss: 18.5835 - landmarks_output_loss: 46073.5879 - mask_output_acc: 0.0048 - landmarks_output_acc: 0.25 - ETA: 2s - loss: 46916.5052 - mask_output_loss: 18.5702 - landmarks_output_loss: 46897.9362 - mask_output_acc: 0.0046 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 46985.6387 - mask_output_loss: 18.4409 - landmarks_output_loss: 46967.1982 - mask_output_acc: 0.0054 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 45916.5578 - mask_output_loss: 18.3045 - landmarks_output_loss: 45898.2539 - mask_output_acc: 0.0053 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 46334.5254 - mask_output_loss: 18.2505 - landmarks_output_loss: 46316.2754 - mask_output_acc: 0.0050 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 46315.0675 - mask_output_loss: 18.1579 - landmarks_output_loss: 46296.9102 - mask_output_acc: 0.0048 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 45996.3589 - mask_output_loss: 18.1465 - landmarks_output_loss: 45978.2129 - mask_output_acc: 0.0063 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 45472.8746 - mask_output_loss: 18.1256 - landmarks_output_loss: 45454.7496 - mask_output_acc: 0.0063 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 45764.6695 - mask_output_loss: 18.1758 - landmarks_output_loss: 45746.4941 - mask_output_acc: 0.0063 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 45312.0515 - mask_output_loss: 18.1889 - landmarks_output_loss: 45293.8629 - mask_output_acc: 0.0062 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 45651.0739 - mask_output_loss: 18.1401 - landmarks_output_loss: 45632.9339 - mask_output_acc: 0.0062 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 46237.4546 - mask_output_loss: 18.1042 - landmarks_output_loss: 46219.3507 - mask_output_acc: 0.0062 - landmarks_output_acc: 0.28 - ETA: 0s - loss: 46089.0181 - mask_output_loss: 18.0453 - landmarks_output_loss: 46070.9729 - mask_output_acc: 0.0078 - landmarks_output_acc: 0.28 - ETA: 0s - loss: 46075.6029 - mask_output_loss: 18.0676 - landmarks_output_loss: 46057.5354 - mask_output_acc: 0.0085 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 45774.0894 - mask_output_loss: 18.0284 - landmarks_output_loss: 45756.0610 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.27 - 3s 5ms/step - loss: 45690.2434 - mask_output_loss: 17.7657 - landmarks_output_loss: 45672.4778 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2795 - val_loss: 104189.0760 - val_mask_output_loss: 44.6263 - val_landmarks_output_loss: 104144.4512 - val_mask_output_acc: 0.0045 - val_landmarks_output_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 44493.2617 - mask_output_loss: 18.6655 - landmarks_output_loss: 44474.5977 - mask_output_acc: 0.0042 - landmarks_output_acc: 0.31 - ETA: 2s - loss: 42386.7656 - mask_output_loss: 18.4625 - landmarks_output_loss: 42368.3047 - mask_output_acc: 0.0030 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 44016.1367 - mask_output_loss: 18.3155 - landmarks_output_loss: 43997.8229 - mask_output_acc: 0.0049 - landmarks_output_acc: 0.27 - ETA: 1s - loss: 44767.8389 - mask_output_loss: 18.1902 - landmarks_output_loss: 44749.6504 - mask_output_acc: 0.0045 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 44885.5844 - mask_output_loss: 18.1309 - landmarks_output_loss: 44867.4547 - mask_output_acc: 0.0063 - landmarks_output_acc: 0.28 - ETA: 1s - loss: 45022.9316 - mask_output_loss: 18.0303 - landmarks_output_loss: 45004.9023 - mask_output_acc: 0.0061 - landmarks_output_acc: 0.29 - ETA: 1s - loss: 45288.7333 - mask_output_loss: 18.0495 - landmarks_output_loss: 45270.6847 - mask_output_acc: 0.0081 - landmarks_output_acc: 0.30 - ETA: 1s - loss: 45322.9731 - mask_output_loss: 18.1112 - landmarks_output_loss: 45304.8628 - mask_output_acc: 0.0079 - landmarks_output_acc: 0.30 - ETA: 1s - loss: 44689.3320 - mask_output_loss: 18.1371 - landmarks_output_loss: 44671.1957 - mask_output_acc: 0.0073 - landmarks_output_acc: 0.29 - ETA: 0s - loss: 44763.4105 - mask_output_loss: 18.1877 - landmarks_output_loss: 44745.2234 - mask_output_acc: 0.0068 - landmarks_output_acc: 0.28 - ETA: 0s - loss: 44649.5799 - mask_output_loss: 18.0908 - landmarks_output_loss: 44631.4897 - mask_output_acc: 0.0074 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 44570.5166 - mask_output_loss: 18.0582 - landmarks_output_loss: 44552.4590 - mask_output_acc: 0.0082 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 44482.8104 - mask_output_loss: 18.0567 - landmarks_output_loss: 44464.7542 - mask_output_acc: 0.0078 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 44670.7162 - mask_output_loss: 18.0433 - landmarks_output_loss: 44652.6735 - mask_output_acc: 0.0086 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 44377.8846 - mask_output_loss: 18.0698 - landmarks_output_loss: 44359.8154 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 44379.9661 - mask_output_loss: 18.0767 - landmarks_output_loss: 44361.8899 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.27 - 3s 5ms/step - loss: 44399.3636 - mask_output_loss: 17.7920 - landmarks_output_loss: 44381.5721 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2757 - val_loss: 59507.0647 - val_mask_output_loss: 37.8871 - val_landmarks_output_loss: 59469.1781 - val_mask_output_acc: 0.0046 - val_landmarks_output_acc: 0.3409\n",
      "Epoch 17/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 41263.9688 - mask_output_loss: 18.2434 - landmarks_output_loss: 41245.7266 - mask_output_acc: 0.0162 - landmarks_output_acc: 0.34 - ETA: 2s - loss: 45109.0762 - mask_output_loss: 18.3572 - landmarks_output_loss: 45090.7188 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.35 - ETA: 1s - loss: 43812.9232 - mask_output_loss: 18.4044 - landmarks_output_loss: 43794.5182 - mask_output_acc: 0.0112 - landmarks_output_acc: 0.31 - ETA: 1s - loss: 43867.2285 - mask_output_loss: 18.1319 - landmarks_output_loss: 43849.0967 - mask_output_acc: 0.0106 - landmarks_output_acc: 0.29 - ETA: 1s - loss: 43944.1398 - mask_output_loss: 18.1015 - landmarks_output_loss: 43926.0383 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.28 - ETA: 1s - loss: 43867.1699 - mask_output_loss: 18.1918 - landmarks_output_loss: 43848.9779 - mask_output_acc: 0.0101 - landmarks_output_acc: 0.28 - ETA: 1s - loss: 43422.0804 - mask_output_loss: 18.2373 - landmarks_output_loss: 43403.8426 - mask_output_acc: 0.0097 - landmarks_output_acc: 0.29 - ETA: 1s - loss: 43296.3530 - mask_output_loss: 18.2219 - landmarks_output_loss: 43278.1309 - mask_output_acc: 0.0092 - landmarks_output_acc: 0.28 - ETA: 1s - loss: 42791.1272 - mask_output_loss: 18.1767 - landmarks_output_loss: 42772.9501 - mask_output_acc: 0.0105 - landmarks_output_acc: 0.28 - ETA: 0s - loss: 42838.7176 - mask_output_loss: 18.1616 - landmarks_output_loss: 42820.5555 - mask_output_acc: 0.0105 - landmarks_output_acc: 0.29 - ETA: 0s - loss: 43055.0533 - mask_output_loss: 18.1861 - landmarks_output_loss: 43036.8668 - mask_output_acc: 0.0097 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 42597.8148 - mask_output_loss: 18.1364 - landmarks_output_loss: 42579.6781 - mask_output_acc: 0.0094 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 42466.7188 - mask_output_loss: 18.1378 - landmarks_output_loss: 42448.5808 - mask_output_acc: 0.0092 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 42688.9127 - mask_output_loss: 18.0966 - landmarks_output_loss: 42670.8158 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 42592.8339 - mask_output_loss: 18.0780 - landmarks_output_loss: 42574.7557 - mask_output_acc: 0.0084 - landmarks_output_acc: 0.28 - ETA: 0s - loss: 42705.0002 - mask_output_loss: 18.1237 - landmarks_output_loss: 42686.8765 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.28 - 3s 5ms/step - loss: 42772.3501 - mask_output_loss: 17.8450 - landmarks_output_loss: 42754.5050 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2890 - val_loss: 72211.7306 - val_mask_output_loss: 36.3093 - val_landmarks_output_loss: 72175.4205 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.3409\n",
      "Epoch 18/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 39962.0547 - mask_output_loss: 17.1237 - landmarks_output_loss: 39944.9297 - mask_output_acc: 0.0323 - landmarks_output_acc: 0.31 - ETA: 2s - loss: 40957.3262 - mask_output_loss: 17.5448 - landmarks_output_loss: 40939.7812 - mask_output_acc: 0.0177 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 41302.8971 - mask_output_loss: 17.6113 - landmarks_output_loss: 41285.2865 - mask_output_acc: 0.0132 - landmarks_output_acc: 0.28 - ETA: 1s - loss: 41542.0635 - mask_output_loss: 17.8137 - landmarks_output_loss: 41524.2500 - mask_output_acc: 0.0107 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 40267.7992 - mask_output_loss: 17.9042 - landmarks_output_loss: 40249.8953 - mask_output_acc: 0.0107 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 39843.7201 - mask_output_loss: 17.8205 - landmarks_output_loss: 39825.8997 - mask_output_acc: 0.0097 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 40147.3555 - mask_output_loss: 17.8488 - landmarks_output_loss: 40129.5067 - mask_output_acc: 0.0087 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 41116.3721 - mask_output_loss: 17.8036 - landmarks_output_loss: 41098.5684 - mask_output_acc: 0.0098 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 40632.1372 - mask_output_loss: 17.7998 - landmarks_output_loss: 40614.3372 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 40522.3828 - mask_output_loss: 17.8334 - landmarks_output_loss: 40504.5492 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 40792.2955 - mask_output_loss: 17.8613 - landmarks_output_loss: 40774.4339 - mask_output_acc: 0.0086 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 41079.7373 - mask_output_loss: 17.9079 - landmarks_output_loss: 41061.8291 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 41326.4630 - mask_output_loss: 17.8971 - landmarks_output_loss: 41308.5658 - mask_output_acc: 0.0087 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 41363.0089 - mask_output_loss: 17.9182 - landmarks_output_loss: 41345.0907 - mask_output_acc: 0.0100 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 41382.9008 - mask_output_loss: 17.9378 - landmarks_output_loss: 41364.9628 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 41301.7886 - mask_output_loss: 17.9462 - landmarks_output_loss: 41283.8423 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.26 - 3s 5ms/step - loss: 41176.5401 - mask_output_loss: 17.6869 - landmarks_output_loss: 41158.8530 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2700 - val_loss: 95554.1579 - val_mask_output_loss: 30.6671 - val_landmarks_output_loss: 95523.4936 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.3409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 44270.5000 - mask_output_loss: 17.9829 - landmarks_output_loss: 44252.5156 - mask_output_acc: 0.0065 - landmarks_output_acc: 0.18 - ETA: 2s - loss: 43141.9199 - mask_output_loss: 18.0120 - landmarks_output_loss: 43123.9062 - mask_output_acc: 0.0065 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 41542.1185 - mask_output_loss: 18.0839 - landmarks_output_loss: 41524.0339 - mask_output_acc: 0.0121 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 42171.8633 - mask_output_loss: 17.9025 - landmarks_output_loss: 42153.9600 - mask_output_acc: 0.0111 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 40929.1445 - mask_output_loss: 18.0634 - landmarks_output_loss: 40911.0805 - mask_output_acc: 0.0105 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 40669.9727 - mask_output_loss: 18.0672 - landmarks_output_loss: 40651.9049 - mask_output_acc: 0.0104 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 40349.8209 - mask_output_loss: 18.0102 - landmarks_output_loss: 40331.8103 - mask_output_acc: 0.0094 - landmarks_output_acc: 0.27 - ETA: 1s - loss: 40054.3916 - mask_output_loss: 17.9330 - landmarks_output_loss: 40036.4580 - mask_output_acc: 0.0087 - landmarks_output_acc: 0.26 - ETA: 1s - loss: 39549.8073 - mask_output_loss: 17.9968 - landmarks_output_loss: 39531.8099 - mask_output_acc: 0.0086 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 39208.7129 - mask_output_loss: 18.0335 - landmarks_output_loss: 39190.6789 - mask_output_acc: 0.0079 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 39292.9158 - mask_output_loss: 18.0441 - landmarks_output_loss: 39274.8711 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 39629.6025 - mask_output_loss: 18.0534 - landmarks_output_loss: 39611.5485 - mask_output_acc: 0.0097 - landmarks_output_acc: 0.27 - ETA: 0s - loss: 39456.8639 - mask_output_loss: 18.0245 - landmarks_output_loss: 39438.8389 - mask_output_acc: 0.0095 - landmarks_output_acc: 0.28 - ETA: 0s - loss: 39362.4448 - mask_output_loss: 18.0437 - landmarks_output_loss: 39344.4007 - mask_output_acc: 0.0091 - landmarks_output_acc: 0.29 - ETA: 0s - loss: 39387.5604 - mask_output_loss: 18.0155 - landmarks_output_loss: 39369.5445 - mask_output_acc: 0.0086 - landmarks_output_acc: 0.28 - ETA: 0s - loss: 39475.2473 - mask_output_loss: 18.0011 - landmarks_output_loss: 39457.2458 - mask_output_acc: 0.0089 - landmarks_output_acc: 0.28 - 3s 5ms/step - loss: 39592.0321 - mask_output_loss: 17.7317 - landmarks_output_loss: 39574.3002 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2776 - val_loss: 49582.3590 - val_mask_output_loss: 35.7191 - val_landmarks_output_loss: 49546.6392 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.0076\n",
      "Epoch 20/20\n",
      "526/526 [==============================] - ETA: 2s - loss: 34872.0977 - mask_output_loss: 18.1386 - landmarks_output_loss: 34853.9609 - mask_output_acc: 0.0055 - landmarks_output_acc: 0.21 - ETA: 2s - loss: 36913.8809 - mask_output_loss: 18.0124 - landmarks_output_loss: 36895.8691 - mask_output_acc: 0.0049 - landmarks_output_acc: 0.23 - ETA: 1s - loss: 35541.0547 - mask_output_loss: 17.7714 - landmarks_output_loss: 35523.2839 - mask_output_acc: 0.0133 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 37234.1719 - mask_output_loss: 17.8660 - landmarks_output_loss: 37216.3066 - mask_output_acc: 0.0105 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 37263.9938 - mask_output_loss: 17.8178 - landmarks_output_loss: 37246.1766 - mask_output_acc: 0.0112 - landmarks_output_acc: 0.21 - ETA: 1s - loss: 38163.8151 - mask_output_loss: 17.8141 - landmarks_output_loss: 38146.0013 - mask_output_acc: 0.0097 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 37746.5463 - mask_output_loss: 17.8969 - landmarks_output_loss: 37728.6496 - mask_output_acc: 0.0085 - landmarks_output_acc: 0.24 - ETA: 1s - loss: 37412.2974 - mask_output_loss: 17.9362 - landmarks_output_loss: 37394.3613 - mask_output_acc: 0.0085 - landmarks_output_acc: 0.25 - ETA: 1s - loss: 37010.8047 - mask_output_loss: 17.9655 - landmarks_output_loss: 36992.8394 - mask_output_acc: 0.0082 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 36669.7398 - mask_output_loss: 17.9976 - landmarks_output_loss: 36651.7426 - mask_output_acc: 0.0079 - landmarks_output_acc: 0.25 - ETA: 0s - loss: 36908.3885 - mask_output_loss: 17.9872 - landmarks_output_loss: 36890.4016 - mask_output_acc: 0.0078 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 37379.6995 - mask_output_loss: 18.0211 - landmarks_output_loss: 37361.6787 - mask_output_acc: 0.0076 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 38038.1547 - mask_output_loss: 17.9778 - landmarks_output_loss: 38020.1773 - mask_output_acc: 0.0085 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 38199.1228 - mask_output_loss: 17.9813 - landmarks_output_loss: 38181.1417 - mask_output_acc: 0.0092 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 38057.5607 - mask_output_loss: 17.9876 - landmarks_output_loss: 38039.5734 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.26 - ETA: 0s - loss: 37984.7781 - mask_output_loss: 17.9967 - landmarks_output_loss: 37966.7817 - mask_output_acc: 0.0090 - landmarks_output_acc: 0.26 - 3s 5ms/step - loss: 37999.7872 - mask_output_loss: 17.7284 - landmarks_output_loss: 37982.0591 - mask_output_acc: 0.0088 - landmarks_output_acc: 0.2700 - val_loss: 56303.7514 - val_mask_output_loss: 37.2942 - val_landmarks_output_loss: 56266.4573 - val_mask_output_acc: 0.0047 - val_landmarks_output_acc: 0.0455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x292a5cdfda0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        '../weights/landmarks/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "        ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='../output/logs')\n",
    "    ]\n",
    "\n",
    "model.fit(\n",
    "    images_train,\n",
    "    {\"mask_output\": masks_train, \"landmarks_output\": labels_train},\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(images_valid, {\"mask_output\": masks_valid, \"landmarks_output\": labels_valid})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x292a6c438d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filenames = os.listdir(PATH+'resized/')\n",
    "\n",
    "test_images = np.array([sk.io.imread(PATH+'resized/' + filenames[i]) for i in range(2)])\n",
    "\n",
    "test_images = np.array([sk.transform.resize(image, IMAGE_SIZE) for image in test_images])\n",
    "\n",
    "masks_o, landmarks = model.predict(test_images)\n",
    "masks = (masks_o > 0.8).astype(np.uint8)\n",
    "\n",
    "print(masks[0].shape)\n",
    "for i in range(2):\n",
    "    mask = np.squeeze(masks[i]).astype(np.float32)\n",
    "    plt.imshow(np.dstack((mask,mask,mask)))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
